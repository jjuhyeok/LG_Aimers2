{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90705af242a74678bccabeb5c71240aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Processing: ",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef970afd94d43d187a73f8c7c262fea",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3978fd0064b048b28cb057020fdf082d",
            "value": 3
          }
        },
        "bef970afd94d43d187a73f8c7c262fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978fd0064b048b28cb057020fdf082d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc31326a2587491997e3dc0ce4445cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Processing: ",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55964cd4efb4d6da0c2586f8f5c3064",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_316449f01a664c74b6309883063ad3d0",
            "value": 79
          }
        },
        "f55964cd4efb4d6da0c2586f8f5c3064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316449f01a664c74b6309883063ad3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fGInzaegLto",
        "outputId": "6717a47f-6e32-46c6-cd3c-a14e895e2579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install AutoGluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ToaV4kUqFy1",
        "outputId": "810d2a2c-cf75-4720-de2a-48fde558f841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting AutoGluon\n",
            "  Downloading autogluon-0.6.2-py3-none-any.whl (9.8 kB)\n",
            "Collecting autogluon.core[all]==0.6.2\n",
            "  Downloading autogluon.core-0.6.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==0.6.2\n",
            "  Downloading autogluon.multimodal-0.6.2-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 KB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.text==0.6.2\n",
            "  Downloading autogluon.text-0.6.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.6.2\n",
            "  Downloading autogluon.timeseries-0.6.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.6/103.6 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.6.2\n",
            "  Downloading autogluon.features-0.6.2-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.6.2\n",
            "  Downloading autogluon.tabular-0.6.2-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.5/292.5 KB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.vision==0.6.2\n",
            "  Downloading autogluon.vision-0.6.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.10.0,>=1.5.4 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.24,>=1.21 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (3.2.2)\n",
            "Collecting autogluon.common==0.6.2\n",
            "  Downloading autogluon.common-0.6.2-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (2.25.1)\n",
            "Collecting networkx<3.0,>=2.3\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (4.64.1)\n",
            "Collecting dask<=2021.11.2,>=2021.09.1\n",
            "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.61-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (1.0.2)\n",
            "Requirement already satisfied: pandas!=1.4.0,<1.6,>=1.2.5 in /usr/local/lib/python3.8/dist-packages (from autogluon.core[all]==0.6.2->AutoGluon) (1.3.5)\n",
            "Collecting psutil<6,>=5.7.3\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distributed<=2021.11.2,>=2021.09.1\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[tune]<2.1,>=2.0\n",
            "  Downloading ray-2.0.1-cp38-cp38-manylinux2014_x86_64.whl (60.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperopt<0.2.8,>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<=1.1.10,>=1.1.10\n",
            "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 KB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<=1.2.2\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nptyping<1.5.0,>=1.4.4\n",
            "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
            "Collecting openmim<=0.2.1,>0.1.5\n",
            "  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<=9.4.0,>=9.3.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<=1.3 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.2->AutoGluon) (1.3)\n",
            "Collecting timm<0.7.0\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.2.0,>=2.1.1\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.14,>=0.9\n",
            "  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<1.8.0,>=1.7.4\n",
            "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 KB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate<=0.3.0\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open<5.3.0,>=5.2.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext<0.14.0\n",
            "  Downloading torchtext-0.13.1-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale<=0.4.6,>=0.4.5\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchmetrics<0.9.0,>=0.8.0\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 KB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations<=1.2.0,>=1.1.0\n",
            "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<=0.7.1,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.2->AutoGluon) (0.7.1)\n",
            "Collecting torchvision<0.14.0\n",
            "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<=4.8.0 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.2->AutoGluon) (4.3.3)\n",
            "Collecting pytorch-metric-learning<1.4.0,>=1.3.0\n",
            "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 KB\u001b[0m \u001b[31m682.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.8/dist-packages (from autogluon.multimodal==0.6.2->AutoGluon) (3.7)\n",
            "Collecting transformers<4.24.0,>=4.23.0\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.13,>=1.9\n",
            "  Downloading torch-1.12.1-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightgbm<3.4,>=3.3\n",
            "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost<1.8,>=1.6\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.tabular[all]==0.6.2->AutoGluon) (2.7.10)\n",
            "Collecting catboost<1.2,>=1.0\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib~=1.1 in /usr/local/lib/python3.8/dist-packages (from autogluon.timeseries[all]==0.6.2->AutoGluon) (1.2.0)\n",
            "Collecting statsmodels~=0.13.0\n",
            "  Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gluonts~=0.11.0\n",
            "  Downloading gluonts-0.11.9-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima~=1.8.2\n",
            "  Downloading pmdarima-1.8.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sktime<0.14,>=0.13.1\n",
            "  Downloading sktime-0.13.4-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats~=1.1\n",
            "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gluoncv<0.10.6,>=0.10.5\n",
            "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from autogluon.common==0.6.2->autogluon.core[all]==0.6.2->AutoGluon) (57.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.2->AutoGluon) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.2->AutoGluon) (21.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.2->AutoGluon) (4.7.0.68)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.2->AutoGluon) (0.0.4)\n",
            "Collecting albumentations<=1.2.0,>=1.1.0\n",
            "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.2->AutoGluon) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.2->AutoGluon) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.2->AutoGluon) (5.5.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2.2.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (0.12.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2022.11.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2.11.3)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (7.1.2)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (6.0.4)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (1.7.0)\n",
            "Collecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (0.3.6)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (1.0.3)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.0.7)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (3.4.4)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (1.5.27)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (22.0.4)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.2->AutoGluon) (4.6.0.66)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.8/dist-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.2->AutoGluon) (4.4.0)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.8/dist-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.2->AutoGluon) (1.10.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.2->AutoGluon) (0.16.0)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.2->AutoGluon) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.2->AutoGluon) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.2->AutoGluon) (5.10.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.6.2->AutoGluon) (0.38.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.6.2->AutoGluon) (2022.6.2)\n",
            "Collecting typish>=1.7.0\n",
            "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting rich\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.2->AutoGluon) (0.8.10)\n",
            "Collecting model-index\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.2->AutoGluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.2->AutoGluon) (2022.7)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.8/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.2->AutoGluon) (0.29.33)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.2->AutoGluon) (1.24.3)\n",
            "Collecting pyDeprecate>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (2.9.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.2->AutoGluon) (1.3.3)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.2->AutoGluon) (3.19.6)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<=1.43.0,>=1.32.0\n",
            "  Downloading grpcio-1.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.2->AutoGluon) (3.9.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.2->AutoGluon) (1.3.1)\n",
            "Collecting tensorboardX>=1.9\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.2->AutoGluon) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.2->AutoGluon) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->autogluon.core[all]==0.6.2->AutoGluon) (2022.12.7)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.2->AutoGluon) (2022.10.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.2->AutoGluon) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.2->AutoGluon) (2.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>=1.0.0->autogluon.core[all]==0.6.2->AutoGluon) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.8/dist-packages (from sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.2->AutoGluon) (0.56.4)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels~=0.13.0->autogluon.timeseries[all]==0.6.2->AutoGluon) (0.5.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.61\n",
            "  Downloading botocore-1.29.61-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->autogluon.core[all]==0.6.2->AutoGluon) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->autogluon.core[all]==0.6.2->AutoGluon) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->autogluon.core[all]==0.6.2->AutoGluon) (3.0.9)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (9.0.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.13->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.2->AutoGluon) (1.14.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema<=4.8.0->autogluon.multimodal==0.6.2->AutoGluon) (3.11.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.2->AutoGluon) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.2->AutoGluon) (0.39.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (1.0.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.10.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (8.1.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (2.4.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (3.0.11)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (2.0.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (2.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (1.0.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.2->AutoGluon) (2.0.1)\n",
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.2->AutoGluon) (8.1.0)\n",
            "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv->ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.2->AutoGluon) (2.6.2)\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.2->AutoGluon) (6.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (5.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (1.3.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.2->AutoGluon) (0.0.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.2->AutoGluon) (3.2.2)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307251 sha256=c6b7c54f7177d856235e8c947fb17de2a0894a37111bf9511de3a091ecd15257\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/4c/a4/f6c0eec2ec5c8ffca075e62b0329801f862e1f1b71422f456b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=50a60afb05370428dd0a4d80063862f5d09d451f6976b21cac34ff171ac96578\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=8abddb8fc1f4e54f92c307aaa10da6f7288636e38a1bbde6387eab5d66a78d74\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
            "Successfully built fairscale antlr4-python3-runtime seqeval\n",
            "Installing collected packages: typish, tokenizers, sentencepiece, py4j, distlib, antlr4-python3-runtime, yacs, xxhash, virtualenv, urllib3, torch, tensorboardX, smart-open, pygments, pyDeprecate, psutil, portalocker, Pillow, ordered-set, omegaconf, nptyping, networkx, multiprocess, mdurl, jmespath, grpcio, deprecated, colorama, autocfg, xgboost, torchmetrics, markdown-it-py, hyperopt, fairscale, dask, botocore, accelerate, torchvision, torchtext, statsmodels, seqeval, scikit-image, s3transfer, rich, responses, ray, nlpaug, model-index, lightgbm, huggingface-hub, gluonts, gluoncv, distributed, catboost, transformers, timm, sktime, pytorch-metric-learning, pmdarima, openmim, datasets, boto3, albumentations, tbats, evaluate, autogluon.common, pytorch-lightning, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.vision, autogluon.timeseries, autogluon.text, AutoGluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.3.0\n",
            "    Uninstalling smart-open-6.3.0:\n",
            "      Successfully uninstalled smart-open-6.3.0\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.51.1\n",
            "    Uninstalling grpcio-1.51.1:\n",
            "      Successfully uninstalled grpcio-1.51.1\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2022.2.1\n",
            "    Uninstalling dask-2022.2.1:\n",
            "      Successfully uninstalled dask-2022.2.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.14.1\n",
            "    Uninstalling torchtext-0.14.1:\n",
            "      Successfully uninstalled torchtext-0.14.1\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.12.2\n",
            "    Uninstalling statsmodels-0.12.2:\n",
            "      Successfully uninstalled statsmodels-0.12.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2022.2.1\n",
            "    Uninstalling distributed-2022.2.1:\n",
            "      Successfully uninstalled distributed-2022.2.1\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.43.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.43.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed AutoGluon-0.6.2 Pillow-9.4.0 accelerate-0.13.2 albumentations-1.1.0 antlr4-python3-runtime-4.8 autocfg-0.0.8 autogluon.common-0.6.2 autogluon.core-0.6.2 autogluon.features-0.6.2 autogluon.multimodal-0.6.2 autogluon.tabular-0.6.2 autogluon.text-0.6.2 autogluon.timeseries-0.6.2 autogluon.vision-0.6.2 boto3-1.26.61 botocore-1.29.61 catboost-1.1.1 colorama-0.4.6 dask-2021.11.2 datasets-2.9.0 deprecated-1.2.13 distlib-0.3.6 distributed-2021.11.2 evaluate-0.3.0 fairscale-0.4.6 gluoncv-0.10.5.post0 gluonts-0.11.9 grpcio-1.43.0 huggingface-hub-0.12.0 hyperopt-0.2.7 jmespath-1.0.1 lightgbm-3.3.5 markdown-it-py-2.1.0 mdurl-0.1.2 model-index-0.1.11 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.10 nptyping-1.4.4 omegaconf-2.1.2 openmim-0.2.1 ordered-set-4.1.0 pmdarima-1.8.5 portalocker-2.7.0 psutil-5.9.4 py4j-0.10.9.7 pyDeprecate-0.3.2 pygments-2.14.0 pytorch-lightning-1.7.7 pytorch-metric-learning-1.3.2 ray-2.0.1 responses-0.18.0 rich-13.3.1 s3transfer-0.6.0 scikit-image-0.19.3 sentencepiece-0.1.97 seqeval-1.2.2 sktime-0.13.4 smart-open-5.2.1 statsmodels-0.13.5 tbats-1.1.2 tensorboardX-2.5.1 timm-0.6.12 tokenizers-0.13.2 torch-1.12.1 torchmetrics-0.8.2 torchtext-0.13.1 torchvision-0.13.1 transformers-4.23.1 typish-1.9.3 urllib3-1.26.14 virtualenv-20.17.1 xgboost-1.7.3 xxhash-3.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9AssMEwUgOeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/train.csv')\n",
        "test_x = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/test.csv')\n",
        "submit = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "train.drop(['PRODUCT_ID'],axis = 1, inplace=True)\n",
        "test_x.drop(['PRODUCT_ID'],axis=1,inplace= True)"
      ],
      "metadata": {
        "id": "rvOfsL8Mhcju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 0]['Y_Quality'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbBZMp4S_mzJ",
        "outputId": "2ff31d67-a396-4171-8a48-b93a629cb34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5208367966249999"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 0]['Y_Quality'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTIL5Xr__0Xe",
        "outputId": "3207249c-740a-4eee-9f2d-4958b8723b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.525066667"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 1]['Y_Quality'].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEMK3vuX_2TN",
        "outputId": "5cafcc2f-5c78-49d1-ce21-04d9dad71555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.525085714"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 1]['Y_Quality'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6TENlWU_xRn",
        "outputId": "deeda844-d57a-41db-a587-6c338534b3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5302534412850123"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 1]['Y_Quality'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPtWLjAN_4g2",
        "outputId": "75a3254b-1bff-4615-9a4e-665d26acb483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.534842857"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 2]['Y_Quality'].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPcCnDRwAECN",
        "outputId": "072a42cd-efbe-43e7-ce17-b7157c5860b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.534950794"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train['Y_Class'] == 2]['Y_Quality'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPPOCibF_yKf",
        "outputId": "2c58aaea-bc75-4319-bb40-b1d73dd027a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5420308521844659"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['Y_Quality'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "vOB3WbqRiGLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "v3dfGXZlaKAW",
        "outputId": "02779824-e08b-41b8-8089-c5dedebf5930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e2f7c4aed698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit_con = pd.concat([submit,test_x['PRODUCT_CODE']],axis=1)\n",
        "submit_A = submit_con[submit_con['PRODUCT_CODE'] == 'A_31']\n",
        "submit_T = submit_con[submit_con['PRODUCT_CODE'] == 'T_31']\n",
        "submit_O = submit_con[submit_con['PRODUCT_CODE'] == 'O_31']\n",
        "submit_A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e83MVk7vuB99",
        "outputId": "94997340-4c92-4545-f73e-676253186da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    PRODUCT_ID  Y_Class PRODUCT_CODE\n",
              "3     TEST_003        0         A_31\n",
              "4     TEST_004        0         A_31\n",
              "5     TEST_005        0         A_31\n",
              "6     TEST_006        0         A_31\n",
              "7     TEST_007        0         A_31\n",
              "..         ...      ...          ...\n",
              "284   TEST_284        0         A_31\n",
              "285   TEST_285        0         A_31\n",
              "286   TEST_286        0         A_31\n",
              "292   TEST_292        0         A_31\n",
              "293   TEST_293        0         A_31\n",
              "\n",
              "[67 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b631f83-998d-4762-8530-a87090469cbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRODUCT_ID</th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TEST_005</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TEST_006</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TEST_007</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>TEST_284</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>TEST_285</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>TEST_286</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>TEST_292</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>TEST_293</td>\n",
              "      <td>0</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b631f83-998d-4762-8530-a87090469cbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b631f83-998d-4762-8530-a87090469cbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b631f83-998d-4762-8530-a87090469cbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5oxTECHDiG0Y",
        "outputId": "d32a2ead-df0b-44dd-f624-45e4b6145c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            TIMESTAMP     LINE PRODUCT_CODE  X_1   X_2  X_3   X_4   X_5  X_6  \\\n",
              "0     2022-09-09 2:01  T100306         T_31  2.0  94.0  0.0  45.0  10.0  0.0   \n",
              "1     2022-09-09 2:09  T100304         T_31  2.0  93.0  0.0  45.0  11.0  0.0   \n",
              "2     2022-09-09 8:42  T100304         T_31  2.0  95.0  0.0  45.0  11.0  0.0   \n",
              "3    2022-09-09 10:56  T010305         A_31  NaN   NaN  NaN   NaN   NaN  NaN   \n",
              "4    2022-09-09 11:04  T010306         A_31  NaN   NaN  NaN   NaN   NaN  NaN   \n",
              "..                ...      ...          ...  ...   ...  ...   ...   ...  ...   \n",
              "305  2022-11-05 11:18  T100306         T_31  2.0  91.0  0.0  45.0  10.0  0.0   \n",
              "306  2022-11-05 16:39  T100304         T_31  2.0  96.0  0.0  45.0  11.0  0.0   \n",
              "307  2022-11-05 16:47  T100306         T_31  2.0  91.0  0.0  45.0  10.0  0.0   \n",
              "308  2022-11-05 20:53  T100306         T_31  2.0  95.0  0.0  45.0  10.0  0.0   \n",
              "309  2022-11-05 21:01  T100306         T_31  2.0  87.0  0.0  45.0  10.0  0.0   \n",
              "\n",
              "      X_7  ...  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  X_2873  \\\n",
              "0    51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "1    45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "2    45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "3     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "4     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "..    ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "305  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "306  45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "307  50.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "308  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "309  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "     X_2874  X_2875  time  \n",
              "0       NaN     NaN     0  \n",
              "1       NaN     NaN     1  \n",
              "2       NaN     NaN     2  \n",
              "3       NaN     NaN     3  \n",
              "4       NaN     NaN     4  \n",
              "..      ...     ...   ...  \n",
              "305     NaN     NaN   305  \n",
              "306     NaN     NaN   306  \n",
              "307     NaN     NaN   307  \n",
              "308     NaN     NaN   308  \n",
              "309     NaN     NaN   309  \n",
              "\n",
              "[310 rows x 2879 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63361cdd-2559-405d-bd55-3122d9c360e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>X_2872</th>\n",
              "      <th>X_2873</th>\n",
              "      <th>X_2874</th>\n",
              "      <th>X_2875</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-09 2:01</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-09 2:09</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-09 8:42</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-09 10:56</td>\n",
              "      <td>T010305</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-09 11:04</td>\n",
              "      <td>T010306</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>2022-11-05 11:18</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>2022-11-05 16:39</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>2022-11-05 16:47</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>2022-11-05 20:53</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>2022-11-05 21:01</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>310 rows × 2879 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63361cdd-2559-405d-bd55-3122d9c360e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63361cdd-2559-405d-bd55-3122d9c360e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63361cdd-2559-405d-bd55-3122d9c360e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['time'] = 0\n",
        "for i in range(len(train)):\n",
        "  train.loc[i,'time'] = i\n",
        "\n",
        "test_x['time'] = 0\n",
        "for i in range(len(test_x)):\n",
        "  test_x.loc[i,'time'] = i"
      ],
      "metadata": {
        "id": "hFLupjmD7bqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['PRODUCT_CODE'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUvqzygDmKA-",
        "outputId": "1624021e-57b0-4c69-e1b4-b327b8eb8508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['A_31', 'T_31', 'O_31'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x['PRODUCT_CODE'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBR58r7mNZ_",
        "outputId": "dbca073c-4f09-405c-ef56-d8a98f76437c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['T_31', 'A_31', 'O_31'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['Y_Class','Y_Quality'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "8Odt9flXdwQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_A = train[train['PRODUCT_CODE'] == 'A_31']\n",
        "train_T = train[train['PRODUCT_CODE'] == 'T_31']\n",
        "train_O = train[train['PRODUCT_CODE'] == 'O_31']\n",
        "test_A = test_x[test_x['PRODUCT_CODE'] == 'A_31']\n",
        "test_T = test_x[test_x['PRODUCT_CODE'] == 'T_31']\n",
        "test_O = test_x[test_x['PRODUCT_CODE'] == 'O_31']"
      ],
      "metadata": {
        "id": "AywHertemQuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_A.to_csv('TA.csv', index=False)\n",
        "train_T.to_csv('TT.csv', index=False)\n",
        "train_O.to_csv('TO.csv', index=False)\n",
        "test_A.to_csv('TeA.csv', index=False)\n",
        "test_T.to_csv('TeT.csv', index=False)\n",
        "test_O.to_csv('TeO.csv', index=False)"
      ],
      "metadata": {
        "id": "tVE3ds5mYEHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_A.isnull().sum().to_csv('TA_NULL.csv', index=False)\n",
        "train_T.isnull().sum().to_csv('TT_NULL.csv', index=False)\n",
        "train_O.isnull().sum().to_csv('TO_NULL.csv', index=False)\n",
        "test_A.isnull().sum().to_csv('TeA_NULL.csv', index=False)\n",
        "test_T.isnull().sum().to_csv('TeT_NULL.csv', index=False)\n",
        "test_O.isnull().sum().to_csv('TeO_NULL.csv', index=False)"
      ],
      "metadata": {
        "id": "A0Zh1P16mf_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_A = train_A.dropna(how = 'all',axis=1)\n",
        "train_A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "wnTTYhx5rfGy",
        "outputId": "3c5a972f-986f-430e-88f0-e8aaf9f8b45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE    X_128  \\\n",
              "0          1   0.533433   2022-06-13 5:14  T050304         A_31   7813.0   \n",
              "1          2   0.541819   2022-06-13 5:22  T050307         A_31      NaN   \n",
              "2          1   0.531267   2022-06-13 5:30  T050304         A_31   7815.0   \n",
              "3          2   0.537325   2022-06-13 5:39  T050307         A_31      NaN   \n",
              "4          1   0.531590   2022-06-13 5:47  T050304         A_31   7817.0   \n",
              "..       ...        ...               ...      ...          ...      ...   \n",
              "583        0   0.522340   2022-09-05 8:34  T050304         A_31  11920.0   \n",
              "584        0   0.519519  2022-09-05 11:09  T010305         A_31      NaN   \n",
              "585        0   0.515214  2022-09-05 11:17  T010306         A_31      NaN   \n",
              "594        0   0.524022  2022-09-08 22:38  T050304         A_31  14810.0   \n",
              "595        0   0.521289  2022-09-08 22:47  T050304         A_31  14813.0   \n",
              "\n",
              "       X_129    X_130    X_131  X_132  ...  X_2862  X_2863      X_2864  \\\n",
              "0     7813.0      NaN      NaN   0.19  ...   189.0   383.0  368.296296   \n",
              "1        NaN  19854.0  19854.0   0.20  ...   185.6   383.0  367.735849   \n",
              "2     7815.0      NaN      NaN   0.19  ...   165.5   383.0  367.320755   \n",
              "3        NaN  19856.0  19856.0   0.20  ...   165.8   384.0  369.188679   \n",
              "4     7817.0      NaN      NaN   0.19  ...   182.6   383.0  367.351852   \n",
              "..       ...      ...      ...    ...  ...     ...     ...         ...   \n",
              "583  11920.0      NaN      NaN   0.19  ...   181.6   394.0  371.943396   \n",
              "584      NaN      NaN      NaN    NaN  ...   184.9   466.0  448.634615   \n",
              "585      NaN      NaN      NaN    NaN  ...   176.7   472.0  450.339623   \n",
              "594  14810.0      NaN      NaN   0.19  ...   168.7   384.0  369.811321   \n",
              "595  14813.0      NaN      NaN   0.19  ...   156.6   383.0  367.018868   \n",
              "\n",
              "     X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \n",
              "0     353.0   39.34   40.89   32.56   34.09   77.77     NaN  \n",
              "1     353.0   38.89   42.82   43.92   35.34   72.55     NaN  \n",
              "2     353.0   39.19   36.65   42.47   36.53   78.35     NaN  \n",
              "3     353.0   37.74   39.17   52.17   30.58   71.78     NaN  \n",
              "4     352.0   38.70   41.89   46.93   33.09   76.97     NaN  \n",
              "..      ...     ...     ...     ...     ...     ...     ...  \n",
              "583   353.0   51.71   59.64   54.61   57.05   63.18     1.0  \n",
              "584   432.0     NaN     NaN     NaN     NaN     NaN     NaN  \n",
              "585   432.0     NaN     NaN     NaN     NaN     NaN     NaN  \n",
              "594   353.0   49.47   53.07   50.89   55.10   66.49     1.0  \n",
              "595   352.0     NaN     NaN     NaN     NaN     NaN     1.0  \n",
              "\n",
              "[249 rows x 2121 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf2f5b54-8fe1-4347-81c4-848209ba9f12\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_128</th>\n",
              "      <th>X_129</th>\n",
              "      <th>X_130</th>\n",
              "      <th>X_131</th>\n",
              "      <th>X_132</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2862</th>\n",
              "      <th>X_2863</th>\n",
              "      <th>X_2864</th>\n",
              "      <th>X_2865</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.533433</td>\n",
              "      <td>2022-06-13 5:14</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>7813.0</td>\n",
              "      <td>7813.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>189.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>368.296296</td>\n",
              "      <td>353.0</td>\n",
              "      <td>39.34</td>\n",
              "      <td>40.89</td>\n",
              "      <td>32.56</td>\n",
              "      <td>34.09</td>\n",
              "      <td>77.77</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.541819</td>\n",
              "      <td>2022-06-13 5:22</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19854.0</td>\n",
              "      <td>19854.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>185.6</td>\n",
              "      <td>383.0</td>\n",
              "      <td>367.735849</td>\n",
              "      <td>353.0</td>\n",
              "      <td>38.89</td>\n",
              "      <td>42.82</td>\n",
              "      <td>43.92</td>\n",
              "      <td>35.34</td>\n",
              "      <td>72.55</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531267</td>\n",
              "      <td>2022-06-13 5:30</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>7815.0</td>\n",
              "      <td>7815.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>165.5</td>\n",
              "      <td>383.0</td>\n",
              "      <td>367.320755</td>\n",
              "      <td>353.0</td>\n",
              "      <td>39.19</td>\n",
              "      <td>36.65</td>\n",
              "      <td>42.47</td>\n",
              "      <td>36.53</td>\n",
              "      <td>78.35</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0.537325</td>\n",
              "      <td>2022-06-13 5:39</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19856.0</td>\n",
              "      <td>19856.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>165.8</td>\n",
              "      <td>384.0</td>\n",
              "      <td>369.188679</td>\n",
              "      <td>353.0</td>\n",
              "      <td>37.74</td>\n",
              "      <td>39.17</td>\n",
              "      <td>52.17</td>\n",
              "      <td>30.58</td>\n",
              "      <td>71.78</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531590</td>\n",
              "      <td>2022-06-13 5:47</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>7817.0</td>\n",
              "      <td>7817.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>182.6</td>\n",
              "      <td>383.0</td>\n",
              "      <td>367.351852</td>\n",
              "      <td>352.0</td>\n",
              "      <td>38.70</td>\n",
              "      <td>41.89</td>\n",
              "      <td>46.93</td>\n",
              "      <td>33.09</td>\n",
              "      <td>76.97</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>0</td>\n",
              "      <td>0.522340</td>\n",
              "      <td>2022-09-05 8:34</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>11920.0</td>\n",
              "      <td>11920.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>181.6</td>\n",
              "      <td>394.0</td>\n",
              "      <td>371.943396</td>\n",
              "      <td>353.0</td>\n",
              "      <td>51.71</td>\n",
              "      <td>59.64</td>\n",
              "      <td>54.61</td>\n",
              "      <td>57.05</td>\n",
              "      <td>63.18</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>0</td>\n",
              "      <td>0.519519</td>\n",
              "      <td>2022-09-05 11:09</td>\n",
              "      <td>T010305</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>184.9</td>\n",
              "      <td>466.0</td>\n",
              "      <td>448.634615</td>\n",
              "      <td>432.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>0</td>\n",
              "      <td>0.515214</td>\n",
              "      <td>2022-09-05 11:17</td>\n",
              "      <td>T010306</td>\n",
              "      <td>A_31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>176.7</td>\n",
              "      <td>472.0</td>\n",
              "      <td>450.339623</td>\n",
              "      <td>432.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>0</td>\n",
              "      <td>0.524022</td>\n",
              "      <td>2022-09-08 22:38</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>14810.0</td>\n",
              "      <td>14810.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>168.7</td>\n",
              "      <td>384.0</td>\n",
              "      <td>369.811321</td>\n",
              "      <td>353.0</td>\n",
              "      <td>49.47</td>\n",
              "      <td>53.07</td>\n",
              "      <td>50.89</td>\n",
              "      <td>55.10</td>\n",
              "      <td>66.49</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>0</td>\n",
              "      <td>0.521289</td>\n",
              "      <td>2022-09-08 22:47</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "      <td>14813.0</td>\n",
              "      <td>14813.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>156.6</td>\n",
              "      <td>383.0</td>\n",
              "      <td>367.018868</td>\n",
              "      <td>352.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 2121 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf2f5b54-8fe1-4347-81c4-848209ba9f12')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf2f5b54-8fe1-4347-81c4-848209ba9f12 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf2f5b54-8fe1-4347-81c4-848209ba9f12');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OZPpGygQrgZl",
        "outputId": "8bec69e4-0363-4055-aa38-0c1d1a4a7161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE  X_1    X_2  \\\n",
              "22         0   0.517719   2022-06-14 8:53  T100304         T_31  2.0  102.0   \n",
              "23         0   0.519090   2022-06-14 9:01  T100304         T_31  2.0  102.0   \n",
              "25         1   0.529362   2022-06-19 9:11  T100304         T_31  2.0   97.0   \n",
              "26         1   0.531992   2022-06-19 9:20  T100306         T_31  2.0   95.0   \n",
              "29         1   0.532405  2022-06-19 23:31  T100304         T_31  2.0  100.0   \n",
              "..       ...        ...               ...      ...          ...  ...    ...   \n",
              "589        1   0.529510  2022-09-06 18:00  T100306         T_31  1.0   94.0   \n",
              "590        1   0.529948   2022-09-07 1:01  T100306         T_31  1.0   89.0   \n",
              "591        1   0.529308   2022-09-07 1:09  T100306         T_31  1.0   87.0   \n",
              "592        1   0.528349  2022-09-08 14:22  T100304         T_31  2.0   98.0   \n",
              "593        1   0.526546  2022-09-08 14:30  T100306         T_31  2.0   95.0   \n",
              "\n",
              "     X_3   X_4   X_5  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \\\n",
              "22   0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "23   0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "25   0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "26   0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "29   0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "..   ...   ...   ...  ...     ...     ...     ...     ...     ...     ...   \n",
              "589  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "590  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "591  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "592  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "593  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "     X_2872  X_2873  X_2874  X_2875  \n",
              "22      NaN     NaN     NaN     NaN  \n",
              "23      NaN     NaN     NaN     NaN  \n",
              "25      NaN     NaN     NaN     NaN  \n",
              "26      NaN     NaN     NaN     NaN  \n",
              "29      NaN     NaN     NaN     NaN  \n",
              "..      ...     ...     ...     ...  \n",
              "589     NaN     NaN     NaN     NaN  \n",
              "590     NaN     NaN     NaN     NaN  \n",
              "591     NaN     NaN     NaN     NaN  \n",
              "592     NaN     NaN     NaN     NaN  \n",
              "593     NaN     NaN     NaN     NaN  \n",
              "\n",
              "[343 rows x 2880 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ec4cd06-6d09-4931-bd9c-a150e104f728\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>X_2872</th>\n",
              "      <th>X_2873</th>\n",
              "      <th>X_2874</th>\n",
              "      <th>X_2875</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0.517719</td>\n",
              "      <td>2022-06-14 8:53</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0.519090</td>\n",
              "      <td>2022-06-14 9:01</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>0.529362</td>\n",
              "      <td>2022-06-19 9:11</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531992</td>\n",
              "      <td>2022-06-19 9:20</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>0.532405</td>\n",
              "      <td>2022-06-19 23:31</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>1</td>\n",
              "      <td>0.529510</td>\n",
              "      <td>2022-09-06 18:00</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>590</th>\n",
              "      <td>1</td>\n",
              "      <td>0.529948</td>\n",
              "      <td>2022-09-07 1:01</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591</th>\n",
              "      <td>1</td>\n",
              "      <td>0.529308</td>\n",
              "      <td>2022-09-07 1:09</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>1</td>\n",
              "      <td>0.528349</td>\n",
              "      <td>2022-09-08 14:22</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>1</td>\n",
              "      <td>0.526546</td>\n",
              "      <td>2022-09-08 14:30</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>343 rows × 2880 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ec4cd06-6d09-4931-bd9c-a150e104f728')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ec4cd06-6d09-4931-bd9c-a150e104f728 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ec4cd06-6d09-4931-bd9c-a150e104f728');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_O"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "8o3OcwmcrhhD",
        "outputId": "6ecf9d55-5cf7-44ef-a9da-8c0fdf537024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE   X_1    X_2  \\\n",
              "569        1   0.530533  2022-09-03 18:32  T100304         O_31   4.0   98.0   \n",
              "570        2   0.534951  2022-09-03 18:40  T100306         O_31   6.0   90.0   \n",
              "571        1   0.525916  2022-09-03 18:48  T100304         O_31   4.0  100.0   \n",
              "572        2   0.535205  2022-09-03 18:56  T100306         O_31   6.0   89.0   \n",
              "596        1   0.531375  2022-09-08 14:38  T100304         O_31  40.0   94.0   \n",
              "597        1   0.533702  2022-09-08 14:46  T100306         O_31  21.0   87.0   \n",
              "\n",
              "     X_3   X_4   X_5  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  \\\n",
              "569  0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "570  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "571  0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "572  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "596  0.0  45.0  11.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "597  0.0  45.0  10.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "     X_2872  X_2873  X_2874  X_2875  \n",
              "569     NaN     NaN     NaN     NaN  \n",
              "570     NaN     NaN     NaN     NaN  \n",
              "571     NaN     NaN     NaN     NaN  \n",
              "572     NaN     NaN     NaN     NaN  \n",
              "596     NaN     NaN     NaN     NaN  \n",
              "597     NaN     NaN     NaN     NaN  \n",
              "\n",
              "[6 rows x 2880 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2f3f6c5-8427-417c-a51c-717722c8fd3f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>X_2872</th>\n",
              "      <th>X_2873</th>\n",
              "      <th>X_2874</th>\n",
              "      <th>X_2875</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>1</td>\n",
              "      <td>0.530533</td>\n",
              "      <td>2022-09-03 18:32</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>2</td>\n",
              "      <td>0.534951</td>\n",
              "      <td>2022-09-03 18:40</td>\n",
              "      <td>T100306</td>\n",
              "      <td>O_31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>571</th>\n",
              "      <td>1</td>\n",
              "      <td>0.525916</td>\n",
              "      <td>2022-09-03 18:48</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>2</td>\n",
              "      <td>0.535205</td>\n",
              "      <td>2022-09-03 18:56</td>\n",
              "      <td>T100306</td>\n",
              "      <td>O_31</td>\n",
              "      <td>6.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531375</td>\n",
              "      <td>2022-09-08 14:38</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>40.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>1</td>\n",
              "      <td>0.533702</td>\n",
              "      <td>2022-09-08 14:46</td>\n",
              "      <td>T100306</td>\n",
              "      <td>O_31</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 2880 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2f3f6c5-8427-417c-a51c-717722c8fd3f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2f3f6c5-8427-417c-a51c-717722c8fd3f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2f3f6c5-8427-417c-a51c-717722c8fd3f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_A1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iVrjYhUKc2ue",
        "outputId": "4eca24b9-7176-4c9f-e5e8-ce753a442345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Y_Class  Y_Quality         TIMESTAMP     LINE PRODUCT_CODE\n",
              "0          1   0.533433   2022-06-13 5:14  T050304         A_31\n",
              "1          2   0.541819   2022-06-13 5:22  T050307         A_31\n",
              "2          1   0.531267   2022-06-13 5:30  T050304         A_31\n",
              "3          2   0.537325   2022-06-13 5:39  T050307         A_31\n",
              "4          1   0.531590   2022-06-13 5:47  T050304         A_31\n",
              "..       ...        ...               ...      ...          ...\n",
              "583        0   0.522340   2022-09-05 8:34  T050304         A_31\n",
              "584        0   0.519519  2022-09-05 11:09  T010305         A_31\n",
              "585        0   0.515214  2022-09-05 11:17  T010306         A_31\n",
              "594        0   0.524022  2022-09-08 22:38  T050304         A_31\n",
              "595        0   0.521289  2022-09-08 22:47  T050304         A_31\n",
              "\n",
              "[249 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30816430-4ba9-4cf3-b308-21fe75dc2d8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.533433</td>\n",
              "      <td>2022-06-13 5:14</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.541819</td>\n",
              "      <td>2022-06-13 5:22</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531267</td>\n",
              "      <td>2022-06-13 5:30</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0.537325</td>\n",
              "      <td>2022-06-13 5:39</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.531590</td>\n",
              "      <td>2022-06-13 5:47</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>0</td>\n",
              "      <td>0.522340</td>\n",
              "      <td>2022-09-05 8:34</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>0</td>\n",
              "      <td>0.519519</td>\n",
              "      <td>2022-09-05 11:09</td>\n",
              "      <td>T010305</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>585</th>\n",
              "      <td>0</td>\n",
              "      <td>0.515214</td>\n",
              "      <td>2022-09-05 11:17</td>\n",
              "      <td>T010306</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>0</td>\n",
              "      <td>0.524022</td>\n",
              "      <td>2022-09-08 22:38</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>0</td>\n",
              "      <td>0.521289</td>\n",
              "      <td>2022-09-08 22:47</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30816430-4ba9-4cf3-b308-21fe75dc2d8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30816430-4ba9-4cf3-b308-21fe75dc2d8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30816430-4ba9-4cf3-b308-21fe75dc2d8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_A = test_A.dropna(how = 'all',axis=1)\n",
        "train_A1 = train_A.iloc[:,:5]\n",
        "test_A1 = test_A.iloc[:,:3]\n",
        "#train_A2 = train_A.iloc[:,943:1685]\n",
        "#test_A2 = test_A.iloc[:,:3]\n",
        "test_A1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XRBKevoRr56Q",
        "outputId": "fd21d1b4-af6a-4923-cc13-cb17c30fc974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            TIMESTAMP     LINE PRODUCT_CODE\n",
              "3    2022-09-09 10:56  T010305         A_31\n",
              "4    2022-09-09 11:04  T010306         A_31\n",
              "5    2022-09-09 19:35  T010306         A_31\n",
              "6    2022-09-09 19:43  T010305         A_31\n",
              "7    2022-09-10 12:27  T050304         A_31\n",
              "..                ...      ...          ...\n",
              "284   2022-11-03 9:53  T050307         A_31\n",
              "285  2022-11-03 10:01  T050307         A_31\n",
              "286  2022-11-03 11:31  T050307         A_31\n",
              "292   2022-11-04 0:31  T050307         A_31\n",
              "293   2022-11-04 0:39  T050307         A_31\n",
              "\n",
              "[67 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a1a7171-420c-41f8-b9fe-3f9d9a20e822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-09-09 10:56</td>\n",
              "      <td>T010305</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-09-09 11:04</td>\n",
              "      <td>T010306</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-09-09 19:35</td>\n",
              "      <td>T010306</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-09-09 19:43</td>\n",
              "      <td>T010305</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-09-10 12:27</td>\n",
              "      <td>T050304</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>2022-11-03 9:53</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>2022-11-03 10:01</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>2022-11-03 11:31</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>2022-11-04 0:31</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>2022-11-04 0:39</td>\n",
              "      <td>T050307</td>\n",
              "      <td>A_31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a1a7171-420c-41f8-b9fe-3f9d9a20e822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a1a7171-420c-41f8-b9fe-3f9d9a20e822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a1a7171-420c-41f8-b9fe-3f9d9a20e822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lX0UT3oVr74c",
        "outputId": "12021bbb-8a43-4f13-dafc-83e257e6eba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            TIMESTAMP     LINE PRODUCT_CODE  X_1    X_2  X_3   X_4   X_5  X_6  \\\n",
              "0     2022-09-09 2:01  T100306         T_31  2.0   94.0  0.0  45.0  10.0  0.0   \n",
              "1     2022-09-09 2:09  T100304         T_31  2.0   93.0  0.0  45.0  11.0  0.0   \n",
              "2     2022-09-09 8:42  T100304         T_31  2.0   95.0  0.0  45.0  11.0  0.0   \n",
              "15    2022-09-20 5:20  T100304         T_31  2.0  102.0  0.0  45.0  11.0  0.0   \n",
              "16    2022-09-20 5:28  T100306         T_31  2.0   93.0  0.0  45.0  10.0  0.0   \n",
              "..                ...      ...          ...  ...    ...  ...   ...   ...  ...   \n",
              "305  2022-11-05 11:18  T100306         T_31  2.0   91.0  0.0  45.0  10.0  0.0   \n",
              "306  2022-11-05 16:39  T100304         T_31  2.0   96.0  0.0  45.0  11.0  0.0   \n",
              "307  2022-11-05 16:47  T100306         T_31  2.0   91.0  0.0  45.0  10.0  0.0   \n",
              "308  2022-11-05 20:53  T100306         T_31  2.0   95.0  0.0  45.0  10.0  0.0   \n",
              "309  2022-11-05 21:01  T100306         T_31  2.0   87.0  0.0  45.0  10.0  0.0   \n",
              "\n",
              "      X_7  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
              "0    51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "1    45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "2    45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "15   45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "16   54.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "..    ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "305  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "306  45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "307  50.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "308  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "309  51.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "     X_2873  X_2874  X_2875  \n",
              "0       NaN     NaN     NaN  \n",
              "1       NaN     NaN     NaN  \n",
              "2       NaN     NaN     NaN  \n",
              "15      NaN     NaN     NaN  \n",
              "16      NaN     NaN     NaN  \n",
              "..      ...     ...     ...  \n",
              "305     NaN     NaN     NaN  \n",
              "306     NaN     NaN     NaN  \n",
              "307     NaN     NaN     NaN  \n",
              "308     NaN     NaN     NaN  \n",
              "309     NaN     NaN     NaN  \n",
              "\n",
              "[239 rows x 2878 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b5825c0-9bd7-407b-9ee5-022d292ba83b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>X_2872</th>\n",
              "      <th>X_2873</th>\n",
              "      <th>X_2874</th>\n",
              "      <th>X_2875</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-09-09 2:01</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-09-09 2:09</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-09-09 8:42</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2022-09-20 5:20</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2022-09-20 5:28</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>2022-11-05 11:18</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>2022-11-05 16:39</td>\n",
              "      <td>T100304</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>2022-11-05 16:47</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>2022-11-05 20:53</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>2022-11-05 21:01</td>\n",
              "      <td>T100306</td>\n",
              "      <td>T_31</td>\n",
              "      <td>2.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>239 rows × 2878 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b5825c0-9bd7-407b-9ee5-022d292ba83b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b5825c0-9bd7-407b-9ee5-022d292ba83b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b5825c0-9bd7-407b-9ee5-022d292ba83b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_O"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tIixL2x8r8e6",
        "outputId": "540c0f3f-3ea6-4c8e-8199-60e9fd54010b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            TIMESTAMP     LINE PRODUCT_CODE    X_1    X_2  X_3   X_4   X_5  \\\n",
              "138  2022-10-19 14:17  T100304         O_31    4.0   98.0  0.0  45.0  10.0   \n",
              "256  2022-10-31 14:17  T100304         O_31  154.0   97.0  0.0  45.0  11.0   \n",
              "257  2022-10-31 14:25  T100306         O_31  146.0   94.0  0.0  45.0  10.0   \n",
              "287  2022-11-03 20:34  T100304         O_31  133.0  100.0  0.0  45.0  10.0   \n",
              "\n",
              "     X_6   X_7  ...  X_2866  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  \\\n",
              "138  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "256  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "257  0.0  67.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "287  0.0  45.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "     X_2873  X_2874  X_2875  \n",
              "138     NaN     NaN     NaN  \n",
              "256     NaN     NaN     NaN  \n",
              "257     NaN     NaN     NaN  \n",
              "287     NaN     NaN     NaN  \n",
              "\n",
              "[4 rows x 2878 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ae71231-cf41-4ecd-a3b0-0fe17006a222\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIMESTAMP</th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_3</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_6</th>\n",
              "      <th>X_7</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>X_2872</th>\n",
              "      <th>X_2873</th>\n",
              "      <th>X_2874</th>\n",
              "      <th>X_2875</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>2022-10-19 14:17</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>4.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>2022-10-31 14:17</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>154.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>2022-10-31 14:25</td>\n",
              "      <td>T100306</td>\n",
              "      <td>O_31</td>\n",
              "      <td>146.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>2022-11-03 20:34</td>\n",
              "      <td>T100304</td>\n",
              "      <td>O_31</td>\n",
              "      <td>133.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 2878 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ae71231-cf41-4ecd-a3b0-0fe17006a222')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ae71231-cf41-4ecd-a3b0-0fe17006a222 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ae71231-cf41-4ecd-a3b0-0fe17006a222');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "ART5zDceYiMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NAN 뺴보기\n"
      ],
      "metadata": {
        "id": "8ECE-gFsYjGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Wr2oki7wjem0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "\n",
        "train_data = TabularDataset(train)\n",
        "test_data = TabularDataset(test_x)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='Y_Class',  eval_metric='f1_macro').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['Y_Class'])\n",
        "submit = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submit['Y_Class'] = y_pred\n",
        "submit.to_csv('submit.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsV7bFUzjgXA",
        "outputId": "528430d1-03ee-4b66-e194-617b25548209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230201_015106/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230201_015106/\"\n",
            "AutoGluon Version:  0.6.2\n",
            "Python Version:     3.8.10\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    598\n",
            "Train Data Columns: 2878\n",
            "Label Column: Y_Class\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t3 unique label values:  [1, 2, 0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11449.43 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.87 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 377 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "/usr/local/lib/python3.8/dist-packages/autogluon/features/generators/datetime.py:59: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  good_rows = series[~series.isin(bad_rows)].astype(np.int64)\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 82): ['X_934', 'X_935', 'X_936', 'X_937', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2838', 'X_2844', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 2793 | ['X_1', 'X_2', 'X_3', 'X_4', 'X_5', ...]\n",
            "\t\t('object', [])                     :    1 | ['PRODUCT_CODE']\n",
            "\t\t('object', ['datetime_as_object']) :    2 | ['TIMESTAMP', 'LINE']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             :    1 | ['PRODUCT_CODE']\n",
            "\t\t('float', [])                : 2416 | ['X_1', 'X_2', 'X_5', 'X_7', 'X_8', ...]\n",
            "\t\t('int', ['bool'])            :  377 | ['X_3', 'X_4', 'X_6', 'X_10', 'X_14', ...]\n",
            "\t\t('int', ['datetime_as_int']) :    8 | ['TIMESTAMP', 'TIMESTAMP.month', 'TIMESTAMP.day', 'TIMESTAMP.dayofweek', 'LINE', ...]\n",
            "\t4.0s = Fit runtime\n",
            "\t2796 features in original data used to generate 2802 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 11.82 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 4.29s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t0.6515\t = Validation score   (f1_macro)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t0.7328\t = Validation score   (f1_macro)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestGini_BAG_L1 ...\n",
            "\t0.6311\t = Validation score   (f1_macro)\n",
            "\t2.0s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ...\n",
            "\t0.6193\t = Validation score   (f1_macro)\n",
            "\t2.0s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
            "\t0.6114\t = Validation score   (f1_macro)\n",
            "\t1.67s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
            "\t0.6064\t = Validation score   (f1_macro)\n",
            "\t1.59s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.7588\t = Validation score   (f1_macro)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 24.38s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t2.0s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t2.0s\t = Training   runtime\n",
            "\t0.26s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.67s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.59s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.45s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230201_015106/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling 3"
      ],
      "metadata": {
        "id": "kOl1-lX1oktu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################\n",
        "#T\n",
        "train_data = TabularDataset(train_T)\n",
        "test_data = TabularDataset(test_T)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='Y_Class',  eval_metric='f1_macro').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['Y_Class'])\n",
        "submit_T['Y_Class'] = y_pred\n",
        "#ubmit.to_csv('submit.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "\n",
        "\n",
        "#################\n",
        "#A\n",
        "\n",
        "\n",
        "train_data = TabularDataset(train_A)\n",
        "test_data = TabularDataset(test_A)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='Y_Class',  eval_metric='f1_macro').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['Y_Class'])\n",
        "submit_A['Y_Class'] = y_pred\n",
        "#submit.to_csv('submit.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "\n",
        "\n",
        "#################\n",
        "#0\n",
        "\n",
        "train_data = TabularDataset(train_O)\n",
        "test_data = TabularDataset(test_O)\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "print(\"==================Tabular_complete========================\")\n",
        "predictor = TabularPredictor(label='Y_Class',  eval_metric='f1_macro').fit(train_data, presets='high_quality',  ag_args_fit={'num_gpus': 0})\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "print(\"==================learning_complete========================\")\n",
        "y_pred = predictor.predict(test_data)\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "print(\"==================predictor_complete========================\")\n",
        "y_pred = pd.DataFrame(y_pred, columns=['Y_Class'])\n",
        "submit_O['Y_Class'] = y_pred\n",
        "#submit.to_csv('submit.csv', index=False)\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")\n",
        "print(\"==================submission_complete========================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kb-QpiQonhK",
        "outputId": "9878ab17-db2a-4aec-8909-482db79d4517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230201_020804/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230201_020804/\"\n",
            "AutoGluon Version:  0.6.2\n",
            "Python Version:     3.8.10\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    343\n",
            "Train Data Columns: 2878\n",
            "Label Column: Y_Class\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t3 unique label values:  [0, 1, 2]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11262.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 7.96 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 83 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "/usr/local/lib/python3.8/dist-packages/autogluon/features/generators/datetime.py:59: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  good_rows = series[~series.isin(bad_rows)].astype(np.int64)\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2259): ['PRODUCT_CODE', 'X_3', 'X_4', 'X_6', 'X_10', 'X_14', 'X_19', 'X_23', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_39', 'X_67', 'X_68', 'X_69', 'X_70', 'X_71', 'X_72', 'X_74', 'X_75', 'X_76', 'X_77', 'X_78', 'X_79', 'X_80', 'X_81', 'X_82', 'X_83', 'X_84', 'X_85', 'X_89', 'X_91', 'X_96', 'X_100', 'X_108', 'X_112', 'X_116', 'X_122', 'X_128', 'X_129', 'X_130', 'X_131', 'X_132', 'X_133', 'X_134', 'X_135', 'X_136', 'X_137', 'X_138', 'X_139', 'X_140', 'X_141', 'X_142', 'X_143', 'X_144', 'X_145', 'X_146', 'X_147', 'X_148', 'X_149', 'X_150', 'X_151', 'X_152', 'X_153', 'X_154', 'X_155', 'X_156', 'X_157', 'X_158', 'X_159', 'X_160', 'X_161', 'X_162', 'X_163', 'X_164', 'X_165', 'X_166', 'X_167', 'X_168', 'X_169', 'X_170', 'X_171', 'X_172', 'X_173', 'X_174', 'X_175', 'X_176', 'X_177', 'X_178', 'X_179', 'X_180', 'X_181', 'X_182', 'X_183', 'X_184', 'X_185', 'X_186', 'X_187', 'X_188', 'X_189', 'X_190', 'X_191', 'X_192', 'X_193', 'X_194', 'X_195', 'X_196', 'X_197', 'X_198', 'X_199', 'X_200', 'X_201', 'X_202', 'X_203', 'X_204', 'X_205', 'X_206', 'X_207', 'X_208', 'X_209', 'X_210', 'X_211', 'X_212', 'X_213', 'X_214', 'X_215', 'X_216', 'X_217', 'X_218', 'X_219', 'X_220', 'X_221', 'X_222', 'X_223', 'X_224', 'X_225', 'X_226', 'X_227', 'X_228', 'X_229', 'X_230', 'X_231', 'X_232', 'X_233', 'X_234', 'X_235', 'X_236', 'X_237', 'X_238', 'X_239', 'X_240', 'X_241', 'X_242', 'X_243', 'X_244', 'X_245', 'X_246', 'X_247', 'X_248', 'X_249', 'X_250', 'X_251', 'X_252', 'X_253', 'X_254', 'X_255', 'X_256', 'X_257', 'X_258', 'X_259', 'X_260', 'X_261', 'X_262', 'X_263', 'X_264', 'X_265', 'X_266', 'X_267', 'X_268', 'X_269', 'X_270', 'X_271', 'X_272', 'X_273', 'X_274', 'X_275', 'X_276', 'X_277', 'X_278', 'X_279', 'X_280', 'X_281', 'X_282', 'X_283', 'X_284', 'X_285', 'X_286', 'X_287', 'X_288', 'X_289', 'X_290', 'X_291', 'X_292', 'X_293', 'X_294', 'X_295', 'X_296', 'X_297', 'X_298', 'X_299', 'X_300', 'X_301', 'X_302', 'X_303', 'X_304', 'X_305', 'X_306', 'X_307', 'X_308', 'X_309', 'X_310', 'X_311', 'X_312', 'X_313', 'X_314', 'X_315', 'X_316', 'X_317', 'X_318', 'X_319', 'X_320', 'X_321', 'X_322', 'X_323', 'X_324', 'X_325', 'X_326', 'X_327', 'X_328', 'X_329', 'X_330', 'X_331', 'X_332', 'X_333', 'X_334', 'X_335', 'X_336', 'X_337', 'X_338', 'X_339', 'X_340', 'X_341', 'X_342', 'X_343', 'X_344', 'X_345', 'X_346', 'X_347', 'X_348', 'X_349', 'X_350', 'X_351', 'X_352', 'X_353', 'X_354', 'X_355', 'X_356', 'X_357', 'X_358', 'X_359', 'X_360', 'X_361', 'X_362', 'X_363', 'X_364', 'X_365', 'X_366', 'X_367', 'X_368', 'X_369', 'X_370', 'X_371', 'X_372', 'X_373', 'X_374', 'X_375', 'X_376', 'X_377', 'X_378', 'X_379', 'X_380', 'X_381', 'X_382', 'X_383', 'X_466', 'X_467', 'X_567', 'X_729', 'X_732', 'X_764', 'X_776', 'X_777', 'X_778', 'X_886', 'X_887', 'X_888', 'X_889', 'X_934', 'X_935', 'X_936', 'X_937', 'X_938', 'X_939', 'X_940', 'X_941', 'X_942', 'X_943', 'X_944', 'X_945', 'X_946', 'X_947', 'X_948', 'X_949', 'X_950', 'X_951', 'X_952', 'X_953', 'X_954', 'X_955', 'X_956', 'X_957', 'X_958', 'X_959', 'X_960', 'X_961', 'X_962', 'X_963', 'X_964', 'X_965', 'X_966', 'X_967', 'X_968', 'X_969', 'X_970', 'X_971', 'X_972', 'X_973', 'X_974', 'X_975', 'X_976', 'X_977', 'X_978', 'X_979', 'X_980', 'X_981', 'X_982', 'X_983', 'X_984', 'X_985', 'X_986', 'X_987', 'X_988', 'X_989', 'X_990', 'X_991', 'X_992', 'X_993', 'X_994', 'X_995', 'X_996', 'X_997', 'X_998', 'X_999', 'X_1000', 'X_1001', 'X_1002', 'X_1003', 'X_1004', 'X_1005', 'X_1006', 'X_1007', 'X_1008', 'X_1009', 'X_1010', 'X_1011', 'X_1012', 'X_1013', 'X_1014', 'X_1015', 'X_1016', 'X_1017', 'X_1018', 'X_1019', 'X_1020', 'X_1021', 'X_1022', 'X_1023', 'X_1024', 'X_1025', 'X_1026', 'X_1027', 'X_1028', 'X_1029', 'X_1030', 'X_1031', 'X_1032', 'X_1033', 'X_1034', 'X_1035', 'X_1036', 'X_1037', 'X_1038', 'X_1039', 'X_1040', 'X_1041', 'X_1042', 'X_1043', 'X_1044', 'X_1045', 'X_1046', 'X_1047', 'X_1048', 'X_1049', 'X_1050', 'X_1051', 'X_1052', 'X_1053', 'X_1054', 'X_1055', 'X_1056', 'X_1057', 'X_1058', 'X_1059', 'X_1060', 'X_1061', 'X_1062', 'X_1063', 'X_1064', 'X_1065', 'X_1066', 'X_1067', 'X_1068', 'X_1069', 'X_1070', 'X_1071', 'X_1072', 'X_1073', 'X_1074', 'X_1075', 'X_1076', 'X_1077', 'X_1078', 'X_1079', 'X_1080', 'X_1081', 'X_1082', 'X_1083', 'X_1084', 'X_1085', 'X_1086', 'X_1087', 'X_1088', 'X_1089', 'X_1090', 'X_1091', 'X_1092', 'X_1093', 'X_1094', 'X_1095', 'X_1096', 'X_1097', 'X_1098', 'X_1099', 'X_1100', 'X_1101', 'X_1102', 'X_1103', 'X_1104', 'X_1105', 'X_1106', 'X_1107', 'X_1108', 'X_1109', 'X_1110', 'X_1111', 'X_1112', 'X_1113', 'X_1114', 'X_1115', 'X_1116', 'X_1117', 'X_1118', 'X_1119', 'X_1120', 'X_1121', 'X_1122', 'X_1123', 'X_1124', 'X_1125', 'X_1126', 'X_1127', 'X_1128', 'X_1129', 'X_1130', 'X_1131', 'X_1132', 'X_1133', 'X_1134', 'X_1135', 'X_1136', 'X_1137', 'X_1138', 'X_1139', 'X_1140', 'X_1141', 'X_1142', 'X_1143', 'X_1144', 'X_1145', 'X_1146', 'X_1147', 'X_1148', 'X_1149', 'X_1150', 'X_1151', 'X_1152', 'X_1153', 'X_1154', 'X_1155', 'X_1156', 'X_1157', 'X_1158', 'X_1159', 'X_1160', 'X_1161', 'X_1162', 'X_1163', 'X_1164', 'X_1165', 'X_1166', 'X_1167', 'X_1168', 'X_1169', 'X_1170', 'X_1171', 'X_1172', 'X_1173', 'X_1174', 'X_1175', 'X_1176', 'X_1177', 'X_1178', 'X_1179', 'X_1180', 'X_1181', 'X_1182', 'X_1183', 'X_1184', 'X_1185', 'X_1186', 'X_1187', 'X_1188', 'X_1189', 'X_1190', 'X_1191', 'X_1192', 'X_1193', 'X_1194', 'X_1195', 'X_1196', 'X_1197', 'X_1198', 'X_1199', 'X_1200', 'X_1201', 'X_1202', 'X_1203', 'X_1204', 'X_1205', 'X_1206', 'X_1207', 'X_1208', 'X_1209', 'X_1210', 'X_1211', 'X_1212', 'X_1213', 'X_1214', 'X_1215', 'X_1216', 'X_1217', 'X_1218', 'X_1219', 'X_1220', 'X_1221', 'X_1222', 'X_1223', 'X_1224', 'X_1225', 'X_1226', 'X_1227', 'X_1228', 'X_1229', 'X_1230', 'X_1231', 'X_1232', 'X_1233', 'X_1234', 'X_1235', 'X_1236', 'X_1237', 'X_1238', 'X_1239', 'X_1240', 'X_1241', 'X_1242', 'X_1243', 'X_1244', 'X_1245', 'X_1246', 'X_1247', 'X_1248', 'X_1249', 'X_1250', 'X_1251', 'X_1252', 'X_1253', 'X_1254', 'X_1255', 'X_1256', 'X_1257', 'X_1258', 'X_1259', 'X_1260', 'X_1261', 'X_1262', 'X_1263', 'X_1264', 'X_1265', 'X_1266', 'X_1267', 'X_1268', 'X_1269', 'X_1270', 'X_1271', 'X_1272', 'X_1273', 'X_1274', 'X_1275', 'X_1276', 'X_1277', 'X_1278', 'X_1279', 'X_1280', 'X_1281', 'X_1282', 'X_1283', 'X_1284', 'X_1285', 'X_1286', 'X_1287', 'X_1288', 'X_1289', 'X_1290', 'X_1291', 'X_1292', 'X_1293', 'X_1294', 'X_1295', 'X_1296', 'X_1297', 'X_1298', 'X_1299', 'X_1300', 'X_1301', 'X_1302', 'X_1303', 'X_1304', 'X_1305', 'X_1306', 'X_1307', 'X_1308', 'X_1309', 'X_1310', 'X_1311', 'X_1312', 'X_1313', 'X_1314', 'X_1315', 'X_1316', 'X_1317', 'X_1318', 'X_1319', 'X_1320', 'X_1321', 'X_1322', 'X_1323', 'X_1324', 'X_1325', 'X_1326', 'X_1327', 'X_1328', 'X_1329', 'X_1330', 'X_1331', 'X_1332', 'X_1333', 'X_1334', 'X_1335', 'X_1336', 'X_1337', 'X_1338', 'X_1339', 'X_1340', 'X_1341', 'X_1342', 'X_1343', 'X_1344', 'X_1345', 'X_1346', 'X_1347', 'X_1348', 'X_1349', 'X_1350', 'X_1351', 'X_1352', 'X_1353', 'X_1354', 'X_1355', 'X_1356', 'X_1357', 'X_1358', 'X_1359', 'X_1360', 'X_1361', 'X_1362', 'X_1363', 'X_1364', 'X_1365', 'X_1366', 'X_1367', 'X_1368', 'X_1369', 'X_1370', 'X_1371', 'X_1372', 'X_1373', 'X_1374', 'X_1375', 'X_1376', 'X_1377', 'X_1378', 'X_1379', 'X_1380', 'X_1381', 'X_1382', 'X_1383', 'X_1384', 'X_1385', 'X_1386', 'X_1387', 'X_1388', 'X_1389', 'X_1390', 'X_1391', 'X_1392', 'X_1393', 'X_1394', 'X_1395', 'X_1396', 'X_1397', 'X_1398', 'X_1399', 'X_1400', 'X_1401', 'X_1402', 'X_1403', 'X_1404', 'X_1405', 'X_1406', 'X_1407', 'X_1408', 'X_1409', 'X_1410', 'X_1411', 'X_1412', 'X_1413', 'X_1414', 'X_1415', 'X_1416', 'X_1417', 'X_1418', 'X_1419', 'X_1420', 'X_1421', 'X_1422', 'X_1423', 'X_1424', 'X_1425', 'X_1426', 'X_1427', 'X_1428', 'X_1429', 'X_1430', 'X_1431', 'X_1432', 'X_1433', 'X_1434', 'X_1435', 'X_1436', 'X_1437', 'X_1438', 'X_1439', 'X_1440', 'X_1441', 'X_1442', 'X_1443', 'X_1444', 'X_1445', 'X_1446', 'X_1447', 'X_1448', 'X_1449', 'X_1450', 'X_1451', 'X_1452', 'X_1453', 'X_1454', 'X_1455', 'X_1456', 'X_1457', 'X_1458', 'X_1459', 'X_1460', 'X_1461', 'X_1462', 'X_1463', 'X_1464', 'X_1465', 'X_1466', 'X_1467', 'X_1468', 'X_1469', 'X_1470', 'X_1471', 'X_1472', 'X_1473', 'X_1474', 'X_1475', 'X_1476', 'X_1477', 'X_1478', 'X_1479', 'X_1480', 'X_1481', 'X_1482', 'X_1483', 'X_1484', 'X_1485', 'X_1486', 'X_1487', 'X_1488', 'X_1489', 'X_1490', 'X_1491', 'X_1492', 'X_1493', 'X_1494', 'X_1495', 'X_1496', 'X_1497', 'X_1498', 'X_1499', 'X_1500', 'X_1501', 'X_1502', 'X_1503', 'X_1504', 'X_1505', 'X_1506', 'X_1507', 'X_1508', 'X_1509', 'X_1510', 'X_1511', 'X_1512', 'X_1513', 'X_1514', 'X_1515', 'X_1516', 'X_1517', 'X_1518', 'X_1519', 'X_1520', 'X_1521', 'X_1522', 'X_1523', 'X_1524', 'X_1525', 'X_1526', 'X_1527', 'X_1528', 'X_1529', 'X_1530', 'X_1531', 'X_1532', 'X_1533', 'X_1534', 'X_1535', 'X_1536', 'X_1537', 'X_1538', 'X_1539', 'X_1540', 'X_1541', 'X_1542', 'X_1543', 'X_1544', 'X_1545', 'X_1546', 'X_1547', 'X_1548', 'X_1549', 'X_1550', 'X_1551', 'X_1552', 'X_1553', 'X_1554', 'X_1555', 'X_1556', 'X_1557', 'X_1558', 'X_1559', 'X_1560', 'X_1561', 'X_1562', 'X_1563', 'X_1564', 'X_1565', 'X_1566', 'X_1567', 'X_1568', 'X_1569', 'X_1570', 'X_1571', 'X_1572', 'X_1573', 'X_1574', 'X_1575', 'X_1576', 'X_1577', 'X_1578', 'X_1579', 'X_1580', 'X_1581', 'X_1582', 'X_1583', 'X_1584', 'X_1585', 'X_1586', 'X_1587', 'X_1588', 'X_1589', 'X_1590', 'X_1591', 'X_1592', 'X_1593', 'X_1594', 'X_1595', 'X_1596', 'X_1597', 'X_1598', 'X_1599', 'X_1600', 'X_1601', 'X_1602', 'X_1603', 'X_1604', 'X_1605', 'X_1606', 'X_1607', 'X_1608', 'X_1609', 'X_1610', 'X_1611', 'X_1612', 'X_1613', 'X_1614', 'X_1615', 'X_1616', 'X_1617', 'X_1618', 'X_1619', 'X_1620', 'X_1621', 'X_1622', 'X_1623', 'X_1624', 'X_1625', 'X_1626', 'X_1627', 'X_1628', 'X_1629', 'X_1630', 'X_1631', 'X_1632', 'X_1633', 'X_1634', 'X_1635', 'X_1636', 'X_1637', 'X_1638', 'X_1639', 'X_1640', 'X_1641', 'X_1642', 'X_1643', 'X_1644', 'X_1645', 'X_1646', 'X_1647', 'X_1648', 'X_1649', 'X_1650', 'X_1651', 'X_1652', 'X_1653', 'X_1654', 'X_1655', 'X_1656', 'X_1657', 'X_1658', 'X_1659', 'X_1660', 'X_1661', 'X_1662', 'X_1663', 'X_1664', 'X_1665', 'X_1666', 'X_1667', 'X_1668', 'X_1669', 'X_1670', 'X_1671', 'X_1672', 'X_1673', 'X_1674', 'X_1675', 'X_1676', 'X_1677', 'X_1678', 'X_1679', 'X_1680', 'X_1681', 'X_1682', 'X_1683', 'X_1684', 'X_1685', 'X_1686', 'X_1687', 'X_1688', 'X_1689', 'X_1690', 'X_1691', 'X_1692', 'X_1693', 'X_1694', 'X_1695', 'X_1696', 'X_1697', 'X_1698', 'X_1699', 'X_1700', 'X_1701', 'X_1702', 'X_1703', 'X_1704', 'X_1705', 'X_1706', 'X_1707', 'X_1708', 'X_1709', 'X_1710', 'X_1711', 'X_1712', 'X_1713', 'X_1714', 'X_1715', 'X_1716', 'X_1717', 'X_1718', 'X_1719', 'X_1720', 'X_1721', 'X_1722', 'X_1723', 'X_1724', 'X_1725', 'X_1726', 'X_1727', 'X_1728', 'X_1729', 'X_1730', 'X_1731', 'X_1732', 'X_1733', 'X_1734', 'X_1735', 'X_1736', 'X_1737', 'X_1738', 'X_1739', 'X_1740', 'X_1741', 'X_1742', 'X_1743', 'X_1744', 'X_1745', 'X_1746', 'X_1747', 'X_1748', 'X_1749', 'X_1750', 'X_1751', 'X_1752', 'X_1753', 'X_1754', 'X_1755', 'X_1756', 'X_1757', 'X_1758', 'X_1759', 'X_1760', 'X_1761', 'X_1762', 'X_1763', 'X_1764', 'X_1765', 'X_1766', 'X_1767', 'X_1768', 'X_1769', 'X_1770', 'X_1771', 'X_1772', 'X_1773', 'X_1774', 'X_1775', 'X_1776', 'X_1777', 'X_1778', 'X_1779', 'X_1780', 'X_1781', 'X_1782', 'X_1783', 'X_1784', 'X_1785', 'X_1786', 'X_1787', 'X_1788', 'X_1789', 'X_1790', 'X_1791', 'X_1792', 'X_1793', 'X_1794', 'X_1795', 'X_1796', 'X_1797', 'X_1798', 'X_1799', 'X_1800', 'X_1801', 'X_1802', 'X_1803', 'X_1804', 'X_1805', 'X_1806', 'X_1807', 'X_1808', 'X_1809', 'X_1810', 'X_1811', 'X_1812', 'X_1813', 'X_1814', 'X_1815', 'X_1816', 'X_1817', 'X_1818', 'X_1819', 'X_1820', 'X_1821', 'X_1822', 'X_1823', 'X_1824', 'X_1825', 'X_1826', 'X_1827', 'X_1828', 'X_1829', 'X_1830', 'X_1831', 'X_1832', 'X_1833', 'X_1834', 'X_1835', 'X_1836', 'X_1837', 'X_1838', 'X_1839', 'X_1840', 'X_1841', 'X_1842', 'X_1843', 'X_1844', 'X_1845', 'X_1846', 'X_1847', 'X_1848', 'X_1849', 'X_1850', 'X_1851', 'X_1852', 'X_1853', 'X_1854', 'X_1855', 'X_1856', 'X_1857', 'X_1858', 'X_1859', 'X_1860', 'X_1861', 'X_1862', 'X_1863', 'X_1864', 'X_1865', 'X_1866', 'X_1867', 'X_1868', 'X_1869', 'X_1870', 'X_1871', 'X_1872', 'X_1873', 'X_1874', 'X_1875', 'X_1876', 'X_1877', 'X_1878', 'X_1879', 'X_1880', 'X_1881', 'X_1882', 'X_1883', 'X_1884', 'X_1885', 'X_1886', 'X_1887', 'X_1888', 'X_1889', 'X_1890', 'X_1891', 'X_1892', 'X_1893', 'X_1894', 'X_1895', 'X_1896', 'X_1897', 'X_1898', 'X_1899', 'X_1900', 'X_1901', 'X_1902', 'X_1903', 'X_1904', 'X_1905', 'X_1906', 'X_1907', 'X_1908', 'X_1909', 'X_1910', 'X_1911', 'X_1912', 'X_1913', 'X_1914', 'X_1915', 'X_1916', 'X_1917', 'X_1918', 'X_1919', 'X_1920', 'X_1921', 'X_1922', 'X_1923', 'X_1924', 'X_1925', 'X_1926', 'X_1927', 'X_1928', 'X_1929', 'X_1930', 'X_1931', 'X_1932', 'X_1933', 'X_1934', 'X_1935', 'X_1936', 'X_1937', 'X_1938', 'X_1939', 'X_1940', 'X_1941', 'X_1942', 'X_1943', 'X_1944', 'X_1945', 'X_1946', 'X_1947', 'X_1948', 'X_1949', 'X_1950', 'X_1951', 'X_1952', 'X_1953', 'X_1954', 'X_1955', 'X_1956', 'X_1957', 'X_1958', 'X_1959', 'X_1960', 'X_1961', 'X_1962', 'X_1963', 'X_1964', 'X_1965', 'X_1966', 'X_1967', 'X_1968', 'X_1969', 'X_1970', 'X_1971', 'X_1972', 'X_1973', 'X_1974', 'X_1975', 'X_1976', 'X_1977', 'X_1978', 'X_1979', 'X_1980', 'X_1981', 'X_1982', 'X_1983', 'X_1984', 'X_1985', 'X_1986', 'X_1987', 'X_1988', 'X_1989', 'X_1990', 'X_1991', 'X_1992', 'X_1993', 'X_1994', 'X_1995', 'X_1996', 'X_1997', 'X_1998', 'X_1999', 'X_2000', 'X_2001', 'X_2002', 'X_2003', 'X_2004', 'X_2005', 'X_2006', 'X_2007', 'X_2008', 'X_2009', 'X_2010', 'X_2011', 'X_2012', 'X_2013', 'X_2014', 'X_2015', 'X_2016', 'X_2017', 'X_2018', 'X_2019', 'X_2020', 'X_2021', 'X_2022', 'X_2023', 'X_2024', 'X_2025', 'X_2026', 'X_2027', 'X_2028', 'X_2029', 'X_2030', 'X_2031', 'X_2032', 'X_2033', 'X_2034', 'X_2035', 'X_2036', 'X_2037', 'X_2038', 'X_2039', 'X_2040', 'X_2041', 'X_2042', 'X_2043', 'X_2044', 'X_2045', 'X_2046', 'X_2047', 'X_2048', 'X_2049', 'X_2050', 'X_2051', 'X_2052', 'X_2053', 'X_2054', 'X_2055', 'X_2056', 'X_2057', 'X_2058', 'X_2059', 'X_2060', 'X_2061', 'X_2062', 'X_2063', 'X_2064', 'X_2065', 'X_2066', 'X_2067', 'X_2068', 'X_2069', 'X_2070', 'X_2071', 'X_2072', 'X_2073', 'X_2074', 'X_2075', 'X_2076', 'X_2077', 'X_2078', 'X_2079', 'X_2080', 'X_2081', 'X_2082', 'X_2083', 'X_2084', 'X_2085', 'X_2086', 'X_2087', 'X_2088', 'X_2089', 'X_2090', 'X_2091', 'X_2092', 'X_2093', 'X_2094', 'X_2095', 'X_2096', 'X_2097', 'X_2098', 'X_2099', 'X_2100', 'X_2101', 'X_2102', 'X_2103', 'X_2104', 'X_2105', 'X_2106', 'X_2107', 'X_2108', 'X_2109', 'X_2110', 'X_2111', 'X_2112', 'X_2113', 'X_2114', 'X_2115', 'X_2116', 'X_2117', 'X_2118', 'X_2119', 'X_2120', 'X_2121', 'X_2122', 'X_2123', 'X_2124', 'X_2125', 'X_2126', 'X_2127', 'X_2128', 'X_2129', 'X_2130', 'X_2131', 'X_2132', 'X_2133', 'X_2134', 'X_2135', 'X_2136', 'X_2137', 'X_2138', 'X_2139', 'X_2140', 'X_2141', 'X_2142', 'X_2143', 'X_2144', 'X_2145', 'X_2146', 'X_2147', 'X_2148', 'X_2149', 'X_2150', 'X_2151', 'X_2152', 'X_2153', 'X_2154', 'X_2155', 'X_2156', 'X_2157', 'X_2158', 'X_2159', 'X_2160', 'X_2161', 'X_2162', 'X_2163', 'X_2164', 'X_2165', 'X_2166', 'X_2167', 'X_2168', 'X_2169', 'X_2170', 'X_2171', 'X_2172', 'X_2173', 'X_2174', 'X_2175', 'X_2176', 'X_2177', 'X_2178', 'X_2179', 'X_2180', 'X_2181', 'X_2182', 'X_2183', 'X_2184', 'X_2185', 'X_2186', 'X_2187', 'X_2188', 'X_2189', 'X_2190', 'X_2191', 'X_2192', 'X_2193', 'X_2194', 'X_2195', 'X_2196', 'X_2197', 'X_2198', 'X_2199', 'X_2200', 'X_2201', 'X_2202', 'X_2203', 'X_2204', 'X_2205', 'X_2206', 'X_2207', 'X_2208', 'X_2209', 'X_2210', 'X_2211', 'X_2212', 'X_2213', 'X_2214', 'X_2215', 'X_2216', 'X_2217', 'X_2218', 'X_2219', 'X_2220', 'X_2221', 'X_2222', 'X_2223', 'X_2224', 'X_2225', 'X_2226', 'X_2227', 'X_2228', 'X_2229', 'X_2230', 'X_2231', 'X_2232', 'X_2233', 'X_2234', 'X_2235', 'X_2236', 'X_2237', 'X_2238', 'X_2239', 'X_2240', 'X_2241', 'X_2242', 'X_2243', 'X_2244', 'X_2245', 'X_2246', 'X_2247', 'X_2248', 'X_2249', 'X_2250', 'X_2251', 'X_2252', 'X_2253', 'X_2254', 'X_2255', 'X_2256', 'X_2257', 'X_2258', 'X_2259', 'X_2260', 'X_2261', 'X_2262', 'X_2263', 'X_2264', 'X_2265', 'X_2266', 'X_2267', 'X_2268', 'X_2269', 'X_2270', 'X_2271', 'X_2272', 'X_2273', 'X_2274', 'X_2275', 'X_2276', 'X_2277', 'X_2278', 'X_2279', 'X_2280', 'X_2281', 'X_2282', 'X_2283', 'X_2284', 'X_2285', 'X_2286', 'X_2287', 'X_2288', 'X_2289', 'X_2290', 'X_2291', 'X_2292', 'X_2293', 'X_2294', 'X_2295', 'X_2296', 'X_2297', 'X_2298', 'X_2299', 'X_2300', 'X_2301', 'X_2302', 'X_2303', 'X_2304', 'X_2305', 'X_2306', 'X_2307', 'X_2308', 'X_2309', 'X_2310', 'X_2311', 'X_2312', 'X_2313', 'X_2314', 'X_2315', 'X_2316', 'X_2317', 'X_2318', 'X_2319', 'X_2320', 'X_2321', 'X_2322', 'X_2323', 'X_2324', 'X_2325', 'X_2326', 'X_2327', 'X_2328', 'X_2329', 'X_2330', 'X_2331', 'X_2332', 'X_2333', 'X_2334', 'X_2335', 'X_2336', 'X_2337', 'X_2338', 'X_2339', 'X_2340', 'X_2341', 'X_2342', 'X_2343', 'X_2344', 'X_2345', 'X_2346', 'X_2347', 'X_2348', 'X_2349', 'X_2350', 'X_2351', 'X_2352', 'X_2353', 'X_2354', 'X_2355', 'X_2356', 'X_2357', 'X_2358', 'X_2359', 'X_2360', 'X_2361', 'X_2362', 'X_2363', 'X_2364', 'X_2365', 'X_2366', 'X_2367', 'X_2368', 'X_2369', 'X_2370', 'X_2371', 'X_2372', 'X_2373', 'X_2374', 'X_2375', 'X_2376', 'X_2377', 'X_2378', 'X_2379', 'X_2380', 'X_2381', 'X_2382', 'X_2383', 'X_2384', 'X_2385', 'X_2386', 'X_2387', 'X_2388', 'X_2389', 'X_2390', 'X_2391', 'X_2392', 'X_2393', 'X_2394', 'X_2395', 'X_2396', 'X_2397', 'X_2398', 'X_2399', 'X_2400', 'X_2401', 'X_2402', 'X_2403', 'X_2404', 'X_2405', 'X_2406', 'X_2407', 'X_2408', 'X_2409', 'X_2410', 'X_2411', 'X_2412', 'X_2413', 'X_2414', 'X_2415', 'X_2416', 'X_2417', 'X_2418', 'X_2419', 'X_2420', 'X_2421', 'X_2422', 'X_2423', 'X_2424', 'X_2425', 'X_2426', 'X_2427', 'X_2428', 'X_2429', 'X_2430', 'X_2431', 'X_2432', 'X_2433', 'X_2434', 'X_2435', 'X_2436', 'X_2437', 'X_2438', 'X_2439', 'X_2440', 'X_2441', 'X_2442', 'X_2443', 'X_2444', 'X_2445', 'X_2446', 'X_2447', 'X_2448', 'X_2449', 'X_2450', 'X_2451', 'X_2452', 'X_2453', 'X_2454', 'X_2455', 'X_2456', 'X_2457', 'X_2458', 'X_2459', 'X_2460', 'X_2461', 'X_2462', 'X_2463', 'X_2464', 'X_2465', 'X_2466', 'X_2467', 'X_2468', 'X_2469', 'X_2470', 'X_2471', 'X_2472', 'X_2473', 'X_2474', 'X_2475', 'X_2476', 'X_2477', 'X_2478', 'X_2479', 'X_2480', 'X_2481', 'X_2482', 'X_2483', 'X_2484', 'X_2485', 'X_2486', 'X_2487', 'X_2488', 'X_2489', 'X_2490', 'X_2491', 'X_2492', 'X_2493', 'X_2494', 'X_2495', 'X_2496', 'X_2497', 'X_2498', 'X_2499', 'X_2500', 'X_2501', 'X_2502', 'X_2503', 'X_2504', 'X_2505', 'X_2506', 'X_2507', 'X_2508', 'X_2509', 'X_2510', 'X_2511', 'X_2512', 'X_2513', 'X_2514', 'X_2515', 'X_2516', 'X_2517', 'X_2518', 'X_2519', 'X_2520', 'X_2521', 'X_2522', 'X_2523', 'X_2524', 'X_2525', 'X_2526', 'X_2527', 'X_2528', 'X_2529', 'X_2530', 'X_2531', 'X_2532', 'X_2533', 'X_2534', 'X_2535', 'X_2536', 'X_2537', 'X_2538', 'X_2539', 'X_2540', 'X_2541', 'X_2542', 'X_2543', 'X_2544', 'X_2545', 'X_2546', 'X_2547', 'X_2548', 'X_2549', 'X_2550', 'X_2551', 'X_2552', 'X_2553', 'X_2554', 'X_2555', 'X_2556', 'X_2557', 'X_2558', 'X_2559', 'X_2560', 'X_2561', 'X_2562', 'X_2563', 'X_2564', 'X_2565', 'X_2566', 'X_2567', 'X_2568', 'X_2569', 'X_2570', 'X_2571', 'X_2572', 'X_2573', 'X_2574', 'X_2575', 'X_2576', 'X_2577', 'X_2578', 'X_2579', 'X_2580', 'X_2581', 'X_2582', 'X_2583', 'X_2584', 'X_2585', 'X_2586', 'X_2587', 'X_2588', 'X_2589', 'X_2590', 'X_2591', 'X_2592', 'X_2593', 'X_2594', 'X_2595', 'X_2596', 'X_2597', 'X_2598', 'X_2599', 'X_2600', 'X_2601', 'X_2602', 'X_2603', 'X_2604', 'X_2605', 'X_2606', 'X_2607', 'X_2608', 'X_2609', 'X_2610', 'X_2611', 'X_2612', 'X_2613', 'X_2614', 'X_2615', 'X_2616', 'X_2617', 'X_2618', 'X_2619', 'X_2620', 'X_2621', 'X_2622', 'X_2623', 'X_2624', 'X_2625', 'X_2626', 'X_2627', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2700', 'X_2701', 'X_2702', 'X_2703', 'X_2704', 'X_2705', 'X_2706', 'X_2707', 'X_2708', 'X_2709', 'X_2710', 'X_2711', 'X_2712', 'X_2713', 'X_2714', 'X_2715', 'X_2716', 'X_2717', 'X_2718', 'X_2719', 'X_2720', 'X_2721', 'X_2722', 'X_2723', 'X_2724', 'X_2725', 'X_2726', 'X_2727', 'X_2728', 'X_2729', 'X_2730', 'X_2731', 'X_2732', 'X_2733', 'X_2734', 'X_2735', 'X_2736', 'X_2737', 'X_2738', 'X_2739', 'X_2740', 'X_2741', 'X_2742', 'X_2743', 'X_2744', 'X_2745', 'X_2746', 'X_2747', 'X_2748', 'X_2749', 'X_2750', 'X_2751', 'X_2752', 'X_2753', 'X_2754', 'X_2755', 'X_2756', 'X_2757', 'X_2758', 'X_2759', 'X_2760', 'X_2761', 'X_2762', 'X_2763', 'X_2764', 'X_2765', 'X_2766', 'X_2767', 'X_2768', 'X_2769', 'X_2770', 'X_2771', 'X_2772', 'X_2773', 'X_2774', 'X_2775', 'X_2776', 'X_2777', 'X_2778', 'X_2779', 'X_2780', 'X_2781', 'X_2782', 'X_2783', 'X_2784', 'X_2785', 'X_2786', 'X_2787', 'X_2788', 'X_2789', 'X_2790', 'X_2791', 'X_2792', 'X_2793', 'X_2794', 'X_2795', 'X_2796', 'X_2797', 'X_2798', 'X_2799', 'X_2800', 'X_2801', 'X_2802', 'X_2803', 'X_2804', 'X_2805', 'X_2806', 'X_2807', 'X_2808', 'X_2809', 'X_2810', 'X_2811', 'X_2812', 'X_2813', 'X_2814', 'X_2815', 'X_2816', 'X_2817', 'X_2818', 'X_2819', 'X_2820', 'X_2821', 'X_2822', 'X_2823', 'X_2824', 'X_2825', 'X_2826', 'X_2827', 'X_2828', 'X_2829', 'X_2830', 'X_2831', 'X_2832', 'X_2833', 'X_2834', 'X_2835', 'X_2836', 'X_2837', 'X_2838', 'X_2839', 'X_2840', 'X_2841', 'X_2842', 'X_2843', 'X_2844', 'X_2845', 'X_2846', 'X_2847', 'X_2848', 'X_2849', 'X_2850', 'X_2851', 'X_2852', 'X_2853', 'X_2854', 'X_2855', 'X_2856', 'X_2857', 'X_2858', 'X_2859', 'X_2860', 'X_2861', 'X_2862', 'X_2863', 'X_2864', 'X_2865', 'X_2866', 'X_2867', 'X_2868', 'X_2869', 'X_2870', 'X_2871', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 617 | ['X_1', 'X_2', 'X_5', 'X_7', 'X_8', ...]\n",
            "\t\t('object', ['datetime_as_object']) :   2 | ['TIMESTAMP', 'LINE']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                : 535 | ['X_1', 'X_2', 'X_7', 'X_11', 'X_12', ...]\n",
            "\t\t('int', ['bool'])            :  83 | ['LINE', 'X_5', 'X_8', 'X_9', 'X_15', ...]\n",
            "\t\t('int', ['datetime_as_int']) :   4 | ['TIMESTAMP', 'TIMESTAMP.month', 'TIMESTAMP.day', 'TIMESTAMP.dayofweek']\n",
            "\t1.5s = Fit runtime\n",
            "\t619 features in original data used to generate 622 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.51 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.58s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t0.518\t = Validation score   (f1_macro)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t0.5403\t = Validation score   (f1_macro)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestGini_BAG_L1 ...\n",
            "\t0.4022\t = Validation score   (f1_macro)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ...\n",
            "\t0.326\t = Validation score   (f1_macro)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
            "\t0.326\t = Validation score   (f1_macro)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
            "\t0.3025\t = Validation score   (f1_macro)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6141\t = Validation score   (f1_macro)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.88s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.41s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230201_020804/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9fe5e5e77a1f>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submit_T['Y_Class'] = y_pred\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230201_020812/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230201_020812/\"\n",
            "AutoGluon Version:  0.6.2\n",
            "Python Version:     3.8.10\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    249\n",
            "Train Data Columns: 2878\n",
            "Label Column: Y_Class\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
            "\t3 unique label values:  [1, 2, 0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11259.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 5.78 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 229 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "/usr/local/lib/python3.8/dist-packages/autogluon/features/generators/datetime.py:59: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  good_rows = series[~series.isin(bad_rows)].astype(np.int64)\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 783): ['PRODUCT_CODE', 'X_1', 'X_2', 'X_3', 'X_4', 'X_5', 'X_6', 'X_7', 'X_8', 'X_9', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56', 'X_57', 'X_58', 'X_59', 'X_60', 'X_61', 'X_62', 'X_63', 'X_64', 'X_65', 'X_66', 'X_67', 'X_68', 'X_69', 'X_70', 'X_71', 'X_72', 'X_73', 'X_74', 'X_75', 'X_76', 'X_77', 'X_78', 'X_79', 'X_80', 'X_81', 'X_82', 'X_83', 'X_84', 'X_85', 'X_86', 'X_87', 'X_88', 'X_89', 'X_90', 'X_91', 'X_92', 'X_93', 'X_94', 'X_95', 'X_96', 'X_97', 'X_98', 'X_99', 'X_100', 'X_101', 'X_102', 'X_103', 'X_104', 'X_105', 'X_106', 'X_107', 'X_108', 'X_109', 'X_110', 'X_111', 'X_112', 'X_113', 'X_114', 'X_115', 'X_116', 'X_117', 'X_118', 'X_119', 'X_120', 'X_121', 'X_122', 'X_123', 'X_124', 'X_125', 'X_126', 'X_127', 'X_384', 'X_385', 'X_386', 'X_387', 'X_388', 'X_389', 'X_390', 'X_391', 'X_392', 'X_393', 'X_394', 'X_395', 'X_396', 'X_397', 'X_398', 'X_399', 'X_400', 'X_401', 'X_402', 'X_403', 'X_404', 'X_405', 'X_406', 'X_407', 'X_408', 'X_409', 'X_410', 'X_411', 'X_412', 'X_413', 'X_414', 'X_415', 'X_416', 'X_417', 'X_418', 'X_419', 'X_420', 'X_421', 'X_422', 'X_423', 'X_424', 'X_425', 'X_426', 'X_427', 'X_428', 'X_429', 'X_430', 'X_431', 'X_432', 'X_433', 'X_434', 'X_435', 'X_436', 'X_437', 'X_438', 'X_439', 'X_440', 'X_441', 'X_442', 'X_443', 'X_444', 'X_445', 'X_446', 'X_447', 'X_448', 'X_449', 'X_450', 'X_451', 'X_452', 'X_453', 'X_454', 'X_455', 'X_456', 'X_457', 'X_458', 'X_459', 'X_460', 'X_461', 'X_462', 'X_463', 'X_464', 'X_465', 'X_466', 'X_467', 'X_468', 'X_469', 'X_470', 'X_471', 'X_472', 'X_473', 'X_474', 'X_475', 'X_476', 'X_477', 'X_478', 'X_479', 'X_480', 'X_481', 'X_482', 'X_483', 'X_484', 'X_485', 'X_486', 'X_487', 'X_488', 'X_489', 'X_490', 'X_491', 'X_492', 'X_493', 'X_494', 'X_495', 'X_496', 'X_497', 'X_498', 'X_499', 'X_500', 'X_501', 'X_502', 'X_503', 'X_504', 'X_505', 'X_506', 'X_507', 'X_508', 'X_509', 'X_510', 'X_511', 'X_512', 'X_513', 'X_514', 'X_515', 'X_516', 'X_517', 'X_518', 'X_519', 'X_520', 'X_521', 'X_522', 'X_523', 'X_524', 'X_525', 'X_526', 'X_527', 'X_528', 'X_529', 'X_530', 'X_531', 'X_532', 'X_533', 'X_534', 'X_535', 'X_536', 'X_537', 'X_538', 'X_539', 'X_540', 'X_541', 'X_542', 'X_543', 'X_544', 'X_545', 'X_546', 'X_547', 'X_548', 'X_549', 'X_550', 'X_551', 'X_552', 'X_553', 'X_554', 'X_555', 'X_556', 'X_557', 'X_558', 'X_559', 'X_560', 'X_561', 'X_562', 'X_563', 'X_564', 'X_565', 'X_566', 'X_567', 'X_568', 'X_569', 'X_570', 'X_571', 'X_572', 'X_573', 'X_574', 'X_575', 'X_576', 'X_577', 'X_578', 'X_579', 'X_580', 'X_581', 'X_582', 'X_583', 'X_584', 'X_585', 'X_586', 'X_587', 'X_588', 'X_589', 'X_590', 'X_591', 'X_592', 'X_593', 'X_594', 'X_595', 'X_596', 'X_597', 'X_598', 'X_599', 'X_600', 'X_601', 'X_602', 'X_603', 'X_604', 'X_605', 'X_606', 'X_607', 'X_608', 'X_609', 'X_610', 'X_611', 'X_612', 'X_613', 'X_614', 'X_615', 'X_616', 'X_617', 'X_618', 'X_619', 'X_620', 'X_621', 'X_622', 'X_623', 'X_624', 'X_625', 'X_626', 'X_627', 'X_628', 'X_629', 'X_630', 'X_631', 'X_632', 'X_633', 'X_634', 'X_635', 'X_636', 'X_637', 'X_638', 'X_639', 'X_640', 'X_641', 'X_642', 'X_643', 'X_644', 'X_645', 'X_646', 'X_647', 'X_648', 'X_649', 'X_650', 'X_651', 'X_652', 'X_653', 'X_654', 'X_655', 'X_656', 'X_657', 'X_658', 'X_659', 'X_660', 'X_661', 'X_662', 'X_663', 'X_664', 'X_665', 'X_666', 'X_667', 'X_668', 'X_669', 'X_670', 'X_671', 'X_672', 'X_673', 'X_674', 'X_675', 'X_676', 'X_677', 'X_678', 'X_679', 'X_680', 'X_681', 'X_682', 'X_683', 'X_684', 'X_685', 'X_686', 'X_687', 'X_688', 'X_689', 'X_690', 'X_691', 'X_692', 'X_693', 'X_694', 'X_695', 'X_696', 'X_697', 'X_698', 'X_699', 'X_700', 'X_701', 'X_702', 'X_703', 'X_704', 'X_705', 'X_706', 'X_707', 'X_708', 'X_709', 'X_710', 'X_711', 'X_712', 'X_713', 'X_714', 'X_715', 'X_716', 'X_717', 'X_718', 'X_719', 'X_720', 'X_721', 'X_722', 'X_723', 'X_724', 'X_725', 'X_726', 'X_727', 'X_728', 'X_729', 'X_730', 'X_731', 'X_732', 'X_733', 'X_734', 'X_735', 'X_736', 'X_737', 'X_738', 'X_739', 'X_740', 'X_741', 'X_742', 'X_743', 'X_744', 'X_745', 'X_746', 'X_747', 'X_748', 'X_749', 'X_750', 'X_751', 'X_752', 'X_753', 'X_754', 'X_755', 'X_756', 'X_757', 'X_758', 'X_759', 'X_760', 'X_761', 'X_762', 'X_763', 'X_764', 'X_765', 'X_766', 'X_767', 'X_768', 'X_769', 'X_770', 'X_771', 'X_772', 'X_773', 'X_774', 'X_775', 'X_776', 'X_777', 'X_778', 'X_779', 'X_780', 'X_781', 'X_782', 'X_783', 'X_784', 'X_785', 'X_786', 'X_787', 'X_788', 'X_789', 'X_790', 'X_791', 'X_792', 'X_793', 'X_794', 'X_795', 'X_796', 'X_797', 'X_798', 'X_799', 'X_800', 'X_801', 'X_802', 'X_803', 'X_804', 'X_805', 'X_806', 'X_807', 'X_808', 'X_809', 'X_810', 'X_811', 'X_812', 'X_813', 'X_814', 'X_815', 'X_816', 'X_817', 'X_818', 'X_819', 'X_820', 'X_821', 'X_822', 'X_823', 'X_824', 'X_825', 'X_826', 'X_827', 'X_828', 'X_829', 'X_830', 'X_831', 'X_832', 'X_833', 'X_834', 'X_835', 'X_836', 'X_837', 'X_838', 'X_839', 'X_840', 'X_841', 'X_842', 'X_843', 'X_844', 'X_845', 'X_846', 'X_847', 'X_848', 'X_849', 'X_850', 'X_851', 'X_852', 'X_853', 'X_854', 'X_855', 'X_856', 'X_857', 'X_858', 'X_859', 'X_860', 'X_861', 'X_862', 'X_863', 'X_864', 'X_865', 'X_866', 'X_867', 'X_868', 'X_869', 'X_870', 'X_871', 'X_872', 'X_873', 'X_874', 'X_875', 'X_876', 'X_877', 'X_878', 'X_879', 'X_880', 'X_881', 'X_882', 'X_883', 'X_884', 'X_885', 'X_886', 'X_887', 'X_888', 'X_889', 'X_890', 'X_891', 'X_892', 'X_893', 'X_894', 'X_895', 'X_896', 'X_897', 'X_898', 'X_899', 'X_900', 'X_901', 'X_902', 'X_903', 'X_904', 'X_905', 'X_906', 'X_907', 'X_908', 'X_909', 'X_910', 'X_911', 'X_912', 'X_913', 'X_914', 'X_915', 'X_916', 'X_917', 'X_918', 'X_919', 'X_920', 'X_921', 'X_922', 'X_923', 'X_924', 'X_925', 'X_926', 'X_927', 'X_928', 'X_929', 'X_930', 'X_931', 'X_932', 'X_933', 'X_934', 'X_935', 'X_936', 'X_937', 'X_1003', 'X_1004', 'X_1005', 'X_1092', 'X_1103', 'X_1119', 'X_1130', 'X_1137', 'X_1146', 'X_1157', 'X_1206', 'X_1216', 'X_1328', 'X_1487', 'X_1502', 'X_1503', 'X_1504', 'X_1522', 'X_1531', 'X_2052', 'X_2053', 'X_2054', 'X_2055', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2838', 'X_2844', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 2093 | ['X_128', 'X_129', 'X_130', 'X_131', 'X_132', ...]\n",
            "\t\t('object', ['datetime_as_object']) :    2 | ['TIMESTAMP', 'LINE']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                : 1864 | ['X_128', 'X_129', 'X_130', 'X_131', 'X_132', ...]\n",
            "\t\t('int', ['bool'])            :  229 | ['X_135', 'X_142', 'X_145', 'X_147', 'X_154', ...]\n",
            "\t\t('int', ['datetime_as_int']) :    8 | ['TIMESTAMP', 'TIMESTAMP.month', 'TIMESTAMP.day', 'TIMESTAMP.dayofweek', 'LINE', ...]\n",
            "\t2.6s = Fit runtime\n",
            "\t2095 features in original data used to generate 2101 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 3.79 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 2.84s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t0.6745\t = Validation score   (f1_macro)\n",
            "\t0.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t0.7808\t = Validation score   (f1_macro)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestGini_BAG_L1 ...\n",
            "\t0.684\t = Validation score   (f1_macro)\n",
            "\t1.19s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ...\n",
            "\t0.6954\t = Validation score   (f1_macro)\n",
            "\t1.38s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
            "\t0.6366\t = Validation score   (f1_macro)\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
            "\t0.6711\t = Validation score   (f1_macro)\n",
            "\t1.16s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.8096\t = Validation score   (f1_macro)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 16.01s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.19s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.38s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.16s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.41s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230201_020812/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-9fe5e5e77a1f>:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submit_A['Y_Class'] = y_pred\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230201_020828/\"\n",
            "Presets specified: ['high_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=5, num_bag_sets=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n",
            "==================Tabular_complete========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230201_020828/\"\n",
            "AutoGluon Version:  0.6.2\n",
            "Python Version:     3.8.10\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    6\n",
            "Train Data Columns: 2878\n",
            "Label Column: Y_Class\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [1, 2]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Warning: Updated label_count_threshold from 10 to 2 to avoid cutting too many classes.\n",
            "Selected class <--> label mapping:  class 1 = 2, class 0 = 1\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (2) vs negative (1) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11244.35 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 118 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "/usr/local/lib/python3.8/dist-packages/autogluon/features/generators/datetime.py:59: FutureWarning: casting datetime64[ns, UTC] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.\n",
            "  good_rows = series[~series.isin(bad_rows)].astype(np.int64)\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2367): ['PRODUCT_CODE', 'X_3', 'X_4', 'X_6', 'X_8', 'X_10', 'X_14', 'X_15', 'X_19', 'X_23', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_39', 'X_67', 'X_68', 'X_69', 'X_70', 'X_71', 'X_72', 'X_74', 'X_75', 'X_76', 'X_77', 'X_78', 'X_79', 'X_80', 'X_81', 'X_82', 'X_83', 'X_84', 'X_85', 'X_89', 'X_91', 'X_96', 'X_100', 'X_108', 'X_112', 'X_116', 'X_122', 'X_128', 'X_129', 'X_130', 'X_131', 'X_132', 'X_133', 'X_134', 'X_135', 'X_136', 'X_137', 'X_138', 'X_139', 'X_140', 'X_141', 'X_142', 'X_143', 'X_144', 'X_145', 'X_146', 'X_147', 'X_148', 'X_149', 'X_150', 'X_151', 'X_152', 'X_153', 'X_154', 'X_155', 'X_156', 'X_157', 'X_158', 'X_159', 'X_160', 'X_161', 'X_162', 'X_163', 'X_164', 'X_165', 'X_166', 'X_167', 'X_168', 'X_169', 'X_170', 'X_171', 'X_172', 'X_173', 'X_174', 'X_175', 'X_176', 'X_177', 'X_178', 'X_179', 'X_180', 'X_181', 'X_182', 'X_183', 'X_184', 'X_185', 'X_186', 'X_187', 'X_188', 'X_189', 'X_190', 'X_191', 'X_192', 'X_193', 'X_194', 'X_195', 'X_196', 'X_197', 'X_198', 'X_199', 'X_200', 'X_201', 'X_202', 'X_203', 'X_204', 'X_205', 'X_206', 'X_207', 'X_208', 'X_209', 'X_210', 'X_211', 'X_212', 'X_213', 'X_214', 'X_215', 'X_216', 'X_217', 'X_218', 'X_219', 'X_220', 'X_221', 'X_222', 'X_223', 'X_224', 'X_225', 'X_226', 'X_227', 'X_228', 'X_229', 'X_230', 'X_231', 'X_232', 'X_233', 'X_234', 'X_235', 'X_236', 'X_237', 'X_238', 'X_239', 'X_240', 'X_241', 'X_242', 'X_243', 'X_244', 'X_245', 'X_246', 'X_247', 'X_248', 'X_249', 'X_250', 'X_251', 'X_252', 'X_253', 'X_254', 'X_255', 'X_256', 'X_257', 'X_258', 'X_259', 'X_260', 'X_261', 'X_262', 'X_263', 'X_264', 'X_265', 'X_266', 'X_267', 'X_268', 'X_269', 'X_270', 'X_271', 'X_272', 'X_273', 'X_274', 'X_275', 'X_276', 'X_277', 'X_278', 'X_279', 'X_280', 'X_281', 'X_282', 'X_283', 'X_284', 'X_285', 'X_286', 'X_287', 'X_288', 'X_289', 'X_290', 'X_291', 'X_292', 'X_293', 'X_294', 'X_295', 'X_296', 'X_297', 'X_298', 'X_299', 'X_300', 'X_301', 'X_302', 'X_303', 'X_304', 'X_305', 'X_306', 'X_307', 'X_308', 'X_309', 'X_310', 'X_311', 'X_312', 'X_313', 'X_314', 'X_315', 'X_316', 'X_317', 'X_318', 'X_319', 'X_320', 'X_321', 'X_322', 'X_323', 'X_324', 'X_325', 'X_326', 'X_327', 'X_328', 'X_329', 'X_330', 'X_331', 'X_332', 'X_333', 'X_334', 'X_335', 'X_336', 'X_337', 'X_338', 'X_339', 'X_340', 'X_341', 'X_342', 'X_343', 'X_344', 'X_345', 'X_346', 'X_347', 'X_348', 'X_349', 'X_350', 'X_351', 'X_352', 'X_353', 'X_354', 'X_355', 'X_356', 'X_357', 'X_358', 'X_359', 'X_360', 'X_361', 'X_362', 'X_363', 'X_364', 'X_365', 'X_366', 'X_367', 'X_368', 'X_369', 'X_370', 'X_371', 'X_372', 'X_373', 'X_374', 'X_375', 'X_376', 'X_377', 'X_378', 'X_379', 'X_380', 'X_381', 'X_382', 'X_383', 'X_390', 'X_391', 'X_392', 'X_393', 'X_409', 'X_410', 'X_411', 'X_424', 'X_425', 'X_426', 'X_427', 'X_429', 'X_430', 'X_431', 'X_432', 'X_433', 'X_434', 'X_441', 'X_466', 'X_467', 'X_470', 'X_472', 'X_479', 'X_480', 'X_487', 'X_488', 'X_503', 'X_504', 'X_505', 'X_508', 'X_509', 'X_511', 'X_512', 'X_519', 'X_526', 'X_529', 'X_530', 'X_531', 'X_532', 'X_533', 'X_550', 'X_551', 'X_558', 'X_567', 'X_579', 'X_583', 'X_590', 'X_600', 'X_601', 'X_602', 'X_603', 'X_604', 'X_610', 'X_617', 'X_620', 'X_629', 'X_631', 'X_633', 'X_634', 'X_636', 'X_638', 'X_639', 'X_640', 'X_641', 'X_642', 'X_650', 'X_666', 'X_672', 'X_673', 'X_674', 'X_676', 'X_685', 'X_691', 'X_692', 'X_693', 'X_695', 'X_715', 'X_729', 'X_732', 'X_740', 'X_743', 'X_749', 'X_750', 'X_752', 'X_764', 'X_767', 'X_776', 'X_777', 'X_778', 'X_823', 'X_830', 'X_834', 'X_836', 'X_843', 'X_844', 'X_847', 'X_849', 'X_859', 'X_868', 'X_869', 'X_872', 'X_873', 'X_874', 'X_879', 'X_880', 'X_881', 'X_886', 'X_887', 'X_888', 'X_889', 'X_902', 'X_903', 'X_904', 'X_905', 'X_906', 'X_908', 'X_909', 'X_910', 'X_912', 'X_934', 'X_935', 'X_936', 'X_937', 'X_938', 'X_939', 'X_940', 'X_941', 'X_942', 'X_943', 'X_944', 'X_945', 'X_946', 'X_947', 'X_948', 'X_949', 'X_950', 'X_951', 'X_952', 'X_953', 'X_954', 'X_955', 'X_956', 'X_957', 'X_958', 'X_959', 'X_960', 'X_961', 'X_962', 'X_963', 'X_964', 'X_965', 'X_966', 'X_967', 'X_968', 'X_969', 'X_970', 'X_971', 'X_972', 'X_973', 'X_974', 'X_975', 'X_976', 'X_977', 'X_978', 'X_979', 'X_980', 'X_981', 'X_982', 'X_983', 'X_984', 'X_985', 'X_986', 'X_987', 'X_988', 'X_989', 'X_990', 'X_991', 'X_992', 'X_993', 'X_994', 'X_995', 'X_996', 'X_997', 'X_998', 'X_999', 'X_1000', 'X_1001', 'X_1002', 'X_1003', 'X_1004', 'X_1005', 'X_1006', 'X_1007', 'X_1008', 'X_1009', 'X_1010', 'X_1011', 'X_1012', 'X_1013', 'X_1014', 'X_1015', 'X_1016', 'X_1017', 'X_1018', 'X_1019', 'X_1020', 'X_1021', 'X_1022', 'X_1023', 'X_1024', 'X_1025', 'X_1026', 'X_1027', 'X_1028', 'X_1029', 'X_1030', 'X_1031', 'X_1032', 'X_1033', 'X_1034', 'X_1035', 'X_1036', 'X_1037', 'X_1038', 'X_1039', 'X_1040', 'X_1041', 'X_1042', 'X_1043', 'X_1044', 'X_1045', 'X_1046', 'X_1047', 'X_1048', 'X_1049', 'X_1050', 'X_1051', 'X_1052', 'X_1053', 'X_1054', 'X_1055', 'X_1056', 'X_1057', 'X_1058', 'X_1059', 'X_1060', 'X_1061', 'X_1062', 'X_1063', 'X_1064', 'X_1065', 'X_1066', 'X_1067', 'X_1068', 'X_1069', 'X_1070', 'X_1071', 'X_1072', 'X_1073', 'X_1074', 'X_1075', 'X_1076', 'X_1077', 'X_1078', 'X_1079', 'X_1080', 'X_1081', 'X_1082', 'X_1083', 'X_1084', 'X_1085', 'X_1086', 'X_1087', 'X_1088', 'X_1089', 'X_1090', 'X_1091', 'X_1092', 'X_1093', 'X_1094', 'X_1095', 'X_1096', 'X_1097', 'X_1098', 'X_1099', 'X_1100', 'X_1101', 'X_1102', 'X_1103', 'X_1104', 'X_1105', 'X_1106', 'X_1107', 'X_1108', 'X_1109', 'X_1110', 'X_1111', 'X_1112', 'X_1113', 'X_1114', 'X_1115', 'X_1116', 'X_1117', 'X_1118', 'X_1119', 'X_1120', 'X_1121', 'X_1122', 'X_1123', 'X_1124', 'X_1125', 'X_1126', 'X_1127', 'X_1128', 'X_1129', 'X_1130', 'X_1131', 'X_1132', 'X_1133', 'X_1134', 'X_1135', 'X_1136', 'X_1137', 'X_1138', 'X_1139', 'X_1140', 'X_1141', 'X_1142', 'X_1143', 'X_1144', 'X_1145', 'X_1146', 'X_1147', 'X_1148', 'X_1149', 'X_1150', 'X_1151', 'X_1152', 'X_1153', 'X_1154', 'X_1155', 'X_1156', 'X_1157', 'X_1158', 'X_1159', 'X_1160', 'X_1161', 'X_1162', 'X_1163', 'X_1164', 'X_1165', 'X_1166', 'X_1167', 'X_1168', 'X_1169', 'X_1170', 'X_1171', 'X_1172', 'X_1173', 'X_1174', 'X_1175', 'X_1176', 'X_1177', 'X_1178', 'X_1179', 'X_1180', 'X_1181', 'X_1182', 'X_1183', 'X_1184', 'X_1185', 'X_1186', 'X_1187', 'X_1188', 'X_1189', 'X_1190', 'X_1191', 'X_1192', 'X_1193', 'X_1194', 'X_1195', 'X_1196', 'X_1197', 'X_1198', 'X_1199', 'X_1200', 'X_1201', 'X_1202', 'X_1203', 'X_1204', 'X_1205', 'X_1206', 'X_1207', 'X_1208', 'X_1209', 'X_1210', 'X_1211', 'X_1212', 'X_1213', 'X_1214', 'X_1215', 'X_1216', 'X_1217', 'X_1218', 'X_1219', 'X_1220', 'X_1221', 'X_1222', 'X_1223', 'X_1224', 'X_1225', 'X_1226', 'X_1227', 'X_1228', 'X_1229', 'X_1230', 'X_1231', 'X_1232', 'X_1233', 'X_1234', 'X_1235', 'X_1236', 'X_1237', 'X_1238', 'X_1239', 'X_1240', 'X_1241', 'X_1242', 'X_1243', 'X_1244', 'X_1245', 'X_1246', 'X_1247', 'X_1248', 'X_1249', 'X_1250', 'X_1251', 'X_1252', 'X_1253', 'X_1254', 'X_1255', 'X_1256', 'X_1257', 'X_1258', 'X_1259', 'X_1260', 'X_1261', 'X_1262', 'X_1263', 'X_1264', 'X_1265', 'X_1266', 'X_1267', 'X_1268', 'X_1269', 'X_1270', 'X_1271', 'X_1272', 'X_1273', 'X_1274', 'X_1275', 'X_1276', 'X_1277', 'X_1278', 'X_1279', 'X_1280', 'X_1281', 'X_1282', 'X_1283', 'X_1284', 'X_1285', 'X_1286', 'X_1287', 'X_1288', 'X_1289', 'X_1290', 'X_1291', 'X_1292', 'X_1293', 'X_1294', 'X_1295', 'X_1296', 'X_1297', 'X_1298', 'X_1299', 'X_1300', 'X_1301', 'X_1302', 'X_1303', 'X_1304', 'X_1305', 'X_1306', 'X_1307', 'X_1308', 'X_1309', 'X_1310', 'X_1311', 'X_1312', 'X_1313', 'X_1314', 'X_1315', 'X_1316', 'X_1317', 'X_1318', 'X_1319', 'X_1320', 'X_1321', 'X_1322', 'X_1323', 'X_1324', 'X_1325', 'X_1326', 'X_1327', 'X_1328', 'X_1329', 'X_1330', 'X_1331', 'X_1332', 'X_1333', 'X_1334', 'X_1335', 'X_1336', 'X_1337', 'X_1338', 'X_1339', 'X_1340', 'X_1341', 'X_1342', 'X_1343', 'X_1344', 'X_1345', 'X_1346', 'X_1347', 'X_1348', 'X_1349', 'X_1350', 'X_1351', 'X_1352', 'X_1353', 'X_1354', 'X_1355', 'X_1356', 'X_1357', 'X_1358', 'X_1359', 'X_1360', 'X_1361', 'X_1362', 'X_1363', 'X_1364', 'X_1365', 'X_1366', 'X_1367', 'X_1368', 'X_1369', 'X_1370', 'X_1371', 'X_1372', 'X_1373', 'X_1374', 'X_1375', 'X_1376', 'X_1377', 'X_1378', 'X_1379', 'X_1380', 'X_1381', 'X_1382', 'X_1383', 'X_1384', 'X_1385', 'X_1386', 'X_1387', 'X_1388', 'X_1389', 'X_1390', 'X_1391', 'X_1392', 'X_1393', 'X_1394', 'X_1395', 'X_1396', 'X_1397', 'X_1398', 'X_1399', 'X_1400', 'X_1401', 'X_1402', 'X_1403', 'X_1404', 'X_1405', 'X_1406', 'X_1407', 'X_1408', 'X_1409', 'X_1410', 'X_1411', 'X_1412', 'X_1413', 'X_1414', 'X_1415', 'X_1416', 'X_1417', 'X_1418', 'X_1419', 'X_1420', 'X_1421', 'X_1422', 'X_1423', 'X_1424', 'X_1425', 'X_1426', 'X_1427', 'X_1428', 'X_1429', 'X_1430', 'X_1431', 'X_1432', 'X_1433', 'X_1434', 'X_1435', 'X_1436', 'X_1437', 'X_1438', 'X_1439', 'X_1440', 'X_1441', 'X_1442', 'X_1443', 'X_1444', 'X_1445', 'X_1446', 'X_1447', 'X_1448', 'X_1449', 'X_1450', 'X_1451', 'X_1452', 'X_1453', 'X_1454', 'X_1455', 'X_1456', 'X_1457', 'X_1458', 'X_1459', 'X_1460', 'X_1461', 'X_1462', 'X_1463', 'X_1464', 'X_1465', 'X_1466', 'X_1467', 'X_1468', 'X_1469', 'X_1470', 'X_1471', 'X_1472', 'X_1473', 'X_1474', 'X_1475', 'X_1476', 'X_1477', 'X_1478', 'X_1479', 'X_1480', 'X_1481', 'X_1482', 'X_1483', 'X_1484', 'X_1485', 'X_1486', 'X_1487', 'X_1488', 'X_1489', 'X_1490', 'X_1491', 'X_1492', 'X_1493', 'X_1494', 'X_1495', 'X_1496', 'X_1497', 'X_1498', 'X_1499', 'X_1500', 'X_1501', 'X_1502', 'X_1503', 'X_1504', 'X_1505', 'X_1506', 'X_1507', 'X_1508', 'X_1509', 'X_1510', 'X_1511', 'X_1512', 'X_1513', 'X_1514', 'X_1515', 'X_1516', 'X_1517', 'X_1518', 'X_1519', 'X_1520', 'X_1521', 'X_1522', 'X_1523', 'X_1524', 'X_1525', 'X_1526', 'X_1527', 'X_1528', 'X_1529', 'X_1530', 'X_1531', 'X_1532', 'X_1533', 'X_1534', 'X_1535', 'X_1536', 'X_1537', 'X_1538', 'X_1539', 'X_1540', 'X_1541', 'X_1542', 'X_1543', 'X_1544', 'X_1545', 'X_1546', 'X_1547', 'X_1548', 'X_1549', 'X_1550', 'X_1551', 'X_1552', 'X_1553', 'X_1554', 'X_1555', 'X_1556', 'X_1557', 'X_1558', 'X_1559', 'X_1560', 'X_1561', 'X_1562', 'X_1563', 'X_1564', 'X_1565', 'X_1566', 'X_1567', 'X_1568', 'X_1569', 'X_1570', 'X_1571', 'X_1572', 'X_1573', 'X_1574', 'X_1575', 'X_1576', 'X_1577', 'X_1578', 'X_1579', 'X_1580', 'X_1581', 'X_1582', 'X_1583', 'X_1584', 'X_1585', 'X_1586', 'X_1587', 'X_1588', 'X_1589', 'X_1590', 'X_1591', 'X_1592', 'X_1593', 'X_1594', 'X_1595', 'X_1596', 'X_1597', 'X_1598', 'X_1599', 'X_1600', 'X_1601', 'X_1602', 'X_1603', 'X_1604', 'X_1605', 'X_1606', 'X_1607', 'X_1608', 'X_1609', 'X_1610', 'X_1611', 'X_1612', 'X_1613', 'X_1614', 'X_1615', 'X_1616', 'X_1617', 'X_1618', 'X_1619', 'X_1620', 'X_1621', 'X_1622', 'X_1623', 'X_1624', 'X_1625', 'X_1626', 'X_1627', 'X_1628', 'X_1629', 'X_1630', 'X_1631', 'X_1632', 'X_1633', 'X_1634', 'X_1635', 'X_1636', 'X_1637', 'X_1638', 'X_1639', 'X_1640', 'X_1641', 'X_1642', 'X_1643', 'X_1644', 'X_1645', 'X_1646', 'X_1647', 'X_1648', 'X_1649', 'X_1650', 'X_1651', 'X_1652', 'X_1653', 'X_1654', 'X_1655', 'X_1656', 'X_1657', 'X_1658', 'X_1659', 'X_1660', 'X_1661', 'X_1662', 'X_1663', 'X_1664', 'X_1665', 'X_1666', 'X_1667', 'X_1668', 'X_1669', 'X_1670', 'X_1671', 'X_1672', 'X_1673', 'X_1674', 'X_1675', 'X_1676', 'X_1677', 'X_1678', 'X_1679', 'X_1680', 'X_1681', 'X_1682', 'X_1683', 'X_1684', 'X_1685', 'X_1686', 'X_1687', 'X_1688', 'X_1689', 'X_1690', 'X_1691', 'X_1692', 'X_1693', 'X_1694', 'X_1695', 'X_1696', 'X_1697', 'X_1698', 'X_1699', 'X_1700', 'X_1701', 'X_1702', 'X_1703', 'X_1704', 'X_1705', 'X_1706', 'X_1707', 'X_1708', 'X_1709', 'X_1710', 'X_1711', 'X_1712', 'X_1713', 'X_1714', 'X_1715', 'X_1716', 'X_1717', 'X_1718', 'X_1719', 'X_1720', 'X_1721', 'X_1722', 'X_1723', 'X_1724', 'X_1725', 'X_1726', 'X_1727', 'X_1728', 'X_1729', 'X_1730', 'X_1731', 'X_1732', 'X_1733', 'X_1734', 'X_1735', 'X_1736', 'X_1737', 'X_1738', 'X_1739', 'X_1740', 'X_1741', 'X_1742', 'X_1743', 'X_1744', 'X_1745', 'X_1746', 'X_1747', 'X_1748', 'X_1749', 'X_1750', 'X_1751', 'X_1752', 'X_1753', 'X_1754', 'X_1755', 'X_1756', 'X_1757', 'X_1758', 'X_1759', 'X_1760', 'X_1761', 'X_1762', 'X_1763', 'X_1764', 'X_1765', 'X_1766', 'X_1767', 'X_1768', 'X_1769', 'X_1770', 'X_1771', 'X_1772', 'X_1773', 'X_1774', 'X_1775', 'X_1776', 'X_1777', 'X_1778', 'X_1779', 'X_1780', 'X_1781', 'X_1782', 'X_1783', 'X_1784', 'X_1785', 'X_1786', 'X_1787', 'X_1788', 'X_1789', 'X_1790', 'X_1791', 'X_1792', 'X_1793', 'X_1794', 'X_1795', 'X_1796', 'X_1797', 'X_1798', 'X_1799', 'X_1800', 'X_1801', 'X_1802', 'X_1803', 'X_1804', 'X_1805', 'X_1806', 'X_1807', 'X_1808', 'X_1809', 'X_1810', 'X_1811', 'X_1812', 'X_1813', 'X_1814', 'X_1815', 'X_1816', 'X_1817', 'X_1818', 'X_1819', 'X_1820', 'X_1821', 'X_1822', 'X_1823', 'X_1824', 'X_1825', 'X_1826', 'X_1827', 'X_1828', 'X_1829', 'X_1830', 'X_1831', 'X_1832', 'X_1833', 'X_1834', 'X_1835', 'X_1836', 'X_1837', 'X_1838', 'X_1839', 'X_1840', 'X_1841', 'X_1842', 'X_1843', 'X_1844', 'X_1845', 'X_1846', 'X_1847', 'X_1848', 'X_1849', 'X_1850', 'X_1851', 'X_1852', 'X_1853', 'X_1854', 'X_1855', 'X_1856', 'X_1857', 'X_1858', 'X_1859', 'X_1860', 'X_1861', 'X_1862', 'X_1863', 'X_1864', 'X_1865', 'X_1866', 'X_1867', 'X_1868', 'X_1869', 'X_1870', 'X_1871', 'X_1872', 'X_1873', 'X_1874', 'X_1875', 'X_1876', 'X_1877', 'X_1878', 'X_1879', 'X_1880', 'X_1881', 'X_1882', 'X_1883', 'X_1884', 'X_1885', 'X_1886', 'X_1887', 'X_1888', 'X_1889', 'X_1890', 'X_1891', 'X_1892', 'X_1893', 'X_1894', 'X_1895', 'X_1896', 'X_1897', 'X_1898', 'X_1899', 'X_1900', 'X_1901', 'X_1902', 'X_1903', 'X_1904', 'X_1905', 'X_1906', 'X_1907', 'X_1908', 'X_1909', 'X_1910', 'X_1911', 'X_1912', 'X_1913', 'X_1914', 'X_1915', 'X_1916', 'X_1917', 'X_1918', 'X_1919', 'X_1920', 'X_1921', 'X_1922', 'X_1923', 'X_1924', 'X_1925', 'X_1926', 'X_1927', 'X_1928', 'X_1929', 'X_1930', 'X_1931', 'X_1932', 'X_1933', 'X_1934', 'X_1935', 'X_1936', 'X_1937', 'X_1938', 'X_1939', 'X_1940', 'X_1941', 'X_1942', 'X_1943', 'X_1944', 'X_1945', 'X_1946', 'X_1947', 'X_1948', 'X_1949', 'X_1950', 'X_1951', 'X_1952', 'X_1953', 'X_1954', 'X_1955', 'X_1956', 'X_1957', 'X_1958', 'X_1959', 'X_1960', 'X_1961', 'X_1962', 'X_1963', 'X_1964', 'X_1965', 'X_1966', 'X_1967', 'X_1968', 'X_1969', 'X_1970', 'X_1971', 'X_1972', 'X_1973', 'X_1974', 'X_1975', 'X_1976', 'X_1977', 'X_1978', 'X_1979', 'X_1980', 'X_1981', 'X_1982', 'X_1983', 'X_1984', 'X_1985', 'X_1986', 'X_1987', 'X_1988', 'X_1989', 'X_1990', 'X_1991', 'X_1992', 'X_1993', 'X_1994', 'X_1995', 'X_1996', 'X_1997', 'X_1998', 'X_1999', 'X_2000', 'X_2001', 'X_2002', 'X_2003', 'X_2004', 'X_2005', 'X_2006', 'X_2007', 'X_2008', 'X_2009', 'X_2010', 'X_2011', 'X_2012', 'X_2013', 'X_2014', 'X_2015', 'X_2016', 'X_2017', 'X_2018', 'X_2019', 'X_2020', 'X_2021', 'X_2022', 'X_2023', 'X_2024', 'X_2025', 'X_2026', 'X_2027', 'X_2028', 'X_2029', 'X_2030', 'X_2031', 'X_2032', 'X_2033', 'X_2034', 'X_2035', 'X_2036', 'X_2037', 'X_2038', 'X_2039', 'X_2040', 'X_2041', 'X_2042', 'X_2043', 'X_2044', 'X_2045', 'X_2046', 'X_2047', 'X_2048', 'X_2049', 'X_2050', 'X_2051', 'X_2052', 'X_2053', 'X_2054', 'X_2055', 'X_2056', 'X_2057', 'X_2058', 'X_2059', 'X_2060', 'X_2061', 'X_2062', 'X_2063', 'X_2064', 'X_2065', 'X_2066', 'X_2067', 'X_2068', 'X_2069', 'X_2070', 'X_2071', 'X_2072', 'X_2073', 'X_2074', 'X_2075', 'X_2076', 'X_2077', 'X_2078', 'X_2079', 'X_2080', 'X_2081', 'X_2082', 'X_2083', 'X_2084', 'X_2085', 'X_2086', 'X_2087', 'X_2088', 'X_2089', 'X_2090', 'X_2091', 'X_2092', 'X_2093', 'X_2094', 'X_2095', 'X_2096', 'X_2097', 'X_2098', 'X_2099', 'X_2100', 'X_2101', 'X_2102', 'X_2103', 'X_2104', 'X_2105', 'X_2106', 'X_2107', 'X_2108', 'X_2109', 'X_2110', 'X_2111', 'X_2112', 'X_2113', 'X_2114', 'X_2115', 'X_2116', 'X_2117', 'X_2118', 'X_2119', 'X_2120', 'X_2121', 'X_2122', 'X_2123', 'X_2124', 'X_2125', 'X_2126', 'X_2127', 'X_2128', 'X_2129', 'X_2130', 'X_2131', 'X_2132', 'X_2133', 'X_2134', 'X_2135', 'X_2136', 'X_2137', 'X_2138', 'X_2139', 'X_2140', 'X_2141', 'X_2142', 'X_2143', 'X_2144', 'X_2145', 'X_2146', 'X_2147', 'X_2148', 'X_2149', 'X_2150', 'X_2151', 'X_2152', 'X_2153', 'X_2154', 'X_2155', 'X_2156', 'X_2157', 'X_2158', 'X_2159', 'X_2160', 'X_2161', 'X_2162', 'X_2163', 'X_2164', 'X_2165', 'X_2166', 'X_2167', 'X_2168', 'X_2169', 'X_2170', 'X_2171', 'X_2172', 'X_2173', 'X_2174', 'X_2175', 'X_2176', 'X_2177', 'X_2178', 'X_2179', 'X_2180', 'X_2181', 'X_2182', 'X_2183', 'X_2184', 'X_2185', 'X_2186', 'X_2187', 'X_2188', 'X_2189', 'X_2190', 'X_2191', 'X_2192', 'X_2193', 'X_2194', 'X_2195', 'X_2196', 'X_2197', 'X_2198', 'X_2199', 'X_2200', 'X_2201', 'X_2202', 'X_2203', 'X_2204', 'X_2205', 'X_2206', 'X_2207', 'X_2208', 'X_2209', 'X_2210', 'X_2211', 'X_2212', 'X_2213', 'X_2214', 'X_2215', 'X_2216', 'X_2217', 'X_2218', 'X_2219', 'X_2220', 'X_2221', 'X_2222', 'X_2223', 'X_2224', 'X_2225', 'X_2226', 'X_2227', 'X_2228', 'X_2229', 'X_2230', 'X_2231', 'X_2232', 'X_2233', 'X_2234', 'X_2235', 'X_2236', 'X_2237', 'X_2238', 'X_2239', 'X_2240', 'X_2241', 'X_2242', 'X_2243', 'X_2244', 'X_2245', 'X_2246', 'X_2247', 'X_2248', 'X_2249', 'X_2250', 'X_2251', 'X_2252', 'X_2253', 'X_2254', 'X_2255', 'X_2256', 'X_2257', 'X_2258', 'X_2259', 'X_2260', 'X_2261', 'X_2262', 'X_2263', 'X_2264', 'X_2265', 'X_2266', 'X_2267', 'X_2268', 'X_2269', 'X_2270', 'X_2271', 'X_2272', 'X_2273', 'X_2274', 'X_2275', 'X_2276', 'X_2277', 'X_2278', 'X_2279', 'X_2280', 'X_2281', 'X_2282', 'X_2283', 'X_2284', 'X_2285', 'X_2286', 'X_2287', 'X_2288', 'X_2289', 'X_2290', 'X_2291', 'X_2292', 'X_2293', 'X_2294', 'X_2295', 'X_2296', 'X_2297', 'X_2298', 'X_2299', 'X_2300', 'X_2301', 'X_2302', 'X_2303', 'X_2304', 'X_2305', 'X_2306', 'X_2307', 'X_2308', 'X_2309', 'X_2310', 'X_2311', 'X_2312', 'X_2313', 'X_2314', 'X_2315', 'X_2316', 'X_2317', 'X_2318', 'X_2319', 'X_2320', 'X_2321', 'X_2322', 'X_2323', 'X_2324', 'X_2325', 'X_2326', 'X_2327', 'X_2328', 'X_2329', 'X_2330', 'X_2331', 'X_2332', 'X_2333', 'X_2334', 'X_2335', 'X_2336', 'X_2337', 'X_2338', 'X_2339', 'X_2340', 'X_2341', 'X_2342', 'X_2343', 'X_2344', 'X_2345', 'X_2346', 'X_2347', 'X_2348', 'X_2349', 'X_2350', 'X_2351', 'X_2352', 'X_2353', 'X_2354', 'X_2355', 'X_2356', 'X_2357', 'X_2358', 'X_2359', 'X_2360', 'X_2361', 'X_2362', 'X_2363', 'X_2364', 'X_2365', 'X_2366', 'X_2367', 'X_2368', 'X_2369', 'X_2370', 'X_2371', 'X_2372', 'X_2373', 'X_2374', 'X_2375', 'X_2376', 'X_2377', 'X_2378', 'X_2379', 'X_2380', 'X_2381', 'X_2382', 'X_2383', 'X_2384', 'X_2385', 'X_2386', 'X_2387', 'X_2388', 'X_2389', 'X_2390', 'X_2391', 'X_2392', 'X_2393', 'X_2394', 'X_2395', 'X_2396', 'X_2397', 'X_2398', 'X_2399', 'X_2400', 'X_2401', 'X_2402', 'X_2403', 'X_2404', 'X_2405', 'X_2406', 'X_2407', 'X_2408', 'X_2409', 'X_2410', 'X_2411', 'X_2412', 'X_2413', 'X_2414', 'X_2415', 'X_2416', 'X_2417', 'X_2418', 'X_2419', 'X_2420', 'X_2421', 'X_2422', 'X_2423', 'X_2424', 'X_2425', 'X_2426', 'X_2427', 'X_2428', 'X_2429', 'X_2430', 'X_2431', 'X_2432', 'X_2433', 'X_2434', 'X_2435', 'X_2436', 'X_2437', 'X_2438', 'X_2439', 'X_2440', 'X_2441', 'X_2442', 'X_2443', 'X_2444', 'X_2445', 'X_2446', 'X_2447', 'X_2448', 'X_2449', 'X_2450', 'X_2451', 'X_2452', 'X_2453', 'X_2454', 'X_2455', 'X_2456', 'X_2457', 'X_2458', 'X_2459', 'X_2460', 'X_2461', 'X_2462', 'X_2463', 'X_2464', 'X_2465', 'X_2466', 'X_2467', 'X_2468', 'X_2469', 'X_2470', 'X_2471', 'X_2472', 'X_2473', 'X_2474', 'X_2475', 'X_2476', 'X_2477', 'X_2478', 'X_2479', 'X_2480', 'X_2481', 'X_2482', 'X_2483', 'X_2484', 'X_2485', 'X_2486', 'X_2487', 'X_2488', 'X_2489', 'X_2490', 'X_2491', 'X_2492', 'X_2493', 'X_2494', 'X_2495', 'X_2496', 'X_2497', 'X_2498', 'X_2499', 'X_2500', 'X_2501', 'X_2502', 'X_2503', 'X_2504', 'X_2505', 'X_2506', 'X_2507', 'X_2508', 'X_2509', 'X_2510', 'X_2511', 'X_2512', 'X_2513', 'X_2514', 'X_2515', 'X_2516', 'X_2517', 'X_2518', 'X_2519', 'X_2520', 'X_2521', 'X_2522', 'X_2523', 'X_2524', 'X_2525', 'X_2526', 'X_2527', 'X_2528', 'X_2529', 'X_2530', 'X_2531', 'X_2532', 'X_2533', 'X_2534', 'X_2535', 'X_2536', 'X_2537', 'X_2538', 'X_2539', 'X_2540', 'X_2541', 'X_2542', 'X_2543', 'X_2544', 'X_2545', 'X_2546', 'X_2547', 'X_2548', 'X_2549', 'X_2550', 'X_2551', 'X_2552', 'X_2553', 'X_2554', 'X_2555', 'X_2556', 'X_2557', 'X_2558', 'X_2559', 'X_2560', 'X_2561', 'X_2562', 'X_2563', 'X_2564', 'X_2565', 'X_2566', 'X_2567', 'X_2568', 'X_2569', 'X_2570', 'X_2571', 'X_2572', 'X_2573', 'X_2574', 'X_2575', 'X_2576', 'X_2577', 'X_2578', 'X_2579', 'X_2580', 'X_2581', 'X_2582', 'X_2583', 'X_2584', 'X_2585', 'X_2586', 'X_2587', 'X_2588', 'X_2589', 'X_2590', 'X_2591', 'X_2592', 'X_2593', 'X_2594', 'X_2595', 'X_2596', 'X_2597', 'X_2598', 'X_2599', 'X_2600', 'X_2601', 'X_2602', 'X_2603', 'X_2604', 'X_2605', 'X_2606', 'X_2607', 'X_2608', 'X_2609', 'X_2610', 'X_2611', 'X_2612', 'X_2613', 'X_2614', 'X_2615', 'X_2616', 'X_2617', 'X_2618', 'X_2619', 'X_2620', 'X_2621', 'X_2622', 'X_2623', 'X_2624', 'X_2625', 'X_2626', 'X_2627', 'X_2628', 'X_2629', 'X_2630', 'X_2631', 'X_2632', 'X_2633', 'X_2634', 'X_2635', 'X_2636', 'X_2637', 'X_2638', 'X_2639', 'X_2640', 'X_2641', 'X_2642', 'X_2643', 'X_2644', 'X_2645', 'X_2646', 'X_2647', 'X_2648', 'X_2649', 'X_2650', 'X_2651', 'X_2652', 'X_2653', 'X_2654', 'X_2655', 'X_2656', 'X_2657', 'X_2658', 'X_2659', 'X_2660', 'X_2661', 'X_2662', 'X_2663', 'X_2664', 'X_2665', 'X_2666', 'X_2667', 'X_2668', 'X_2669', 'X_2670', 'X_2671', 'X_2672', 'X_2673', 'X_2674', 'X_2675', 'X_2676', 'X_2677', 'X_2678', 'X_2679', 'X_2680', 'X_2681', 'X_2682', 'X_2683', 'X_2684', 'X_2685', 'X_2686', 'X_2687', 'X_2688', 'X_2689', 'X_2690', 'X_2691', 'X_2692', 'X_2693', 'X_2694', 'X_2695', 'X_2696', 'X_2697', 'X_2698', 'X_2699', 'X_2700', 'X_2701', 'X_2702', 'X_2703', 'X_2704', 'X_2705', 'X_2706', 'X_2707', 'X_2708', 'X_2709', 'X_2710', 'X_2711', 'X_2712', 'X_2713', 'X_2714', 'X_2715', 'X_2716', 'X_2717', 'X_2718', 'X_2719', 'X_2720', 'X_2721', 'X_2722', 'X_2723', 'X_2724', 'X_2725', 'X_2726', 'X_2727', 'X_2728', 'X_2729', 'X_2730', 'X_2731', 'X_2732', 'X_2733', 'X_2734', 'X_2735', 'X_2736', 'X_2737', 'X_2738', 'X_2739', 'X_2740', 'X_2741', 'X_2742', 'X_2743', 'X_2744', 'X_2745', 'X_2746', 'X_2747', 'X_2748', 'X_2749', 'X_2750', 'X_2751', 'X_2752', 'X_2753', 'X_2754', 'X_2755', 'X_2756', 'X_2757', 'X_2758', 'X_2759', 'X_2760', 'X_2761', 'X_2762', 'X_2763', 'X_2764', 'X_2765', 'X_2766', 'X_2767', 'X_2768', 'X_2769', 'X_2770', 'X_2771', 'X_2772', 'X_2773', 'X_2774', 'X_2775', 'X_2776', 'X_2777', 'X_2778', 'X_2779', 'X_2780', 'X_2781', 'X_2782', 'X_2783', 'X_2784', 'X_2785', 'X_2786', 'X_2787', 'X_2788', 'X_2789', 'X_2790', 'X_2791', 'X_2792', 'X_2793', 'X_2794', 'X_2795', 'X_2796', 'X_2797', 'X_2798', 'X_2799', 'X_2800', 'X_2801', 'X_2802', 'X_2803', 'X_2804', 'X_2805', 'X_2806', 'X_2807', 'X_2808', 'X_2809', 'X_2810', 'X_2811', 'X_2812', 'X_2813', 'X_2814', 'X_2815', 'X_2816', 'X_2817', 'X_2818', 'X_2819', 'X_2820', 'X_2821', 'X_2822', 'X_2823', 'X_2824', 'X_2825', 'X_2826', 'X_2827', 'X_2828', 'X_2829', 'X_2830', 'X_2831', 'X_2832', 'X_2833', 'X_2834', 'X_2835', 'X_2836', 'X_2837', 'X_2838', 'X_2839', 'X_2840', 'X_2841', 'X_2842', 'X_2843', 'X_2844', 'X_2845', 'X_2846', 'X_2847', 'X_2848', 'X_2849', 'X_2850', 'X_2851', 'X_2852', 'X_2853', 'X_2854', 'X_2855', 'X_2856', 'X_2857', 'X_2858', 'X_2859', 'X_2860', 'X_2861', 'X_2862', 'X_2863', 'X_2864', 'X_2865', 'X_2866', 'X_2867', 'X_2868', 'X_2869', 'X_2870', 'X_2871', 'X_2872', 'X_2873', 'X_2874', 'X_2875']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                      : 509 | ['X_1', 'X_2', 'X_5', 'X_7', 'X_9', ...]\n",
            "\t\t('object', ['datetime_as_object']) :   2 | ['TIMESTAMP', 'LINE']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])                : 392 | ['X_1', 'X_2', 'X_7', 'X_11', 'X_12', ...]\n",
            "\t\t('int', ['bool'])            : 118 | ['LINE', 'X_5', 'X_9', 'X_16', 'X_17', ...]\n",
            "\t\t('int', ['datetime_as_int']) :   3 | ['TIMESTAMP', 'TIMESTAMP.day', 'TIMESTAMP.dayofweek']\n",
            "\t1.5s = Fit runtime\n",
            "\t511 features in original data used to generate 513 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.58s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
            "\t0.4\t = Validation score   (f1_macro)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ...\n",
            "\t0.25\t = Validation score   (f1_macro)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestGini_BAG_L1 ...\n",
            "\t0.3333\t = Validation score   (f1_macro)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ...\n",
            "\t0.3333\t = Validation score   (f1_macro)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
            "\t0.25\t = Validation score   (f1_macro)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
            "\t0.25\t = Validation score   (f1_macro)\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L1 ...\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ...\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
            "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 526, in _fit_folds\n",
            "    fold_fitting_strategy = fold_fitting_strategy(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 450, in __init__\n",
            "    self.resources, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 635, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/autogluon/core/ray/resources_calculator.py\", line 55, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, \\\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.4\t = Validation score   (f1_macro)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 5.78s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t0.38s\t = Training   runtime\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230201_020828/\")\n",
            "<ipython-input-54-9fe5e5e77a1f>:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  submit_O['Y_Class'] = y_pred\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================learning_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================predictor_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n",
            "==================submission_complete========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pycaret"
      ],
      "metadata": {
        "id": "gJdMn9SDvLSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install --upgrade xgboost\n",
        "!pip install catboost\n",
        "!pip install pycaret\n",
        "!pip install numpy == 1.20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AN-0iggWvMTF",
        "outputId": "920db738-c6a3-42cf-b5a0-69e2e4d0c80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.20.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.5.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (0.90)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.7.3-py3-none-manylinux2014_x86_64.whl (193.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.20.0)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.7.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "xgboost"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from catboost) (1.5.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycaret in /usr/local/lib/python3.8/dist-packages (2.3.10)\n",
            "Requirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: pyyaml<6.0.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (5.4.1)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: mlxtend>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.19.0)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.5.4)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (2.3.9)\n",
            "Requirement already satisfied: imbalanced-learn==0.7.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.3.5)\n",
            "Requirement already satisfied: kmodes>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.12.2)\n",
            "Requirement already satisfied: yellowbrick>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.3.post1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.8/dist-packages (from pycaret) (2.1.1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from pycaret) (7.9.0)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.3.5)\n",
            "Requirement already satisfied: pandas-profiling>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.6.6)\n",
            "Requirement already satisfied: pyod in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.0.7)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.11.2)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.3.7)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.23.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: numba<0.55 in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.54.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.2.0)\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: Boruta in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.3)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pycaret) (3.7)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (from pycaret) (1.8.2.2)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.8/dist-packages (from pycaret) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn==0.7.0->pycaret) (1.20.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==0.23.2->pycaret) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim<4.0.0->pycaret) (6.3.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (5.7.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (0.18.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (5.3.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->pycaret) (3.0.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->pycaret) (0.38.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pycaret) (1.4.4)\n",
            "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba<0.55->pycaret) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->pycaret) (2022.7)\n",
            "Requirement already satisfied: ydata-profiling in /usr/local/lib/python3.8/dist-packages (from pandas-profiling>=2.8.0->pycaret) (4.0.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=4.4.1->pycaret) (8.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (3.0.8)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (1.0.2)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (7.4.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (4.64.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (0.7.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0->pycaret) (2.28.2)\n",
            "Collecting numpy>=1.13.3\n",
            "  Using cached numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.4)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: docker<7,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (6.0.1)\n",
            "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.17.4)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (2.11.3)\n",
            "Requirement already satisfied: alembic<2 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.9.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (3.19.6)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (3.4.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.4.3)\n",
            "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.4.46)\n",
            "Requirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (9.0.0)\n",
            "Requirement already satisfied: packaging<23 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (21.3)\n",
            "Requirement already satisfied: shap<1,>=0.40 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (0.41.0)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (5.2.0)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (2.2.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: gunicorn<21 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (20.1.0)\n",
            "Requirement already satisfied: gitpython<4,>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from mlflow->pycaret) (3.1.30)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->pycaret) (2022.6.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.8/dist-packages (from pyLDAvis->pycaret) (1.18)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.8/dist-packages (from pyLDAvis->pycaret) (2.8.4)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from pyod->pycaret) (0.13.5)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn->pycaret) (0.5.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud->pycaret) (7.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic<2->mlflow->pycaret) (1.2.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic<2->mlflow->pycaret) (5.10.2)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (0.8.10)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->pycaret) (2.6.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from docker<7,>=4.0.0->mlflow->pycaret) (1.5.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.8/dist-packages (from docker<7,>=4.0.0->mlflow->pycaret) (1.26.14)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from gitpython<4,>=2.1.0->mlflow->pycaret) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow->pycaret) (3.11.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (6.1.12)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->pycaret) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow->pycaret) (2.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0->pycaret) (2.10)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow->pycaret) (0.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow->pycaret) (2.0.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.7.16)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->pycaret) (0.7.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.8/dist-packages (from statsmodels->pyod->pycaret) (0.5.3)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.5 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: pydantic<1.11,>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (1.10.4)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (0.1.12)\n",
            "Requirement already satisfied: multimethod<1.10,>=1.4 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (1.9.1)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (0.12.3)\n",
            "Requirement already satisfied: typeguard<2.14,>=2.13.2 in /usr/local/lib/python3.8/dist-packages (from ydata-profiling->pandas-profiling>=2.8.0->pycaret) (2.13.3)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (3.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (22.2.0)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.8/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (4.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow->pycaret) (5.0.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.7.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.13.3)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.15.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic<1.11,>=1.8.1->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (4.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (2.6.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (5.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (1.5.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (2.16.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (from imagehash->visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling>=2.8.0->pycaret) (1.4.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.19.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pycaret) (0.5.1)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.20.0\n",
            "    Uninstalling numpy-1.20.0:\n",
            "      Successfully uninstalled numpy-1.20.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.9 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.19.5\n",
            "\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *"
      ],
      "metadata": {
        "id": "OH15zBM_vkOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['TIMESTAMP'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "wB33JJ6E2gw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setup(silent = True, data = train,target = \"Y_Class\", fold = 10, session_id = 777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90705af242a74678bccabeb5c71240aa",
            "bef970afd94d43d187a73f8c7c262fea",
            "3978fd0064b048b28cb057020fdf082d"
          ]
        },
        "id": "KTCULhJRvoC8",
        "outputId": "1fd9b707-226a-4b77-9fa9-301bb2bb0a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id               777\n",
              "1                                   Target           Y_Class\n",
              "2                              Target Type        Multiclass\n",
              "3                            Label Encoded              None\n",
              "4                            Original Data       (598, 2880)\n",
              "5                           Missing Values              True\n",
              "6                         Numeric Features              1936\n",
              "7                     Categorical Features               941\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set       (418, 3265)\n",
              "12                    Transformed Test Set       (180, 3265)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              e9e6\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44             Remove Perfect Collinearity              True\n",
              "45                              Clustering             False\n",
              "46                    Clustering Iteration              None\n",
              "47                     Polynomial Features             False\n",
              "48                       Polynomial Degree              None\n",
              "49                    Trignometry Features             False\n",
              "50                    Polynomial Threshold              None\n",
              "51                          Group Features             False\n",
              "52                       Feature Selection             False\n",
              "53                Feature Selection Method           classic\n",
              "54            Features Selection Threshold              None\n",
              "55                     Feature Interaction             False\n",
              "56                           Feature Ratio             False\n",
              "57                   Interaction Threshold              None\n",
              "58                           Fix Imbalance             False\n",
              "59                    Fix Imbalance Method             SMOTE"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78c6a9d0-31c3-494b-93f2-36e8ff35046f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Y_Class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Multiclass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(598, 2880)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>1936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(418, 3265)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(180, 3265)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>e9e6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78c6a9d0-31c3-494b-93f2-36e8ff35046f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78c6a9d0-31c3-494b-93f2-36e8ff35046f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78c6a9d0-31c3-494b-93f2-36e8ff35046f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:logs:create_model_container: 0\n",
            "INFO:logs:master_model_container: 0\n",
            "INFO:logs:display_container: 1\n",
            "INFO:logs:Pipeline(memory=None,\n",
            "         steps=[('dtypes',\n",
            "                 DataTypes_Auto_infer(categorical_features=[],\n",
            "                                      display_types=False, features_todrop=[],\n",
            "                                      id_columns=['time'],\n",
            "                                      ml_usecase='classification',\n",
            "                                      numerical_features=[], target='Y_Class',\n",
            "                                      time_features=[])),\n",
            "                ('imputer',\n",
            "                 Simple_Imputer(categorical_strategy='not_available',\n",
            "                                fill_value_categorical=None,\n",
            "                                fill_value_numerical=None,\n",
            "                                numer...\n",
            "                ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
            "                ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
            "                ('cluster_all', 'passthrough'),\n",
            "                ('dummy', Dummify(target='Y_Class')),\n",
            "                ('fix_perfect', Remove_100(target='Y_Class')),\n",
            "                ('clean_names', Clean_Colum_Names()),\n",
            "                ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
            "                ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
            "         verbose=False)\n",
            "INFO:logs:setup() succesfully completed......................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False,\n",
              " -1,\n",
              " False,\n",
              " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x7f6f732ca340>,\n",
              "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x7f6f732d5790>,\n",
              "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x7f6f732ca580>,\n",
              "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x7f6f732caf10>,\n",
              "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x7f6f732cacd0>,\n",
              "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x7f6f7731c520>,\n",
              "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x7f6f77bd4370>,\n",
              "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x7f6f76e57b20>,\n",
              "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x7f6f7614a160>,\n",
              "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x7f6f761472e0>,\n",
              "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x7f6f76142040>,\n",
              "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x7f6f6711f9a0>,\n",
              "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x7f6f732ca5e0>,\n",
              "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x7f6f732ca250>,\n",
              "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x7f6f7617b490>,\n",
              "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x7f6f7616b220>,\n",
              "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x7f6f7617be50>,\n",
              "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x7f6f7616c8e0>,\n",
              "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x7f6f7637d6d0>,\n",
              "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x7f6f7637aca0>,\n",
              "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x7f6f7637ac40>,\n",
              "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x7f6f7637ae50>},\n",
              " False,\n",
              " {'USI',\n",
              "  'X',\n",
              "  'X_test',\n",
              "  'X_train',\n",
              "  '_all_metrics',\n",
              "  '_all_models',\n",
              "  '_all_models_internal',\n",
              "  '_available_plots',\n",
              "  '_gpu_n_jobs_param',\n",
              "  '_internal_pipeline',\n",
              "  '_ml_usecase',\n",
              "  'create_model_container',\n",
              "  'dashboard_logger',\n",
              "  'data_before_preprocess',\n",
              "  'display_container',\n",
              "  'exp_name_log',\n",
              "  'experiment__',\n",
              "  'fix_imbalance_method_param',\n",
              "  'fix_imbalance_param',\n",
              "  'fold_generator',\n",
              "  'fold_groups_param',\n",
              "  'fold_groups_param_full',\n",
              "  'fold_param',\n",
              "  'fold_shuffle_param',\n",
              "  'gpu_param',\n",
              "  'html_param',\n",
              "  'imputation_classifier',\n",
              "  'imputation_regressor',\n",
              "  'iterative_imputation_iters_param',\n",
              "  'log_plots_param',\n",
              "  'logging_param',\n",
              "  'master_model_container',\n",
              "  'n_jobs_param',\n",
              "  'prep_pipe',\n",
              "  'pycaret_globals',\n",
              "  'seed',\n",
              "  'stratify_param',\n",
              "  'target_param',\n",
              "  'transform_target_method_param',\n",
              "  'transform_target_param',\n",
              "  'y',\n",
              "  'y_test',\n",
              "  'y_train'},\n",
              " <MLUsecase.CLASSIFICATION: 1>,\n",
              " None,\n",
              " 485    1\n",
              " 165    1\n",
              " 529    1\n",
              " 253    1\n",
              " 255    0\n",
              "       ..\n",
              " 423    1\n",
              " 116    0\n",
              " 71     1\n",
              " 571    1\n",
              " 103    1\n",
              " Name: Y_Class, Length: 418, dtype: int64,\n",
              "            X_13        X_16        X_17        X_18      X_38       X_40  \\\n",
              " 485  500.100006  247.500000  248.000000  247.300003  0.075000  65.199997   \n",
              " 165  489.500000  247.500000  248.000000  247.500000  0.079000  63.200001   \n",
              " 529  515.000000  247.600006  248.199997  247.300003  0.079000  63.000000   \n",
              " 253  482.700012  247.600006  248.300003  247.300003  0.077000  65.699997   \n",
              " 255  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " ..          ...         ...         ...         ...       ...        ...   \n",
              " 423  493.399994  247.500000  248.000000  247.300003  0.076000  65.199997   \n",
              " 116  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 71   488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 571  492.399994  247.500000  248.100006  247.399994  0.079000  63.200001   \n",
              " 103  478.000000  247.500000  248.100006  247.300003  0.079000  63.200001   \n",
              " \n",
              "           X_41       X_42       X_43       X_44  ...  TIMESTAMP_hour_4  \\\n",
              " 485  66.800003  65.699997  76.800003  72.000000  ...               0.0   \n",
              " 165  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              " 529  64.800003  63.799999  76.400002  68.300003  ...               0.0   \n",
              " 253  66.699997  65.699997  77.300003  72.099998  ...               0.0   \n",
              " 255  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " ..         ...        ...        ...        ...  ...               ...   \n",
              " 423  66.800003  65.699997  76.800003  72.000000  ...               0.0   \n",
              " 116  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 71   65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 571  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              " 103  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_5  TIMESTAMP_hour_6  TIMESTAMP_hour_7  TIMESTAMP_hour_8  \\\n",
              " 485               0.0               0.0               0.0               0.0   \n",
              " 165               0.0               0.0               0.0               0.0   \n",
              " 529               0.0               0.0               0.0               0.0   \n",
              " 253               0.0               1.0               0.0               0.0   \n",
              " 255               0.0               0.0               0.0               0.0   \n",
              " ..                ...               ...               ...               ...   \n",
              " 423               0.0               0.0               0.0               0.0   \n",
              " 116               0.0               0.0               0.0               0.0   \n",
              " 71                0.0               0.0               1.0               0.0   \n",
              " 571               0.0               0.0               0.0               0.0   \n",
              " 103               0.0               0.0               0.0               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_9  LINE_weekday_0  LINE_weekday_1  LINE_is_month_end_0  \\\n",
              " 485               0.0             0.0             1.0                  1.0   \n",
              " 165               0.0             0.0             0.0                  1.0   \n",
              " 529               1.0             0.0             0.0                  1.0   \n",
              " 253               0.0             0.0             1.0                  1.0   \n",
              " 255               0.0             1.0             0.0                  1.0   \n",
              " ..                ...             ...             ...                  ...   \n",
              " 423               0.0             0.0             1.0                  1.0   \n",
              " 116               0.0             1.0             0.0                  1.0   \n",
              " 71                0.0             1.0             0.0                  1.0   \n",
              " 571               0.0             0.0             0.0                  1.0   \n",
              " 103               0.0             0.0             0.0                  1.0   \n",
              " \n",
              "      LINE_is_month_start_0  \n",
              " 485                    1.0  \n",
              " 165                    1.0  \n",
              " 529                    1.0  \n",
              " 253                    1.0  \n",
              " 255                    1.0  \n",
              " ..                     ...  \n",
              " 423                    1.0  \n",
              " 116                    1.0  \n",
              " 71                     1.0  \n",
              " 571                    1.0  \n",
              " 103                    1.0  \n",
              " \n",
              " [418 rows x 3265 columns],\n",
              " StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
              " -1,\n",
              " 10,\n",
              " 777,\n",
              " False,\n",
              " None,\n",
              " [('Setup Config',                                Description             Value\n",
              "   0                               session_id               777\n",
              "   1                                   Target           Y_Class\n",
              "   2                              Target Type        Multiclass\n",
              "   3                            Label Encoded              None\n",
              "   4                            Original Data       (598, 2880)\n",
              "   5                           Missing Values              True\n",
              "   6                         Numeric Features              1936\n",
              "   7                     Categorical Features               941\n",
              "   8                         Ordinal Features             False\n",
              "   9                High Cardinality Features             False\n",
              "   10                 High Cardinality Method              None\n",
              "   11                   Transformed Train Set       (418, 3265)\n",
              "   12                    Transformed Test Set       (180, 3265)\n",
              "   13                      Shuffle Train-Test              True\n",
              "   14                     Stratify Train-Test             False\n",
              "   15                          Fold Generator   StratifiedKFold\n",
              "   16                             Fold Number                10\n",
              "   17                                CPU Jobs                -1\n",
              "   18                                 Use GPU             False\n",
              "   19                          Log Experiment             False\n",
              "   20                         Experiment Name  clf-default-name\n",
              "   21                                     USI              e9e6\n",
              "   22                         Imputation Type            simple\n",
              "   23          Iterative Imputation Iteration              None\n",
              "   24                         Numeric Imputer              mean\n",
              "   25      Iterative Imputation Numeric Model              None\n",
              "   26                     Categorical Imputer          constant\n",
              "   27  Iterative Imputation Categorical Model              None\n",
              "   28           Unknown Categoricals Handling    least_frequent\n",
              "   29                               Normalize             False\n",
              "   30                        Normalize Method              None\n",
              "   31                          Transformation             False\n",
              "   32                   Transformation Method              None\n",
              "   33                                     PCA             False\n",
              "   34                              PCA Method              None\n",
              "   35                          PCA Components              None\n",
              "   36                     Ignore Low Variance             False\n",
              "   37                     Combine Rare Levels             False\n",
              "   38                    Rare Level Threshold              None\n",
              "   39                         Numeric Binning             False\n",
              "   40                         Remove Outliers             False\n",
              "   41                      Outliers Threshold              None\n",
              "   42                Remove Multicollinearity             False\n",
              "   43             Multicollinearity Threshold              None\n",
              "   44             Remove Perfect Collinearity              True\n",
              "   45                              Clustering             False\n",
              "   46                    Clustering Iteration              None\n",
              "   47                     Polynomial Features             False\n",
              "   48                       Polynomial Degree              None\n",
              "   49                    Trignometry Features             False\n",
              "   50                    Polynomial Threshold              None\n",
              "   51                          Group Features             False\n",
              "   52                       Feature Selection             False\n",
              "   53                Feature Selection Method           classic\n",
              "   54            Features Selection Threshold              None\n",
              "   55                     Feature Interaction             False\n",
              "   56                           Feature Ratio             False\n",
              "   57                   Interaction Threshold              None\n",
              "   58                           Fix Imbalance             False\n",
              "   59                    Fix Imbalance Method             SMOTE),\n",
              "  ('X_training Set',\n",
              "              X_13        X_16        X_17        X_18      X_38       X_40  \\\n",
              "   485  500.100006  247.500000  248.000000  247.300003  0.075000  65.199997   \n",
              "   165  489.500000  247.500000  248.000000  247.500000  0.079000  63.200001   \n",
              "   529  515.000000  247.600006  248.199997  247.300003  0.079000  63.000000   \n",
              "   253  482.700012  247.600006  248.300003  247.300003  0.077000  65.699997   \n",
              "   255  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   ..          ...         ...         ...         ...       ...        ...   \n",
              "   423  493.399994  247.500000  248.000000  247.300003  0.076000  65.199997   \n",
              "   116  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   71   488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   571  492.399994  247.500000  248.100006  247.399994  0.079000  63.200001   \n",
              "   103  478.000000  247.500000  248.100006  247.300003  0.079000  63.200001   \n",
              "   \n",
              "             X_41       X_42       X_43       X_44  ...  TIMESTAMP_hour_4  \\\n",
              "   485  66.800003  65.699997  76.800003  72.000000  ...               0.0   \n",
              "   165  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              "   529  64.800003  63.799999  76.400002  68.300003  ...               0.0   \n",
              "   253  66.699997  65.699997  77.300003  72.099998  ...               0.0   \n",
              "   255  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   ..         ...        ...        ...        ...  ...               ...   \n",
              "   423  66.800003  65.699997  76.800003  72.000000  ...               0.0   \n",
              "   116  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   71   65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   571  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              "   103  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              "   \n",
              "        TIMESTAMP_hour_5  TIMESTAMP_hour_6  TIMESTAMP_hour_7  TIMESTAMP_hour_8  \\\n",
              "   485               0.0               0.0               0.0               0.0   \n",
              "   165               0.0               0.0               0.0               0.0   \n",
              "   529               0.0               0.0               0.0               0.0   \n",
              "   253               0.0               1.0               0.0               0.0   \n",
              "   255               0.0               0.0               0.0               0.0   \n",
              "   ..                ...               ...               ...               ...   \n",
              "   423               0.0               0.0               0.0               0.0   \n",
              "   116               0.0               0.0               0.0               0.0   \n",
              "   71                0.0               0.0               1.0               0.0   \n",
              "   571               0.0               0.0               0.0               0.0   \n",
              "   103               0.0               0.0               0.0               0.0   \n",
              "   \n",
              "        TIMESTAMP_hour_9  LINE_weekday_0  LINE_weekday_1  LINE_is_month_end_0  \\\n",
              "   485               0.0             0.0             1.0                  1.0   \n",
              "   165               0.0             0.0             0.0                  1.0   \n",
              "   529               1.0             0.0             0.0                  1.0   \n",
              "   253               0.0             0.0             1.0                  1.0   \n",
              "   255               0.0             1.0             0.0                  1.0   \n",
              "   ..                ...             ...             ...                  ...   \n",
              "   423               0.0             0.0             1.0                  1.0   \n",
              "   116               0.0             1.0             0.0                  1.0   \n",
              "   71                0.0             1.0             0.0                  1.0   \n",
              "   571               0.0             0.0             0.0                  1.0   \n",
              "   103               0.0             0.0             0.0                  1.0   \n",
              "   \n",
              "        LINE_is_month_start_0  \n",
              "   485                    1.0  \n",
              "   165                    1.0  \n",
              "   529                    1.0  \n",
              "   253                    1.0  \n",
              "   255                    1.0  \n",
              "   ..                     ...  \n",
              "   423                    1.0  \n",
              "   116                    1.0  \n",
              "   71                     1.0  \n",
              "   571                    1.0  \n",
              "   103                    1.0  \n",
              "   \n",
              "   [418 rows x 3265 columns]),\n",
              "  ('y_training Set', 485    1\n",
              "   165    1\n",
              "   529    1\n",
              "   253    1\n",
              "   255    0\n",
              "         ..\n",
              "   423    1\n",
              "   116    0\n",
              "   71     1\n",
              "   571    1\n",
              "   103    1\n",
              "   Name: Y_Class, Length: 418, dtype: int64),\n",
              "  ('X_test Set',\n",
              "              X_13        X_16        X_17        X_18      X_38       X_40  \\\n",
              "   546  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   401  503.299988  247.500000  248.100006  247.300003  0.079000  63.000000   \n",
              "   564  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   393  493.200012  247.600006  248.000000  247.300003  0.076000  65.199997   \n",
              "   262  496.799988  247.600006  248.100006  247.399994  0.079000  63.200001   \n",
              "   ..          ...         ...         ...         ...       ...        ...   \n",
              "   283  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   305  496.799988  247.600006  248.199997  247.399994  0.079000  63.200001   \n",
              "   166  489.799988  247.500000  248.300003  247.199997  0.079000  63.200001   \n",
              "   65   488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              "   373  488.799988  247.500000  248.100006  247.300003  0.075000  65.199997   \n",
              "   \n",
              "             X_41       X_42       X_43       X_44  ...  TIMESTAMP_hour_4  \\\n",
              "   546  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   401  64.099998  63.700001  76.500000  68.900002  ...               0.0   \n",
              "   564  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   393  66.900002  65.599998  76.800003  72.000000  ...               0.0   \n",
              "   262  63.500000  64.099998  78.099998  69.000000  ...               0.0   \n",
              "   ..         ...        ...        ...        ...  ...               ...   \n",
              "   283  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   305  64.099998  63.700001  77.500000  68.900002  ...               0.0   \n",
              "   166  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              "   65   65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              "   373  66.900002  65.599998  76.800003  72.000000  ...               0.0   \n",
              "   \n",
              "        TIMESTAMP_hour_5  TIMESTAMP_hour_6  TIMESTAMP_hour_7  TIMESTAMP_hour_8  \\\n",
              "   546               0.0               0.0               0.0               0.0   \n",
              "   401               0.0               0.0               0.0               0.0   \n",
              "   564               0.0               0.0               0.0               0.0   \n",
              "   393               0.0               0.0               0.0               0.0   \n",
              "   262               0.0               0.0               0.0               1.0   \n",
              "   ..                ...               ...               ...               ...   \n",
              "   283               0.0               0.0               0.0               0.0   \n",
              "   305               0.0               1.0               0.0               0.0   \n",
              "   166               0.0               0.0               0.0               0.0   \n",
              "   65                0.0               0.0               0.0               0.0   \n",
              "   373               0.0               0.0               0.0               0.0   \n",
              "   \n",
              "        TIMESTAMP_hour_9  LINE_weekday_0  LINE_weekday_1  LINE_is_month_end_0  \\\n",
              "   546               0.0             0.0             0.0                  1.0   \n",
              "   401               0.0             0.0             0.0                  1.0   \n",
              "   564               0.0             1.0             0.0                  1.0   \n",
              "   393               0.0             0.0             1.0                  1.0   \n",
              "   262               0.0             0.0             0.0                  1.0   \n",
              "   ..                ...             ...             ...                  ...   \n",
              "   283               0.0             1.0             0.0                  1.0   \n",
              "   305               0.0             0.0             0.0                  1.0   \n",
              "   166               1.0             0.0             0.0                  1.0   \n",
              "   65                0.0             1.0             0.0                  1.0   \n",
              "   373               0.0             0.0             1.0                  1.0   \n",
              "   \n",
              "        LINE_is_month_start_0  \n",
              "   546                    1.0  \n",
              "   401                    1.0  \n",
              "   564                    1.0  \n",
              "   393                    1.0  \n",
              "   262                    1.0  \n",
              "   ..                     ...  \n",
              "   283                    1.0  \n",
              "   305                    1.0  \n",
              "   166                    1.0  \n",
              "   65                     1.0  \n",
              "   373                    1.0  \n",
              "   \n",
              "   [180 rows x 3265 columns]),\n",
              "  ('y_test Set', 546    0\n",
              "   401    1\n",
              "   564    2\n",
              "   393    1\n",
              "   262    2\n",
              "         ..\n",
              "   283    2\n",
              "   305    1\n",
              "   166    1\n",
              "   65     1\n",
              "   373    1\n",
              "   Name: Y_Class, Length: 180, dtype: int64),\n",
              "  ('Transformation Pipeline', Pipeline(memory=None,\n",
              "            steps=[('dtypes',\n",
              "                    DataTypes_Auto_infer(categorical_features=[],\n",
              "                                         display_types=False, features_todrop=[],\n",
              "                                         id_columns=['time'],\n",
              "                                         ml_usecase='classification',\n",
              "                                         numerical_features=[], target='Y_Class',\n",
              "                                         time_features=[])),\n",
              "                   ('imputer',\n",
              "                    Simple_Imputer(categorical_strategy='not_available',\n",
              "                                   fill_value_categorical=None,\n",
              "                                   fill_value_numerical=None,\n",
              "                                   numer...\n",
              "                   ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
              "                   ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
              "                   ('cluster_all', 'passthrough'),\n",
              "                   ('dummy', Dummify(target='Y_Class')),\n",
              "                   ('fix_perfect', Remove_100(target='Y_Class')),\n",
              "                   ('clean_names', Clean_Colum_Names()),\n",
              "                   ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
              "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
              "            verbose=False))],\n",
              "            X_13        X_16        X_17        X_18      X_38       X_40  \\\n",
              " 0    488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 1    488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 2    488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 3    488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 4    488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " ..          ...         ...         ...         ...       ...        ...   \n",
              " 593  459.200012  247.500000  248.000000  247.300003  0.075000  67.199997   \n",
              " 594  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 595  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 596  497.100006  247.500000  248.100006  247.300003  0.078000  63.700001   \n",
              " 597  462.899994  247.500000  248.000000  247.300003  0.077000  67.199997   \n",
              " \n",
              "           X_41       X_42       X_43       X_44  ...  TIMESTAMP_hour_4  \\\n",
              " 0    65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 1    65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 2    65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 3    65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 4    65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " ..         ...        ...        ...        ...  ...               ...   \n",
              " 593  68.900002  67.500000  79.800003  70.900002  ...               0.0   \n",
              " 594  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 595  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 596  64.599998  64.699997  78.599998  69.000000  ...               0.0   \n",
              " 597  68.900002  67.500000  79.800003  70.900002  ...               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_5  TIMESTAMP_hour_6  TIMESTAMP_hour_7  TIMESTAMP_hour_8  \\\n",
              " 0                 1.0               0.0               0.0               0.0   \n",
              " 1                 1.0               0.0               0.0               0.0   \n",
              " 2                 1.0               0.0               0.0               0.0   \n",
              " 3                 1.0               0.0               0.0               0.0   \n",
              " 4                 1.0               0.0               0.0               0.0   \n",
              " ..                ...               ...               ...               ...   \n",
              " 593               0.0               0.0               0.0               0.0   \n",
              " 594               0.0               0.0               0.0               0.0   \n",
              " 595               0.0               0.0               0.0               0.0   \n",
              " 596               0.0               0.0               0.0               0.0   \n",
              " 597               0.0               0.0               0.0               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_9  LINE_weekday_0  LINE_weekday_1  LINE_is_month_end_0  \\\n",
              " 0                 0.0             1.0             0.0                  1.0   \n",
              " 1                 0.0             0.0             0.0                  1.0   \n",
              " 2                 0.0             1.0             0.0                  1.0   \n",
              " 3                 0.0             0.0             0.0                  1.0   \n",
              " 4                 0.0             1.0             0.0                  1.0   \n",
              " ..                ...             ...             ...                  ...   \n",
              " 593               0.0             0.0             1.0                  1.0   \n",
              " 594               0.0             1.0             0.0                  1.0   \n",
              " 595               0.0             1.0             0.0                  1.0   \n",
              " 596               0.0             0.0             0.0                  1.0   \n",
              " 597               0.0             0.0             1.0                  1.0   \n",
              " \n",
              "      LINE_is_month_start_0  \n",
              " 0                      1.0  \n",
              " 1                      1.0  \n",
              " 2                      1.0  \n",
              " 3                      1.0  \n",
              " 4                      1.0  \n",
              " ..                     ...  \n",
              " 593                    1.0  \n",
              " 594                    1.0  \n",
              " 595                    1.0  \n",
              " 596                    1.0  \n",
              " 597                    1.0  \n",
              " \n",
              " [598 rows x 3265 columns],\n",
              " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x7f6f732e0c10>,\n",
              "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x7f6f732e0b50>,\n",
              "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x7f6f732e0580>,\n",
              "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x7f6f732f3310>,\n",
              "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x7f6f732f3250>,\n",
              "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x7f6f765b6880>,\n",
              "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x7f6f814bad60>,\n",
              "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x7f6f732ec190>,\n",
              "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x7f6f732ec910>,\n",
              "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x7f6f732eca90>,\n",
              "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x7f6f76f15bb0>,\n",
              "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x7f6f7264ba30>,\n",
              "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x7f6f78206a60>,\n",
              "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x7f6f77fd97f0>,\n",
              "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x7f6f732e2850>,\n",
              "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x7f6f732d53a0>,\n",
              "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x7f6f732e2340>,\n",
              "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x7f6f7813ea60>},\n",
              " 'lightgbm',\n",
              " 'e9e6',\n",
              " Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False),\n",
              " False,\n",
              " {'parameter': 'Hyperparameters',\n",
              "  'auc': 'AUC',\n",
              "  'confusion_matrix': 'Confusion Matrix',\n",
              "  'threshold': 'Threshold',\n",
              "  'pr': 'Precision Recall',\n",
              "  'error': 'Prediction Error',\n",
              "  'class_report': 'Class Report',\n",
              "  'rfe': 'Feature Selection',\n",
              "  'learning': 'Learning Curve',\n",
              "  'manifold': 'Manifold Learning',\n",
              "  'calibration': 'Calibration Curve',\n",
              "  'vc': 'Validation Curve',\n",
              "  'dimension': 'Dimensions',\n",
              "  'feature': 'Feature Importance',\n",
              "  'feature_all': 'Feature Importance (All)',\n",
              "  'boundary': 'Decision Boundary',\n",
              "  'lift': 'Lift Chart',\n",
              "  'gain': 'Gain Chart',\n",
              "  'tree': 'Decision Tree',\n",
              "  'ks': 'KS Statistic Plot'},\n",
              " False,\n",
              " None,\n",
              " [],\n",
              " {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x7f6f7637aaf0>,\n",
              "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x7f6f7637a190>,\n",
              "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x7f6f76378ca0>,\n",
              "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x7f6f76378730>,\n",
              "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x7f6f76376580>,\n",
              "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x7f6f76373ac0>,\n",
              "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x7f6f76373100>},\n",
              " None,\n",
              " 546    0\n",
              " 401    1\n",
              " 564    2\n",
              " 393    1\n",
              " 262    2\n",
              "       ..\n",
              " 283    2\n",
              " 305    1\n",
              " 166    1\n",
              " 65     1\n",
              " 373    1\n",
              " Name: Y_Class, Length: 180, dtype: int64,\n",
              " [],\n",
              " False,\n",
              " 0      1\n",
              " 1      2\n",
              " 2      1\n",
              " 3      2\n",
              " 4      1\n",
              "       ..\n",
              " 593    1\n",
              " 594    0\n",
              " 595    0\n",
              " 596    1\n",
              " 597    1\n",
              " Name: Y_Class, Length: 598, dtype: int64,\n",
              "            X_13        X_16        X_17        X_18      X_38       X_40  \\\n",
              " 546  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 401  503.299988  247.500000  248.100006  247.300003  0.079000  63.000000   \n",
              " 564  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 393  493.200012  247.600006  248.000000  247.300003  0.076000  65.199997   \n",
              " 262  496.799988  247.600006  248.100006  247.399994  0.079000  63.200001   \n",
              " ..          ...         ...         ...         ...       ...        ...   \n",
              " 283  488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 305  496.799988  247.600006  248.199997  247.399994  0.079000  63.200001   \n",
              " 166  489.799988  247.500000  248.300003  247.199997  0.079000  63.200001   \n",
              " 65   488.107544  247.539688  248.065872  247.311508  0.077365  64.478973   \n",
              " 373  488.799988  247.500000  248.100006  247.300003  0.075000  65.199997   \n",
              " \n",
              "           X_41       X_42       X_43       X_44  ...  TIMESTAMP_hour_4  \\\n",
              " 546  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 401  64.099998  63.700001  76.500000  68.900002  ...               0.0   \n",
              " 564  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 393  66.900002  65.599998  76.800003  72.000000  ...               0.0   \n",
              " 262  63.500000  64.099998  78.099998  69.000000  ...               0.0   \n",
              " ..         ...        ...        ...        ...  ...               ...   \n",
              " 283  65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 305  64.099998  63.700001  77.500000  68.900002  ...               0.0   \n",
              " 166  63.500000  64.099998  78.599998  68.599998  ...               0.0   \n",
              " 65   65.554764  65.006355  77.659927  70.297623  ...               0.0   \n",
              " 373  66.900002  65.599998  76.800003  72.000000  ...               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_5  TIMESTAMP_hour_6  TIMESTAMP_hour_7  TIMESTAMP_hour_8  \\\n",
              " 546               0.0               0.0               0.0               0.0   \n",
              " 401               0.0               0.0               0.0               0.0   \n",
              " 564               0.0               0.0               0.0               0.0   \n",
              " 393               0.0               0.0               0.0               0.0   \n",
              " 262               0.0               0.0               0.0               1.0   \n",
              " ..                ...               ...               ...               ...   \n",
              " 283               0.0               0.0               0.0               0.0   \n",
              " 305               0.0               1.0               0.0               0.0   \n",
              " 166               0.0               0.0               0.0               0.0   \n",
              " 65                0.0               0.0               0.0               0.0   \n",
              " 373               0.0               0.0               0.0               0.0   \n",
              " \n",
              "      TIMESTAMP_hour_9  LINE_weekday_0  LINE_weekday_1  LINE_is_month_end_0  \\\n",
              " 546               0.0             0.0             0.0                  1.0   \n",
              " 401               0.0             0.0             0.0                  1.0   \n",
              " 564               0.0             1.0             0.0                  1.0   \n",
              " 393               0.0             0.0             1.0                  1.0   \n",
              " 262               0.0             0.0             0.0                  1.0   \n",
              " ..                ...             ...             ...                  ...   \n",
              " 283               0.0             1.0             0.0                  1.0   \n",
              " 305               0.0             0.0             0.0                  1.0   \n",
              " 166               1.0             0.0             0.0                  1.0   \n",
              " 65                0.0             1.0             0.0                  1.0   \n",
              " 373               0.0             0.0             1.0                  1.0   \n",
              " \n",
              "      LINE_is_month_start_0  \n",
              " 546                    1.0  \n",
              " 401                    1.0  \n",
              " 564                    1.0  \n",
              " 393                    1.0  \n",
              " 262                    1.0  \n",
              " ..                     ...  \n",
              " 283                    1.0  \n",
              " 305                    1.0  \n",
              " 166                    1.0  \n",
              " 65                     1.0  \n",
              " 373                    1.0  \n",
              " \n",
              " [180 rows x 3265 columns],\n",
              " True,\n",
              "      Y_Class         TIMESTAMP     LINE PRODUCT_CODE   X_1   X_2  X_3   X_4  \\\n",
              " 0          1   2022-06-13 5:14  T050304         A_31   NaN   NaN  NaN   NaN   \n",
              " 1          2   2022-06-13 5:22  T050307         A_31   NaN   NaN  NaN   NaN   \n",
              " 2          1   2022-06-13 5:30  T050304         A_31   NaN   NaN  NaN   NaN   \n",
              " 3          2   2022-06-13 5:39  T050307         A_31   NaN   NaN  NaN   NaN   \n",
              " 4          1   2022-06-13 5:47  T050304         A_31   NaN   NaN  NaN   NaN   \n",
              " ..       ...               ...      ...          ...   ...   ...  ...   ...   \n",
              " 593        1  2022-09-08 14:30  T100306         T_31   2.0  95.0  0.0  45.0   \n",
              " 594        0  2022-09-08 22:38  T050304         A_31   NaN   NaN  NaN   NaN   \n",
              " 595        0  2022-09-08 22:47  T050304         A_31   NaN   NaN  NaN   NaN   \n",
              " 596        1  2022-09-08 14:38  T100304         O_31  40.0  94.0  0.0  45.0   \n",
              " 597        1  2022-09-08 14:46  T100306         O_31  21.0  87.0  0.0  45.0   \n",
              " \n",
              "       X_5  X_6  ...  X_2867  X_2868  X_2869  X_2870  X_2871  X_2872  X_2873  \\\n",
              " 0     NaN  NaN  ...   40.89   32.56   34.09   77.77     NaN     NaN     NaN   \n",
              " 1     NaN  NaN  ...   42.82   43.92   35.34   72.55     NaN     NaN     NaN   \n",
              " 2     NaN  NaN  ...   36.65   42.47   36.53   78.35     NaN     NaN     NaN   \n",
              " 3     NaN  NaN  ...   39.17   52.17   30.58   71.78     NaN     NaN     NaN   \n",
              " 4     NaN  NaN  ...   41.89   46.93   33.09   76.97     NaN     NaN     NaN   \n",
              " ..    ...  ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              " 593  10.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              " 594   NaN  NaN  ...   53.07   50.89   55.10   66.49     1.0     NaN     NaN   \n",
              " 595   NaN  NaN  ...     NaN     NaN     NaN     NaN     1.0     NaN     NaN   \n",
              " 596  11.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              " 597  10.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              " \n",
              "      X_2874  X_2875  time  \n",
              " 0       NaN     NaN     0  \n",
              " 1       NaN     NaN     1  \n",
              " 2       NaN     NaN     2  \n",
              " 3       NaN     NaN     3  \n",
              " 4       NaN     NaN     4  \n",
              " ..      ...     ...   ...  \n",
              " 593     NaN     NaN   593  \n",
              " 594     NaN     NaN   594  \n",
              " 595     NaN     NaN   595  \n",
              " 596     NaN     NaN   596  \n",
              " 597     NaN     NaN   597  \n",
              " \n",
              " [598 rows x 2880 columns],\n",
              " 'Y_Class',\n",
              " 'lightgbm',\n",
              " [<pandas.io.formats.style.Styler at 0x7f6f76166520>],\n",
              " 'box-cox',\n",
              " 5,\n",
              " Pipeline(memory=None,\n",
              "          steps=[('dtypes',\n",
              "                  DataTypes_Auto_infer(categorical_features=[],\n",
              "                                       display_types=False, features_todrop=[],\n",
              "                                       id_columns=['time'],\n",
              "                                       ml_usecase='classification',\n",
              "                                       numerical_features=[], target='Y_Class',\n",
              "                                       time_features=[])),\n",
              "                 ('imputer',\n",
              "                  Simple_Imputer(categorical_strategy='not_available',\n",
              "                                 fill_value_categorical=None,\n",
              "                                 fill_value_numerical=None,\n",
              "                                 numer...\n",
              "                 ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
              "                 ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
              "                 ('cluster_all', 'passthrough'),\n",
              "                 ('dummy', Dummify(target='Y_Class')),\n",
              "                 ('fix_perfect', Remove_100(target='Y_Class')),\n",
              "                 ('clean_names', Clean_Colum_Names()),\n",
              "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
              "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
              "          verbose=False),\n",
              " 'clf-default-name')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bm = compare_models(sort = 'f1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672,
          "referenced_widgets": [
            "fc31326a2587491997e3dc0ce4445cde",
            "f55964cd4efb4d6da0c2586f8f5c3064",
            "316449f01a664c74b6309883063ad3d0"
          ]
        },
        "id": "JnOHvKhhv9hd",
        "outputId": "b11e986c-7859-4d07-9da2-8f8d0f617e5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "lightgbm  Light Gradient Boosting Machine    0.7798  0.7462  0.5976  0.7759   \n",
              "gbc          Gradient Boosting Classifier    0.7631  0.7560  0.5789  0.7576   \n",
              "lda          Linear Discriminant Analysis    0.7656  0.7227  0.5731  0.7559   \n",
              "et                 Extra Trees Classifier    0.7681  0.7435  0.5511  0.7608   \n",
              "rf               Random Forest Classifier    0.7632  0.7647  0.5477  0.7457   \n",
              "knn                K Neighbors Classifier    0.7297  0.7235  0.5193  0.7165   \n",
              "nb                            Naive Bayes    0.6623  0.7208  0.5338  0.6928   \n",
              "lr                    Logistic Regression    0.7130  0.6474  0.4638  0.6632   \n",
              "dt               Decision Tree Classifier    0.6533  0.6554  0.5302  0.6727   \n",
              "ada                  Ada Boost Classifier    0.7130  0.6248  0.4481  0.6441   \n",
              "ridge                    Ridge Classifier    0.7081  0.0000  0.3927  0.6261   \n",
              "svm                   SVM - Linear Kernel    0.6793  0.0000  0.3514  0.5176   \n",
              "dummy                    Dummy Classifier    0.6914  0.5000  0.3333  0.4781   \n",
              "qda       Quadratic Discriminant Analysis    0.6341  0.4750  0.3319  0.5229   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "lightgbm  0.7573  0.4584  0.4824     1.180  \n",
              "gbc       0.7389  0.4243  0.4461     6.685  \n",
              "lda       0.7366  0.4091  0.4369     0.327  \n",
              "et        0.7327  0.3997  0.4381     0.291  \n",
              "rf        0.7302  0.3891  0.4219     0.317  \n",
              "knn       0.7030  0.3463  0.3682     0.141  \n",
              "nb        0.6727  0.3260  0.3291     0.061  \n",
              "lr        0.6675  0.2547  0.2843     3.685  \n",
              "dt        0.6566  0.2957  0.3003     0.153  \n",
              "ada       0.6500  0.2059  0.2426     0.544  \n",
              "ridge     0.6211  0.1317  0.1942     0.059  \n",
              "svm       0.5751  0.0383  0.0555     0.187  \n",
              "dummy     0.5653  0.0000  0.0000     0.227  \n",
              "qda       0.5594 -0.0136 -0.0192     0.164  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e6366bb-3f1a-4aa6-8717-86e7fabcd31e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.7798</td>\n",
              "      <td>0.7462</td>\n",
              "      <td>0.5976</td>\n",
              "      <td>0.7759</td>\n",
              "      <td>0.7573</td>\n",
              "      <td>0.4584</td>\n",
              "      <td>0.4824</td>\n",
              "      <td>1.180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.7631</td>\n",
              "      <td>0.7560</td>\n",
              "      <td>0.5789</td>\n",
              "      <td>0.7576</td>\n",
              "      <td>0.7389</td>\n",
              "      <td>0.4243</td>\n",
              "      <td>0.4461</td>\n",
              "      <td>6.685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.7656</td>\n",
              "      <td>0.7227</td>\n",
              "      <td>0.5731</td>\n",
              "      <td>0.7559</td>\n",
              "      <td>0.7366</td>\n",
              "      <td>0.4091</td>\n",
              "      <td>0.4369</td>\n",
              "      <td>0.327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.7681</td>\n",
              "      <td>0.7435</td>\n",
              "      <td>0.5511</td>\n",
              "      <td>0.7608</td>\n",
              "      <td>0.7327</td>\n",
              "      <td>0.3997</td>\n",
              "      <td>0.4381</td>\n",
              "      <td>0.291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.7632</td>\n",
              "      <td>0.7647</td>\n",
              "      <td>0.5477</td>\n",
              "      <td>0.7457</td>\n",
              "      <td>0.7302</td>\n",
              "      <td>0.3891</td>\n",
              "      <td>0.4219</td>\n",
              "      <td>0.317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.7297</td>\n",
              "      <td>0.7235</td>\n",
              "      <td>0.5193</td>\n",
              "      <td>0.7165</td>\n",
              "      <td>0.7030</td>\n",
              "      <td>0.3463</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.6623</td>\n",
              "      <td>0.7208</td>\n",
              "      <td>0.5338</td>\n",
              "      <td>0.6928</td>\n",
              "      <td>0.6727</td>\n",
              "      <td>0.3260</td>\n",
              "      <td>0.3291</td>\n",
              "      <td>0.061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.7130</td>\n",
              "      <td>0.6474</td>\n",
              "      <td>0.4638</td>\n",
              "      <td>0.6632</td>\n",
              "      <td>0.6675</td>\n",
              "      <td>0.2547</td>\n",
              "      <td>0.2843</td>\n",
              "      <td>3.685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.6533</td>\n",
              "      <td>0.6554</td>\n",
              "      <td>0.5302</td>\n",
              "      <td>0.6727</td>\n",
              "      <td>0.6566</td>\n",
              "      <td>0.2957</td>\n",
              "      <td>0.3003</td>\n",
              "      <td>0.153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.7130</td>\n",
              "      <td>0.6248</td>\n",
              "      <td>0.4481</td>\n",
              "      <td>0.6441</td>\n",
              "      <td>0.6500</td>\n",
              "      <td>0.2059</td>\n",
              "      <td>0.2426</td>\n",
              "      <td>0.544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7081</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3927</td>\n",
              "      <td>0.6261</td>\n",
              "      <td>0.6211</td>\n",
              "      <td>0.1317</td>\n",
              "      <td>0.1942</td>\n",
              "      <td>0.059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.6793</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3514</td>\n",
              "      <td>0.5176</td>\n",
              "      <td>0.5751</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dummy</th>\n",
              "      <td>Dummy Classifier</td>\n",
              "      <td>0.6914</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.4781</td>\n",
              "      <td>0.5653</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.6341</td>\n",
              "      <td>0.4750</td>\n",
              "      <td>0.3319</td>\n",
              "      <td>0.5229</td>\n",
              "      <td>0.5594</td>\n",
              "      <td>-0.0136</td>\n",
              "      <td>-0.0192</td>\n",
              "      <td>0.164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e6366bb-3f1a-4aa6-8717-86e7fabcd31e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e6366bb-3f1a-4aa6-8717-86e7fabcd31e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e6366bb-3f1a-4aa6-8717-86e7fabcd31e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:logs:create_model_container: 14\n",
            "INFO:logs:master_model_container: 14\n",
            "INFO:logs:display_container: 2\n",
            "INFO:logs:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=777, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
            "INFO:logs:compare_models() succesfully completed......................................\n"
          ]
        }
      ]
    }
  ]
}