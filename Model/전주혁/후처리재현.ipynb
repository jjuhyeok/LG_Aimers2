{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from category_encoders import OneHotEncoder\n",
        "import warnings\n",
        "import random\n",
        "import os\n",
        "plt.style.use('ggplot')\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "SWaMm7uplya4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/test.csv')"
      ],
      "metadata": {
        "id": "Z_lIBWa2l0W3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(37) # Seed 고정"
      ],
      "metadata": {
        "id": "nXofy_g5tX3P"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_list = train.columns\n",
        "nan_list = []\n",
        "nan_cnt = []\n",
        "nan_col = []\n",
        "full_list = []\n",
        "for col in col_list:\n",
        "    if train[col].isnull().sum() == 0 :\n",
        "        full_list.append(col)\n",
        "        continue\n",
        "    nan_list.append([col, train[col].isnull().sum()])\n",
        "    nan_cnt.append(train[col].isnull().sum())\n",
        "    nan_col.append(col)\n",
        "    \n",
        "'''모든값이 결측값이면 제거'''\n",
        "del_col = []\n",
        "for col in nan_list :\n",
        "    if col[1] == 598 :\n",
        "        del_col.append(col[0])\n",
        "train = train.drop(columns=del_col)\n",
        "test = test.drop(columns=del_col)\n",
        "\n",
        "\n",
        "\n",
        "trainA_31 = train[train['PRODUCT_CODE']=='A_31']\n",
        "train_T_31 = train[train['PRODUCT_CODE']=='T_31']\n",
        "train_O_31 = train[train['PRODUCT_CODE']=='O_31']\n",
        "\n",
        "testA_31 = test[test['PRODUCT_CODE']=='A_31']\n",
        "test_T_31 = test[test['PRODUCT_CODE']=='T_31']\n",
        "test_O_31 = test[test['PRODUCT_CODE']=='O_31']\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listA_31 = []\n",
        "nan_cntA_31 = []\n",
        "nan_colA_31 = []\n",
        "full_listA_31 = []\n",
        "for col in col_list:\n",
        "    if trainA_31[col].isnull().sum() == 0 :\n",
        "        full_listA_31.append(col)\n",
        "        continue\n",
        "    nan_listA_31.append([col, trainA_31[col].isnull().sum()])\n",
        "    nan_cntA_31.append(trainA_31[col].isnull().sum())\n",
        "    nan_colA_31.append(col)\n",
        "    \n",
        "'''모든값이 결측값이면 제거'''\n",
        "del_col = []\n",
        "for col in nan_listA_31 :\n",
        "    if col[1] == len(trainA_31) :\n",
        "        del_col.append(col[0])\n",
        "trainA_31 = trainA_31.drop(columns=del_col)\n",
        "testA_31 = testA_31.drop(columns=del_col)\n",
        "\n",
        "'''값이 1개 존재하면 제거'''\n",
        "del_col = []\n",
        "col_list = trainA_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if trainA_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "trainA_31 = trainA_31.drop(columns=del_col)\n",
        "testA_31 = testA_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listO = []\n",
        "nan_cntO = []\n",
        "nan_colO = []\n",
        "full_listO = []\n",
        "for col in col_list:\n",
        "    if train_O_31[col].isnull().sum() == 0 :\n",
        "        full_listO.append(col)\n",
        "        continue\n",
        "    nan_listO.append([col, train_O_31[col].isnull().sum()])\n",
        "    nan_cntO.append(train_O_31[col].isnull().sum())\n",
        "    nan_colO.append(col)\n",
        "    \n",
        "'''모든값이 결측값이면 제거'''\n",
        "del_col = []\n",
        "for col in nan_listO :\n",
        "    if col[1] == len(train_O_31) :\n",
        "        del_col.append(col[0])\n",
        "train_O_31 = train_O_31.drop(columns=del_col)\n",
        "test_O_31 = test_O_31.drop(columns=del_col)\n",
        "\n",
        "'''값이 1개 존재하면 제거'''\n",
        "del_col = []\n",
        "col_list = train_O_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if train_O_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "train_O_31 = train_O_31.drop(columns=del_col)\n",
        "test_O_31 = test_O_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listT = []\n",
        "nan_cntT = []\n",
        "nan_colT = []\n",
        "full_listT = []\n",
        "for col in col_list:\n",
        "    if train_T_31[col].isnull().sum() == 0 :\n",
        "        full_listT.append(col)\n",
        "        continue\n",
        "    nan_listT.append([col, train_T_31[col].isnull().sum()])\n",
        "    nan_cntT.append(train_T_31[col].isnull().sum())\n",
        "    nan_colT.append(col)\n",
        "    \n",
        "'''모든값이 결측값이면 제거'''\n",
        "del_col = []\n",
        "for col in nan_listT :\n",
        "    if col[1] == len(train_T_31) :\n",
        "        del_col.append(col[0])\n",
        "train_T_31 = train_T_31.drop(columns=del_col)\n",
        "test_T_31 = test_T_31.drop(columns=del_col)\n",
        "\n",
        "'''값이 1개 존재하면 제거'''\n",
        "del_col = []\n",
        "col_list = train_T_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if train_T_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "train_T_31 = train_T_31.drop(columns=del_col)\n",
        "test_T_31 = test_T_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "trainA_31_x = trainA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
        "testA_31_x = testA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_T_31_x = train_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','Y_Class','Y_Quality','PRODUCT_CODE'])\n",
        "test_T_31_x = test_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_O_31_x = train_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
        "test_O_31_x = test_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "\n",
        "# classification\n",
        "trainA_31_y_c = trainA_31['Y_Class']\n",
        "train_T_31_y_c = train_T_31['Y_Class']\n",
        "train_O_31_y_c = train_O_31['Y_Class']\n",
        "\n",
        "# regression\n",
        "trainA_31_y_r = trainA_31['Y_Quality']\n",
        "train_T_31_y_r = train_T_31['Y_Quality']\n",
        "train_O_31_y_r = train_O_31['Y_Quality']\n",
        "\n",
        "trainA_31_x=trainA_31_x.fillna(-1)\n",
        "testA_31_x=testA_31_x.fillna(-1)\n",
        "train_T_31_x=train_T_31_x.fillna(-1)\n",
        "test_T_31_x=test_T_31_x.fillna(-1)\n",
        "train_O_31_x=train_O_31_x.fillna(-1)\n",
        "test_O_31_x=test_O_31_x.fillna(-1)\n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(trainA_31_x[i])\n",
        "    trainA_31_x[i] = le.transform(trainA_31_x[i])\n",
        "    \n",
        "    for label in np.unique(testA_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    testA_31_x[i] = le.transform(testA_31_x[i]) \n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_T_31_x[i])\n",
        "    train_T_31_x[i] = le.transform(train_T_31_x[i])\n",
        "    \n",
        "    for label in np.unique(test_T_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_T_31_x[i] = le.transform(test_T_31_x[i]) \n",
        "\n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_O_31_x[i])\n",
        "    train_O_31_x[i] = le.transform(train_O_31_x[i])\n",
        "    \n",
        "    for label in np.unique(test_O_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_O_31_x[i] = le.transform(test_O_31_x[i]) \n"
      ],
      "metadata": {
        "id": "qGSdyYPLl2_l"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "from catboost import *"
      ],
      "metadata": {
        "id": "zswnRMtJmGtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier(random_state=1234,verbose=500,iterations=1500,learning_rate=0.033)\n",
        "model.fit(trainA_31_x, trainA_31_y_c)\n",
        "pred_a = model.predict_proba(testA_31_x)\n",
        "model.fit(train_T_31_x, train_T_31_y_c)\n",
        "pred_t = model.predict_proba(test_T_31_x)\n",
        "model.fit(train_O_31_x, train_O_31_y_c)\n",
        "pred_o = model.predict_proba(test_O_31_x)\n",
        "\n",
        "testA_31['class0'] = pred_a[:, 0]\n",
        "testA_31['class1'] = pred_a[:, 1]\n",
        "testA_31['class2'] = pred_a[:, 2]\n",
        "test_T_31['class0'] = pred_t[:, 0]\n",
        "test_T_31['class1'] = pred_t[:, 1]\n",
        "test_T_31['class2'] = pred_t[:, 2]\n",
        "test_O_31['class0'] = 0\n",
        "test_O_31['class1'] = pred_o[:, 0]\n",
        "test_O_31['class2'] = pred_o[:, 1]\n",
        "\n",
        "\n",
        "submita = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submitt = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submito = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "\n",
        "submita = pd.merge(submita[['PRODUCT_ID']],testA_31[['PRODUCT_ID','class0','class1','class2']],on='PRODUCT_ID')\n",
        "submitt = pd.merge(submitt[['PRODUCT_ID']],test_T_31[['PRODUCT_ID','class0','class1','class2']],on='PRODUCT_ID')\n",
        "submito = pd.merge(submito[['PRODUCT_ID']],test_O_31[['PRODUCT_ID','class0','class1','class2']],on='PRODUCT_ID')\n",
        "\n",
        "proba = pd.concat([submita,submitt,submito]).sort_values(by='PRODUCT_ID')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM8bcIjRmISV",
        "outputId": "051b54ae-bda3-47fa-cac0-d90a30f258b1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0882409\ttotal: 367ms\tremaining: 9m 9s\n",
            "500:\tlearn: 0.1579504\ttotal: 2m 19s\tremaining: 4m 38s\n",
            "1000:\tlearn: 0.0575422\ttotal: 4m 39s\tremaining: 2m 19s\n",
            "1499:\tlearn: 0.0313583\ttotal: 6m 55s\tremaining: 0us\n",
            "0:\tlearn: 1.0742571\ttotal: 130ms\tremaining: 3m 14s\n",
            "500:\tlearn: 0.1306600\ttotal: 52.7s\tremaining: 1m 45s\n",
            "1000:\tlearn: 0.0516016\ttotal: 1m 45s\tremaining: 52.4s\n",
            "1499:\tlearn: 0.0292629\ttotal: 2m 36s\tremaining: 0us\n",
            "0:\tlearn: 0.6684011\ttotal: 4.09ms\tremaining: 6.14s\n",
            "500:\tlearn: 0.0152105\ttotal: 1.84s\tremaining: 3.67s\n",
            "1000:\tlearn: 0.0083918\ttotal: 6.27s\tremaining: 3.12s\n",
            "1499:\tlearn: 0.0057760\ttotal: 8.12s\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostRegressor(random_state=1234,verbose=500,iterations=1500,learning_rate=0.033)\n",
        "model.fit(trainA_31_x, trainA_31_y_c)\n",
        "pred_a_r_c = model.predict(testA_31_x)\n",
        "model.fit(train_T_31_x, train_T_31_y_c)\n",
        "pred_t_r_c = model.predict(test_T_31_x)\n",
        "model.fit(train_O_31_x, train_O_31_y_c)\n",
        "pred_o_r_c = model.predict(test_O_31_x)\n",
        "testA_31['Y_Class'] = pred_a_r_c\n",
        "test_T_31['Y_Class'] = pred_t_r_c\n",
        "test_O_31['Y_Class'] = pred_o_r_c\n",
        "submita = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submitt = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submito = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "\n",
        "submita = pd.merge(submita[['PRODUCT_ID']],testA_31[['PRODUCT_ID','Y_Class']],on='PRODUCT_ID')\n",
        "submitt = pd.merge(submitt[['PRODUCT_ID']],test_T_31[['PRODUCT_ID','Y_Class']],on='PRODUCT_ID')\n",
        "submito = pd.merge(submito[['PRODUCT_ID']],test_O_31[['PRODUCT_ID','Y_Class']],on='PRODUCT_ID')\n",
        "\n",
        "reg = pd.concat([submita,submitt,submito]).sort_values(by='PRODUCT_ID')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzBx6S2nmZXN",
        "outputId": "d44cf395-5a1e-4ed7-b0a0-7b3e98dd75d4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.7183692\ttotal: 136ms\tremaining: 3m 23s\n",
            "500:\tlearn: 0.0618939\ttotal: 1m 1s\tremaining: 2m 2s\n",
            "1000:\tlearn: 0.0060866\ttotal: 2m 4s\tremaining: 1m 2s\n",
            "1499:\tlearn: 0.0005781\ttotal: 3m 7s\tremaining: 0us\n",
            "0:\tlearn: 0.4093482\ttotal: 50.9ms\tremaining: 1m 16s\n",
            "500:\tlearn: 0.0796737\ttotal: 21.5s\tremaining: 43s\n",
            "1000:\tlearn: 0.0156947\ttotal: 45.1s\tremaining: 22.5s\n",
            "1499:\tlearn: 0.0023566\ttotal: 1m 8s\tremaining: 0us\n",
            "0:\tlearn: 0.4671273\ttotal: 5.78ms\tremaining: 8.66s\n",
            "500:\tlearn: 0.0034926\ttotal: 1.62s\tremaining: 3.23s\n",
            "1000:\tlearn: 0.0000555\ttotal: 3.32s\tremaining: 1.66s\n",
            "1499:\tlearn: 0.0000009\ttotal: 5.03s\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processing = pd.merge(proba,reg, on= 'PRODUCT_ID')"
      ],
      "metadata": {
        "id": "rRyosPPemhi6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before = pd.read_csv('/content/scale1.csv')\n",
        "#processing = pd.read_csv('/content/processing.csv')"
      ],
      "metadata": {
        "id": "IaPX0WpClsfj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mer2 = pd.merge(before,processing, on = 'PRODUCT_ID')\n",
        "mer2['Y_Class_x'][(mer2['Y_Class_x'] != 0) & (mer2['class0'] > 0.45) & (mer2['Y_Class_y'] <= 0.75)] = 0\n",
        "submit = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
        "submit['Y_Class'] = mer2['Y_Class_x']\n",
        "submit.to_csv('재현확인.csv',index=False)"
      ],
      "metadata": {
        "id": "YI64e8nfj6iM"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}