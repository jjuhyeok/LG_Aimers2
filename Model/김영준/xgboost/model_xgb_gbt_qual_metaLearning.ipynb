{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d91c10",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5b1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "import sys\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pickle\n",
    "import random as rnd\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random as np_rnd\n",
    "import warnings\n",
    "from math import ceil\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, create_study\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# display setting\n",
    "warnings.filterwarnings(action='ignore')\n",
    "rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b587dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # python random\n",
    "    rnd.seed(seed)\n",
    "    # numpy random\n",
    "    np_rnd.seed(seed)\n",
    "    # tf random\n",
    "    try:\n",
    "        tf_rnd.set_seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # RAPIDS random\n",
    "    try:\n",
    "        cupy.random.seed(seed)\n",
    "    except:\n",
    "        pass\n",
    "    # pytorch random\n",
    "    try:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def pickleIO(obj, src, op=\"w\"):\n",
    "    if op==\"w\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            pickle.dump(obj, f)\n",
    "    elif op==\"r\":\n",
    "        with open(src, op + \"b\") as f:\n",
    "            tmp = pickle.load(f)\n",
    "        return tmp\n",
    "    else:\n",
    "        print(\"unknown operation\")\n",
    "        return obj\n",
    "\n",
    "def findIdx(data_x, col_names):\n",
    "    return [int(i) for i, j in enumerate(data_x) if j in col_names]\n",
    "\n",
    "def diff(first, second):\n",
    "    second = set(second)\n",
    "    return [item for item in first if item not in second]\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print('Error: Creating directory. ' + directory)\n",
    "        \n",
    "def week_of_month(dt):\n",
    "    \"\"\" \n",
    "        Returns the week of the month for the specified date.\n",
    "    \"\"\"\n",
    "    first_day = dt.replace(day=1)\n",
    "    dom = dt.day\n",
    "    adjusted_dom = dom + (1 + first_day.weekday()) % 7\n",
    "    return int(ceil(adjusted_dom/7.0))\n",
    "\n",
    "def quality_to_class(x, threshold):\n",
    "    y_pred_class = []\n",
    "    for i in x:\n",
    "        tmp_class = len(threshold)\n",
    "        for k, v in threshold.items():\n",
    "            if i < v:\n",
    "                tmp_class = k\n",
    "                break\n",
    "        y_pred_class.append(tmp_class)\n",
    "    return y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f2ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    debug = False\n",
    "    TF = True\n",
    "    product_mapper = {\n",
    "        \"A\": [\"T010305\", \"T010306\", \"T050304\", \"T050307\"],\n",
    "        \"O\": [\"T100304\", \"T100306\"],\n",
    "        \"T\": [\"T100304\", \"T100306\"],\n",
    "    }\n",
    "    line_mapper = {\n",
    "        \"T010305\": \"A\", \"T010306\": \"A\", \"T050304\": \"A\", \"T050307\": \"A\",\n",
    "        \"T100304\": \"O_T\", \"T100306\": \"O_T\",\n",
    "    }\n",
    "    line_groups = [\n",
    "        [\"T010305\", \"T010306\"],\n",
    "        [\"T050304\", \"T050307\"],\n",
    "        [\"T100304\", \"T100306\"],\n",
    "    ]\n",
    "    classes = [0, 1, 2]\n",
    "    time_features = [\"month\", \"day\", \"weekday\", \"week_of_month\", \"hour\", \"office_hour\", \"sec_in_day\", \"sin_in_day\", \"cos_in_day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330300df",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_threshold = pickleIO(None, \"../datasets/dataset_valid/quality_threshold.pkl\", \"r\")\n",
    "quality_threshold['T010305_T010306_T050304_T050307'] = {0: (0.525046 + 0.525086) / 2, 1: (0.534843 + 0.535279) / 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe818ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_threshold = {\n",
    "    \"T010305_T010306\": {0: 0.52507, 1: 0.53490},\n",
    "    \"T050304_T050307\": {0: 0.52507, 1: 0.53490},\n",
    "    \"T100304_T100306\": {0: 0.52507, 1: 0.53490},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468aab73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T010305_T010306': {0: 0.52507, 1: 0.5349},\n",
       " 'T050304_T050307': {0: 0.52507, 1: 0.5349},\n",
       " 'T100304_T100306': {0: 0.52507, 1: 0.5349}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfb6f23",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac68518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information Provided by Dacon\n",
    "\n",
    "# PRODUCT_ID : 제품의 고유 ID\n",
    "# Y_Class : 제품 품질 상태(Target) \n",
    "# 0 : 적정 기준 미달 (부적합)\n",
    "# 1 : 적합\n",
    "# 2 : 적정 기준 초과 (부적합)\n",
    "# Y_Quality : 제품 품질 관련 정량적 수치\n",
    "# TIMESTAMP : 제품이 공정에 들어간 시각\n",
    "# LINE : 제품이 들어간 공정 LINE 종류 ('T050304', 'T050307', 'T100304', 'T100306', 'T010306', 'T010305' 존재)\n",
    "# PRODUCT_CODE : 제품의 CODE 번호 ('A_31', 'T_31', 'O_31' 존재)\n",
    "# X_1 ~ X_2875 : 공정 과정에서 추출되어 비식별화된 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c70fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"../datasets/train.csv\")\n",
    "df_full.columns = df_full.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749fbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time feature engineernig\n",
    "# df_full[\"month\"] = df_full[\"timestamp\"].dt.month\n",
    "# df_full[\"day\"] = df_full[\"timestamp\"].dt.day\n",
    "# df_full[\"weekday\"] = df_full[\"timestamp\"].dt.weekday\n",
    "# df_full[\"week_of_month\"] = df_full[\"timestamp\"].apply(week_of_month)\n",
    "# df_full[\"hour\"] = df_full[\"timestamp\"].dt.hour\n",
    "# df_full[\"office_hour\"] = df_full[\"hour\"].apply(lambda x: 1 if ((x >= 9) & (x < 18)) else 0)\n",
    "# df_full[\"sec_in_day\"] = (df_full[\"timestamp\"] - df_full[\"timestamp\"].dt.normalize()).dt.total_seconds() / 3600\n",
    "# df_full[\"sin_in_day\"] = np.sin(2 * np.pi * df_full[\"sec_in_day\"].values)\n",
    "# df_full[\"cos_in_day\"] = np.cos(2 * np.pi * df_full[\"sec_in_day\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10b1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pickleIO(None, \"../../datasets/dataset_valid2/df_train.pkl\", \"r\")\n",
    "# df_valid = pickleIO(None, \"../../datasets/dataset_valid2/df_valid.pkl\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c6a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time feature engineernig\n",
    "# df_train[\"month\"] = df_train[\"timestamp\"].dt.month\n",
    "# df_train[\"day\"] = df_train[\"timestamp\"].dt.day\n",
    "# df_train[\"weekday\"] = df_train[\"timestamp\"].dt.weekday\n",
    "# df_train[\"week_of_month\"] = df_train[\"timestamp\"].apply(week_of_month)\n",
    "# df_train[\"hour\"] = df_train[\"timestamp\"].dt.hour\n",
    "# df_train[\"office_hour\"] = df_train[\"hour\"].apply(lambda x: 1 if ((x >= 9) & (x < 18)) else 0)\n",
    "# df_train[\"sec_in_day\"] = (df_train[\"timestamp\"] - df_train[\"timestamp\"].dt.normalize()).dt.total_seconds() / 3600\n",
    "# df_train[\"sin_in_day\"] = np.sin(2 * np.pi * df_train[\"sec_in_day\"].values)\n",
    "# df_train[\"cos_in_day\"] = np.cos(2 * np.pi * df_train[\"sec_in_day\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6977eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time feature engineernig\n",
    "# df_valid[\"month\"] = df_valid[\"timestamp\"].dt.month\n",
    "# df_valid[\"day\"] = df_valid[\"timestamp\"].dt.day\n",
    "# df_valid[\"weekday\"] = df_valid[\"timestamp\"].dt.weekday\n",
    "# df_valid[\"week_of_month\"] = df_valid[\"timestamp\"].apply(week_of_month)\n",
    "# df_valid[\"hour\"] = df_valid[\"timestamp\"].dt.hour\n",
    "# df_valid[\"office_hour\"] = df_valid[\"hour\"].apply(lambda x: 1 if ((x >= 9) & (x < 18)) else 0)\n",
    "# df_valid[\"sec_in_day\"] = (df_valid[\"timestamp\"] - df_valid[\"timestamp\"].dt.normalize()).dt.total_seconds() / 3600\n",
    "# df_valid[\"sin_in_day\"] = np.sin(2 * np.pi * df_valid[\"sec_in_day\"].values)\n",
    "# df_valid[\"cos_in_day\"] = np.cos(2 * np.pi * df_valid[\"sec_in_day\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceac0c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a77d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"y_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e78dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.groupby([\"line\", \"product_code\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e3fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee2734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31716e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid[\"y_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d8be679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.groupby([\"line\", \"product_code\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c2ef4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>tmp</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.530272</td>\n",
       "      <td>0.538753</td>\n",
       "      <td>0.520646</td>\n",
       "      <td>0.530209</td>\n",
       "      <td>0.543508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005765</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.502517</td>\n",
       "      <td>0.525213</td>\n",
       "      <td>0.534951</td>\n",
       "      <td>0.500856</td>\n",
       "      <td>0.525086</td>\n",
       "      <td>0.535279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.520467</td>\n",
       "      <td>0.528483</td>\n",
       "      <td>0.535541</td>\n",
       "      <td>0.519388</td>\n",
       "      <td>0.527989</td>\n",
       "      <td>0.537330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.523422</td>\n",
       "      <td>0.530308</td>\n",
       "      <td>0.536237</td>\n",
       "      <td>0.521315</td>\n",
       "      <td>0.530353</td>\n",
       "      <td>0.539235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.524612</td>\n",
       "      <td>0.532119</td>\n",
       "      <td>0.539517</td>\n",
       "      <td>0.523522</td>\n",
       "      <td>0.532332</td>\n",
       "      <td>0.547506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.525067</td>\n",
       "      <td>0.534837</td>\n",
       "      <td>0.551279</td>\n",
       "      <td>0.525046</td>\n",
       "      <td>0.534843</td>\n",
       "      <td>0.578841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tmp              0                                 1                       \n",
       "y_class          0           1          2          0           1          2\n",
       "count    28.000000  289.000000  32.000000  60.000000  118.000000  71.000000\n",
       "mean      0.521246    0.530272   0.538753   0.520646    0.530209   0.543508\n",
       "std       0.005765    0.002334   0.004931   0.003990    0.002705   0.008733\n",
       "min       0.502517    0.525213   0.534951   0.500856    0.525086   0.535279\n",
       "25%       0.520467    0.528483   0.535541   0.519388    0.527989   0.537330\n",
       "50%       0.523422    0.530308   0.536237   0.521315    0.530353   0.539235\n",
       "75%       0.524612    0.532119   0.539517   0.523522    0.532332   0.547506\n",
       "max       0.525067    0.534837   0.551279   0.525046    0.534843   0.578841"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_full[\"tmp\"] = df_full[\"product_code\"].apply(lambda x: 1 if x == \"A_31\" else 0)\n",
    "display(df_full.groupby([\"tmp\", \"y_class\"])[\"y_quality\"].describe().T)\n",
    "df_full = df_full.drop(\"tmp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "627ffcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tmp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>349.000000</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.011461</td>\n",
       "      <td>1.044177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.725442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tmp             0           1\n",
       "count  349.000000  249.000000\n",
       "mean     1.011461    1.044177\n",
       "std      0.415069    0.725442\n",
       "min      0.000000    0.000000\n",
       "25%      1.000000    1.000000\n",
       "50%      1.000000    1.000000\n",
       "75%      1.000000    2.000000\n",
       "max      2.000000    2.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_full[\"tmp\"] = df_full[\"product_code\"].apply(lambda x: 1 if x == \"A_31\" else 0)\n",
    "display(df_full.groupby(\"tmp\")[\"y_class\"].describe().T)\n",
    "df_full = df_full.drop(\"tmp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d45df36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp  y_class\n",
      "0    1          0.828080\n",
      "     2          0.091691\n",
      "     0          0.080229\n",
      "1    1          0.473896\n",
      "     2          0.285141\n",
      "     0          0.240964\n",
      "Name: y_class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_full[\"tmp\"] = df_full[\"product_code\"].apply(lambda x: 1 if x == \"A_31\" else 0)\n",
    "print(df_full.groupby(\"tmp\")[\"y_class\"].value_counts(normalize=True))\n",
    "df_full = df_full.drop(\"tmp\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dbec75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../datasets/test.csv\")\n",
    "df_test.columns = df_test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a236e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time feature engineernig\n",
    "# df_test[\"month\"] = df_test[\"timestamp\"].dt.month\n",
    "# df_test[\"day\"] = df_test[\"timestamp\"].dt.day\n",
    "# df_test[\"weekday\"] = df_test[\"timestamp\"].dt.weekday\n",
    "# df_test[\"week_of_month\"] = df_test[\"timestamp\"].apply(week_of_month)\n",
    "# df_test[\"hour\"] = df_test[\"timestamp\"].dt.hour\n",
    "# df_test[\"office_hour\"] = df_test[\"hour\"].apply(lambda x: 1 if ((x >= 9) & (x < 18)) else 0)\n",
    "# df_test[\"sec_in_day\"] = (df_test[\"timestamp\"] - df_test[\"timestamp\"].dt.normalize()).dt.total_seconds() / 3600\n",
    "# df_test[\"sin_in_day\"] = np.sin(2 * np.pi * df_test[\"sec_in_day\"].values)\n",
    "# df_test[\"cos_in_day\"] = np.cos(2 * np.pi * df_test[\"sec_in_day\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "248c14b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>line</th>\n",
       "      <th>product_code</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>...</th>\n",
       "      <th>x_2866</th>\n",
       "      <th>x_2867</th>\n",
       "      <th>x_2868</th>\n",
       "      <th>x_2869</th>\n",
       "      <th>x_2870</th>\n",
       "      <th>x_2871</th>\n",
       "      <th>x_2872</th>\n",
       "      <th>x_2873</th>\n",
       "      <th>x_2874</th>\n",
       "      <th>x_2875</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>2022-09-09 2:01</td>\n",
       "      <td>T100306</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>2022-09-09 2:09</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>2022-09-09 8:42</td>\n",
       "      <td>T100304</td>\n",
       "      <td>T_31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>2022-09-09 10:56</td>\n",
       "      <td>T010305</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>2022-09-09 11:04</td>\n",
       "      <td>T010306</td>\n",
       "      <td>A_31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id         timestamp     line product_code  x_1   x_2  x_3   x_4  \\\n",
       "0   TEST_000   2022-09-09 2:01  T100306         T_31  2.0  94.0  0.0  45.0   \n",
       "1   TEST_001   2022-09-09 2:09  T100304         T_31  2.0  93.0  0.0  45.0   \n",
       "2   TEST_002   2022-09-09 8:42  T100304         T_31  2.0  95.0  0.0  45.0   \n",
       "3   TEST_003  2022-09-09 10:56  T010305         A_31  NaN   NaN  NaN   NaN   \n",
       "4   TEST_004  2022-09-09 11:04  T010306         A_31  NaN   NaN  NaN   NaN   \n",
       "\n",
       "    x_5  x_6  ...  x_2866  x_2867  x_2868  x_2869  x_2870  x_2871  x_2872  \\\n",
       "0  10.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1  11.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2  11.0  0.0  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3   NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4   NaN  NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   x_2873  x_2874  x_2875  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 2879 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c948b",
   "metadata": {},
   "source": [
    "## Training by Lines\n",
    "\n",
    "* \"T010305\", \"T010306\"\n",
    "* \"T050304\", \"T050307\"\n",
    "* \"T100304\", \"T100306\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cdf9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_root_path = \"./architectures/\"\n",
    "architecture_name = \"daheeRef_targetQual_bylines_TF_xgb_gbt_metaLearning_try2\"\n",
    "architecture_path = architecture_root_path + architecture_name + \"/\"\n",
    "createFolder(architecture_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d08be1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling\n",
    "df_full = df_full.sample(frac=1, random_state=GLOBAL_SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74653b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding on Line\n",
    "lbe = LabelEncoder()\n",
    "lbe.fit([\"T010305\", \"T010306\", \"T050304\", \"T050307\", \"T100304\", \"T100306\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245b36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = {\"reg_qual\": None, \"cls_cls\": None, \"reg_cls\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c42ffb",
   "metadata": {},
   "source": [
    "### Training - Regression (y_quality) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d05387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.5, 0.5, 1234)\n",
      "(1.0, 0.5, 0.5, 42)\n",
      "(1.0, 0.5, 0.8, 1234)\n",
      "(1.0, 0.5, 0.8, 42)\n",
      "(1.0, 0.8, 0.5, 1234)\n",
      "(1.0, 0.8, 0.5, 42)\n",
      "(1.0, 0.8, 0.8, 1234)\n",
      "(1.0, 0.8, 0.8, 42)\n",
      "(0.1, 0.5, 0.5, 1234)\n",
      "(0.1, 0.5, 0.5, 42)\n",
      "(0.1, 0.5, 0.8, 1234)\n",
      "(0.1, 0.5, 0.8, 42)\n",
      "(0.1, 0.8, 0.5, 1234)\n",
      "(0.1, 0.8, 0.5, 42)\n",
      "(0.1, 0.8, 0.8, 1234)\n",
      "(0.1, 0.8, 0.8, 42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective\n",
    "# regession : \"mae\", \"mse\"\n",
    "# classification - binary : \"binary\"\n",
    "# classification - binary : \"multiclass\" (num_class=n)\n",
    "# ranking : \"xe_ndcg_mart\"\n",
    "\n",
    "# metric\n",
    "# regession : \"mae\", \"mse\", \"rmse\"\n",
    "# classification - binary : \"binary_logloss\", \"binary_error\", \"auc\"\n",
    "# classification - muticlass : \"multi_logloss\", \"multi_error\"\n",
    "# ranking : \"ndcg\", \"map\"\n",
    "\n",
    "fixed_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"max_depth\": 6,\n",
    "}\n",
    "\n",
    "searching_params = {\n",
    "    \"reg_lambda\": [1.0, 0.1],\n",
    "    \"subsample\": [0.5, 0.8],\n",
    "    \"colsample_bytree\": [0.5, 0.8],\n",
    "    \"random_state\": [1234, 42],\n",
    "}\n",
    "\n",
    "preset_params = []\n",
    "for params in list(product(*searching_params.values())):\n",
    "    print(params)\n",
    "    tmp = fixed_params.copy()\n",
    "    tmp[\"reg_lambda\"] = params[0]\n",
    "    tmp[\"subsample\"] = params[1]\n",
    "    tmp[\"colsample_bytree\"] = params[2]\n",
    "    tmp[\"random_state\"] = params[3]\n",
    "    preset_params.append(tmp)\n",
    "\n",
    "preset_params = preset_params[:3] if CFG.debug else preset_params\n",
    "len(preset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f79538b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 1173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [02:13<00:00,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [01:02<00:00,  3.90s/it]\n"
     ]
    }
   ],
   "source": [
    "line_split = [\n",
    "    # A\n",
    "    [\"A_31\"],\n",
    "    # O, T\n",
    "    [\"T_31\", \"O_31\"],\n",
    "]\n",
    "score_dic = {\n",
    "    \"mae\": None,\n",
    "    \"r2\": None,\n",
    "    \"accuracy\": None,\n",
    "    \"f1\": None,\n",
    "}\n",
    "line_split_f1 = {}\n",
    "line_score = {\"_\".join(i): {\"train\": score_dic.copy(), \"valid\": score_dic.copy()} for i in line_split}\n",
    "valid_pred = {\"_\".join(i): None for i in line_split}\n",
    "test_pred = {\"_\".join(i): None for i in line_split}\n",
    "\n",
    "for line in line_split:\n",
    "    seed_everything()\n",
    "    # Training\n",
    "    # === Preprocessing (Train) ===\n",
    "    full_x = df_full[df_full[\"product_code\"].isin(line)]\n",
    "    full_x[\"line\"] = lbe.transform(full_x[\"line\"])\n",
    "    \n",
    "    full_y = full_x[\"y_quality\"].values\n",
    "    full_y_cls = full_x[\"y_class\"].values\n",
    "    # Drop columns\n",
    "    full_x = full_x.drop([\"product_id\", \"y_class\", \"y_quality\", \"timestamp\", \"product_code\"], axis=1)\n",
    "    \n",
    "    full_x = full_x[full_x.columns[~(full_x.var() == 0).values & ~full_x.isna().all().values]]\n",
    "    full_x = full_x.fillna(-1.0)\n",
    "    full_x = full_x.T.drop_duplicates().T\n",
    "    full_x = full_x.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    selected_vars = full_x.columns\n",
    "    cat_vars = [\"line\"]\n",
    "    num_vars = diff(selected_vars, cat_vars)\n",
    "    categoIdx = findIdx(selected_vars, cat_vars)\n",
    "\n",
    "    full_x[num_vars] = full_x[num_vars].astype(\"float32\")\n",
    "    full_x[cat_vars] = full_x[cat_vars].astype(\"int32\")\n",
    "    print(full_x.shape)\n",
    "    \n",
    "    # === Preprocessing (Test) ===\n",
    "    test_x = df_test[df_test[\"product_code\"].isin(line)]\n",
    "    test_x[\"line\"] = lbe.transform(test_x[\"line\"])\n",
    "    test_x = test_x[selected_vars]\n",
    "    test_x = test_x.fillna(-1.0)\n",
    "    \n",
    "    test_x[num_vars] = test_x[num_vars].astype(\"float32\")\n",
    "    test_x[cat_vars] = test_x[cat_vars].astype(\"int32\")\n",
    "    \n",
    "    class_weight = compute_class_weight(class_weight=\"balanced\", classes=[0, 1, 2], y=full_y_cls)\n",
    "    line_full_pred = np.zeros(len(full_x))\n",
    "    line_test_pred = np.zeros(len(test_x))\n",
    "    for params in tqdm(preset_params):\n",
    "        model = xgb.XGBRegressor(verbosity=1, **params)\n",
    "        model.fit(full_x, np.log1p(full_y), sample_weight=class_weight[full_y_cls], verbose=int(params[\"n_estimators\"] * 0.2))\n",
    "        line_full_pred[:] += np.expm1(model.predict(full_x)) / len(preset_params)\n",
    "        line_test_pred[:] += np.expm1(model.predict(test_x)) / len(preset_params)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = line_full_pred.copy()\n",
    "    y_true = full_y.copy()\n",
    "    eval_mae = mean_absolute_error(y_true, y_pred)\n",
    "    eval_r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Transform quality to class\n",
    "    y_true_class = full_y_cls.copy()\n",
    "    y_pred_class = quality_to_class(y_pred, {0: 0.52507, 1: 0.53490})\n",
    "    eval_acc = accuracy_score(y_true_class, y_pred_class)\n",
    "    eval_f1 = f1_score(y_true_class, y_pred_class, average=\"macro\")\n",
    "    \n",
    "    # Save values\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"mae\"] = eval_mae\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"r2\"] = eval_r2\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"accuracy\"] = eval_acc\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"f1\"] = eval_f1\n",
    "    valid_pred[\"_\".join(line)] = y_pred\n",
    "    \n",
    "    # Inference\n",
    "    y_pred = line_test_pred.copy()\n",
    "    \n",
    "    # Save values\n",
    "    test_pred[\"_\".join(line)] = y_pred\n",
    "\n",
    "df_meta[\"reg_qual\"] = [valid_pred, test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c17ed283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.00041076571860552795, 'r2': 0.9973971129195781, 'accuracy': 0.9718875502008032, 'f1': 0.9723616789676588}}, 'T_31_O_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.0005373432574761392, 'r2': 0.9781928046144005, 'accuracy': 0.9885386819484241, 'f1': 0.9746106820710523}}}\n"
     ]
    }
   ],
   "source": [
    "print(line_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244aa25c",
   "metadata": {},
   "source": [
    "### Training - Regression (y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "798226bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.5, 0.5, 1234)\n",
      "(1.0, 0.5, 0.5, 42)\n",
      "(1.0, 0.5, 0.8, 1234)\n",
      "(1.0, 0.5, 0.8, 42)\n",
      "(1.0, 0.8, 0.5, 1234)\n",
      "(1.0, 0.8, 0.5, 42)\n",
      "(1.0, 0.8, 0.8, 1234)\n",
      "(1.0, 0.8, 0.8, 42)\n",
      "(0.1, 0.5, 0.5, 1234)\n",
      "(0.1, 0.5, 0.5, 42)\n",
      "(0.1, 0.5, 0.8, 1234)\n",
      "(0.1, 0.5, 0.8, 42)\n",
      "(0.1, 0.8, 0.5, 1234)\n",
      "(0.1, 0.8, 0.5, 42)\n",
      "(0.1, 0.8, 0.8, 1234)\n",
      "(0.1, 0.8, 0.8, 42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective\n",
    "# regession : \"mae\", \"mse\"\n",
    "# classification - binary : \"binary\"\n",
    "# classification - binary : \"multiclass\" (num_class=n)\n",
    "# ranking : \"xe_ndcg_mart\"\n",
    "\n",
    "# metric\n",
    "# regession : \"mae\", \"mse\", \"rmse\"\n",
    "# classification - binary : \"binary_logloss\", \"binary_error\", \"auc\"\n",
    "# classification - muticlass : \"multi_logloss\", \"multi_error\"\n",
    "# ranking : \"ndcg\", \"map\"\n",
    "\n",
    "fixed_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"max_depth\": 6,\n",
    "}\n",
    "\n",
    "searching_params = {\n",
    "    \"reg_lambda\": [1.0, 0.1],\n",
    "    \"subsample\": [0.5, 0.8],\n",
    "    \"colsample_bytree\": [0.5, 0.8],\n",
    "    \"random_state\": [1234, 42],\n",
    "}\n",
    "\n",
    "preset_params = []\n",
    "for params in list(product(*searching_params.values())):\n",
    "    print(params)\n",
    "    tmp = fixed_params.copy()\n",
    "    tmp[\"reg_lambda\"] = params[0]\n",
    "    tmp[\"subsample\"] = params[1]\n",
    "    tmp[\"colsample_bytree\"] = params[2]\n",
    "    tmp[\"random_state\"] = params[3]\n",
    "    preset_params.append(tmp)\n",
    "\n",
    "preset_params = preset_params[:3] if CFG.debug else preset_params\n",
    "len(preset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be2a0bc0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 1173)\n",
      "(349, 452)\n"
     ]
    }
   ],
   "source": [
    "line_split = [\n",
    "    # A\n",
    "    [\"A_31\"],\n",
    "    # O, T\n",
    "    [\"T_31\", \"O_31\"],\n",
    "]\n",
    "score_dic = {\n",
    "    \"mae\": None,\n",
    "    \"r2\": None,\n",
    "    \"accuracy\": None,\n",
    "    \"f1\": None,\n",
    "}\n",
    "line_split_f1 = {}\n",
    "line_score = {\"_\".join(i): {\"train\": score_dic.copy(), \"valid\": score_dic.copy()} for i in line_split}\n",
    "valid_pred = {\"_\".join(i): None for i in line_split}\n",
    "test_pred = {\"_\".join(i): None for i in line_split}\n",
    "\n",
    "for line in line_split:\n",
    "    seed_everything()\n",
    "    # Training\n",
    "    # === Preprocessing (Train) ===\n",
    "    full_x = df_full[df_full[\"product_code\"].isin(line)]\n",
    "    \n",
    "    # Label Encoding on Line\n",
    "    full_x[\"line\"] = lbe.transform(full_x[\"line\"])\n",
    "    \n",
    "    full_y = full_x[\"y_quality\"].values\n",
    "    full_y_cls = full_x[\"y_class\"].values\n",
    "    # Drop columns\n",
    "    full_x = full_x.drop([\"product_id\", \"y_class\", \"y_quality\", \"timestamp\", \"product_code\"], axis=1)\n",
    "    \n",
    "    full_x = full_x[full_x.columns[~(full_x.var() == 0).values & ~full_x.isna().all().values]]\n",
    "    full_x = full_x.fillna(-1.0)\n",
    "    full_x = full_x.T.drop_duplicates().T\n",
    "    full_x = full_x.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    selected_vars = full_x.columns\n",
    "    cat_vars = [\"line\"]\n",
    "    num_vars = diff(selected_vars, cat_vars)\n",
    "    categoIdx = findIdx(selected_vars, cat_vars)\n",
    "\n",
    "    full_x[num_vars] = full_x[num_vars].astype(\"float32\")\n",
    "    full_x[cat_vars] = full_x[cat_vars].astype(\"int32\")\n",
    "    print(full_x.shape)\n",
    "    \n",
    "    # === Preprocessing (Test) ===\n",
    "    test_x = df_test[df_test[\"product_code\"].isin(line)]\n",
    "    test_x[\"line\"] = lbe.transform(test_x[\"line\"])\n",
    "    test_x = test_x[selected_vars]\n",
    "    test_x = test_x.fillna(-1.0)\n",
    "    \n",
    "    test_x[num_vars] = test_x[num_vars].astype(\"float32\")\n",
    "    test_x[cat_vars] = test_x[cat_vars].astype(\"int32\")\n",
    "    \n",
    "    class_weight = compute_class_weight(class_weight=\"balanced\", classes=[0, 1, 2], y=full_y_cls)\n",
    "    line_full_pred = np.zeros(len(full_x))\n",
    "    line_test_pred = np.zeros(len(test_x))\n",
    "    for params in tqdm(preset_params):\n",
    "        model = xgb.XGBRegressor(verbosity=1, **params)\n",
    "        model.fit(full_x, full_y_cls, sample_weight=class_weight[full_y_cls], verbose=int(params[\"n_estimators\"] * 0.2))\n",
    "        line_full_pred[:] += model.predict(full_x) / len(preset_params)\n",
    "        line_test_pred[:] += model.predict(test_x) / len(preset_params)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = line_full_pred.copy()\n",
    "    y_true = full_y.copy()\n",
    "    eval_mae = mean_absolute_error(y_true, y_pred)\n",
    "    eval_r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # Transform quality to class\n",
    "    y_true_class = full_y_cls.copy()\n",
    "    y_pred_class = np.clip(np.round(y_true), 0, 2)\n",
    "    eval_acc = accuracy_score(y_true_class, full_y_cls)\n",
    "    eval_f1 = f1_score(y_true_class, full_y_cls, average=\"macro\")\n",
    "    \n",
    "    # Save values\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"mae\"] = eval_mae\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"r2\"] = eval_r2\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"accuracy\"] = eval_acc\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"f1\"] = eval_f1\n",
    "    valid_pred[\"_\".join(line)] = y_pred\n",
    "    \n",
    "    # Inference\n",
    "    y_pred = line_test_pred.copy()\n",
    "    \n",
    "    # Save values\n",
    "    test_pred[\"_\".join(line)] = y_pred\n",
    "\n",
    "df_meta[\"reg_cls\"] = [valid_pred, test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d4e7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.7580452113758052, 'r2': -7722.723816671717, 'accuracy': 1.0, 'f1': 1.0}}, 'T_31_O_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.5641397042119296, 'r2': -17822.474144681797, 'accuracy': 1.0, 'f1': 1.0}}}\n"
     ]
    }
   ],
   "source": [
    "print(line_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6cbc5",
   "metadata": {},
   "source": [
    "### Training - Classfication (y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1ecad33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 0.5, 0.5, 1234)\n",
      "(1.0, 0.5, 0.5, 42)\n",
      "(1.0, 0.5, 0.8, 1234)\n",
      "(1.0, 0.5, 0.8, 42)\n",
      "(1.0, 0.8, 0.5, 1234)\n",
      "(1.0, 0.8, 0.5, 42)\n",
      "(1.0, 0.8, 0.8, 1234)\n",
      "(1.0, 0.8, 0.8, 42)\n",
      "(0.1, 0.5, 0.5, 1234)\n",
      "(0.1, 0.5, 0.5, 42)\n",
      "(0.1, 0.5, 0.8, 1234)\n",
      "(0.1, 0.5, 0.8, 42)\n",
      "(0.1, 0.8, 0.5, 1234)\n",
      "(0.1, 0.8, 0.5, 42)\n",
      "(0.1, 0.8, 0.8, 1234)\n",
      "(0.1, 0.8, 0.8, 42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective\n",
    "# regession : \"mae\", \"mse\"\n",
    "# classification - binary : \"binary\"\n",
    "# classification - binary : \"multiclass\" (num_class=n)\n",
    "# ranking : \"xe_ndcg_mart\"\n",
    "\n",
    "# metric\n",
    "# regession : \"mae\", \"mse\", \"rmse\"\n",
    "# classification - binary : \"binary_logloss\", \"binary_error\", \"auc\"\n",
    "# classification - muticlass : \"multi_logloss\", \"multi_error\"\n",
    "# ranking : \"ndcg\", \"map\"\n",
    "\n",
    "fixed_params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"max_depth\": 6,\n",
    "}\n",
    "\n",
    "searching_params = {\n",
    "    \"reg_lambda\": [1.0, 0.1],\n",
    "    \"subsample\": [0.5, 0.8],\n",
    "    \"colsample_bytree\": [0.5, 0.8],\n",
    "    \"random_state\": [1234, 42],\n",
    "}\n",
    "\n",
    "preset_params = []\n",
    "for params in list(product(*searching_params.values())):\n",
    "    print(params)\n",
    "    tmp = fixed_params.copy()\n",
    "    tmp[\"reg_lambda\"] = params[0]\n",
    "    tmp[\"subsample\"] = params[1]\n",
    "    tmp[\"colsample_bytree\"] = params[2]\n",
    "    tmp[\"random_state\"] = params[3]\n",
    "    preset_params.append(tmp)\n",
    "\n",
    "preset_params = preset_params[:3] if CFG.debug else preset_params\n",
    "len(preset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfef62d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 1173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████▌                                                                                                                | 1/16 [00:11<02:52, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████                                                                                                         | 2/16 [00:23<02:42, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▌                                                                                                 | 3/16 [00:36<02:42, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████████████                                                                                          | 4/16 [00:50<02:35, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████████████████▌                                                                                  | 5/16 [01:02<02:20, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████                                                                           | 6/16 [01:15<02:06, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████████████████▌                                                                   | 7/16 [01:30<02:00, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████████████████████████                                                            | 8/16 [01:45<01:51, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████████████████████████████████████████████████▌                                                    | 9/16 [01:56<01:31, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████▍                                            | 10/16 [02:08<01:15, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 11/16 [02:21<01:03, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:50:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████▎                             | 12/16 [02:34<00:51, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 13/16 [02:46<00:37, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 14/16 [02:58<00:24, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 15/16 [03:13<00:13, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [03:27<00:00, 12.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 452)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|███████▌                                                                                                                | 1/16 [00:05<01:25,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████████████                                                                                                         | 2/16 [00:11<01:20,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████████████▌                                                                                                 | 3/16 [00:18<01:21,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██████████████████████████████                                                                                          | 4/16 [00:25<01:18,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████████████████▌                                                                                  | 5/16 [00:31<01:10,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████                                                                           | 6/16 [00:37<01:03,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████████████████████▌                                                                   | 7/16 [00:45<01:00,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████████████████████████                                                            | 8/16 [00:52<00:55,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|███████████████████████████████████████████████████████████████████▌                                                    | 9/16 [00:58<00:46,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████████████████████████████▍                                            | 10/16 [01:04<00:38,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|█████████████████████████████████████████████████████████████████████████████████▊                                     | 11/16 [01:11<00:32,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████▎                             | 12/16 [01:18<00:26,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 13/16 [01:24<00:19,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 14/16 [01:30<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 15/16 [01:37<00:06,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [01:44<00:00,  6.54s/it]\n"
     ]
    }
   ],
   "source": [
    "line_split = [\n",
    "    # A\n",
    "    [\"A_31\"],\n",
    "    # O, T\n",
    "    [\"T_31\", \"O_31\"],\n",
    "]\n",
    "score_dic = {\n",
    "    \"mae\": None,\n",
    "    \"r2\": None,\n",
    "    \"accuracy\": None,\n",
    "    \"f1\": None,\n",
    "}\n",
    "line_split_f1 = {}\n",
    "line_score = {\"_\".join(i): {\"train\": score_dic.copy(), \"valid\": score_dic.copy()} for i in line_split}\n",
    "valid_pred = {\"_\".join(i): None for i in line_split}\n",
    "test_pred = {\"_\".join(i): None for i in line_split}\n",
    "\n",
    "for line in line_split:\n",
    "    seed_everything()\n",
    "    # Training\n",
    "    # === Preprocessing (Train) ===\n",
    "    full_x = df_full[df_full[\"product_code\"].isin(line)]\n",
    "    \n",
    "    # Label Encoding on Line\n",
    "    full_x[\"line\"] = lbe.transform(full_x[\"line\"])\n",
    "    \n",
    "    full_y = full_x[\"y_quality\"].values\n",
    "    full_y_cls = full_x[\"y_class\"].values\n",
    "    # Drop columns\n",
    "    full_x = full_x.drop([\"product_id\", \"y_class\", \"y_quality\", \"timestamp\", \"product_code\"], axis=1)\n",
    "    \n",
    "    full_x = full_x[full_x.columns[~(full_x.var() == 0).values & ~full_x.isna().all().values]]\n",
    "    full_x = full_x.fillna(-1.0)\n",
    "    full_x = full_x.T.drop_duplicates().T\n",
    "    full_x = full_x.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    selected_vars = full_x.columns\n",
    "    cat_vars = [\"line\"]\n",
    "    num_vars = diff(selected_vars, cat_vars)\n",
    "    categoIdx = findIdx(selected_vars, cat_vars)\n",
    "\n",
    "    full_x[num_vars] = full_x[num_vars].astype(\"float32\")\n",
    "    full_x[cat_vars] = full_x[cat_vars].astype(\"int32\")\n",
    "    print(full_x.shape)\n",
    "    \n",
    "    # === Preprocessing (Test) ===\n",
    "    test_x = df_test[df_test[\"product_code\"].isin(line)]\n",
    "    test_x[\"line\"] = lbe.transform(test_x[\"line\"])\n",
    "    test_x = test_x[selected_vars]\n",
    "    test_x = test_x.fillna(-1.0)\n",
    "    \n",
    "    test_x[num_vars] = test_x[num_vars].astype(\"float32\")\n",
    "    test_x[cat_vars] = test_x[cat_vars].astype(\"int32\")\n",
    "    \n",
    "    class_weight = compute_class_weight(class_weight=\"balanced\", classes=[0, 1, 2], y=full_y_cls)\n",
    "    line_full_pred = np.zeros((len(full_x), 3))\n",
    "    line_test_pred = np.zeros((len(test_x), 3))\n",
    "    for params in tqdm(preset_params):\n",
    "        model = xgb.XGBClassifier(verbosity=1, **params)\n",
    "        model.fit(full_x, full_y_cls, sample_weight=class_weight[full_y_cls], verbose=int(params[\"n_estimators\"] * 0.2))\n",
    "        line_full_pred[:] += model.predict_proba(full_x) / len(preset_params)\n",
    "        line_test_pred[:] += model.predict_proba(test_x) / len(preset_params)\n",
    "\n",
    "    # Evaluation\n",
    "    y_pred = line_full_pred.copy()\n",
    "    y_true = full_y_cls.copy()\n",
    "\n",
    "    # Transform quality to class\n",
    "    y_true_class = y_true\n",
    "    y_pred_class = y_pred.argmax(axis=1)\n",
    "    eval_acc = accuracy_score(y_true_class, y_pred_class)\n",
    "    eval_f1 = f1_score(y_true_class, y_pred_class, average=\"macro\")\n",
    "    \n",
    "    # Save values\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"mae\"] = eval_mae\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"r2\"] = eval_r2\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"accuracy\"] = eval_acc\n",
    "    line_score[\"_\".join(line)][\"valid\"][\"f1\"] = eval_f1\n",
    "    valid_pred[\"_\".join(line)] = y_pred\n",
    "    \n",
    "    # Inference\n",
    "    y_pred = line_test_pred.copy()\n",
    "    \n",
    "    # Save values\n",
    "    test_pred[\"_\".join(line)] = y_pred\n",
    "\n",
    "df_meta[\"cls_cls\"] = [valid_pred, test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ca9f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.5641397042119296, 'r2': -17822.474144681797, 'accuracy': 1.0, 'f1': 1.0}}, 'T_31_O_31': {'train': {'mae': None, 'r2': None, 'accuracy': None, 'f1': None}, 'valid': {'mae': 0.5641397042119296, 'r2': -17822.474144681797, 'accuracy': 1.0, 'f1': 1.0}}}\n"
     ]
    }
   ],
   "source": [
    "print(line_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b8768",
   "metadata": {},
   "source": [
    "## Meta Learning (no class weight,  normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "287ad2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prob_valid = {}\n",
    "output_prob_test = {}\n",
    "\n",
    "for line in line_split:\n",
    "    full_x = []\n",
    "    test_x = []\n",
    "    for k, v in df_meta.items():\n",
    "        full_x.append(v[0][\"_\".join(line)])\n",
    "        test_x.append(v[1][\"_\".join(line)])\n",
    "    full_x = np.concatenate([i.reshape(-1, 1) if len(i.shape) == 1 else i for i in full_x], axis=1)\n",
    "    full_x[: ,0] = (full_x[: ,0] - 0.5) * 10\n",
    "    full_x[: ,4] = (full_x[: ,4]) / 3\n",
    "    full_y = df_full.loc[df_full[\"product_code\"].isin(line), \"y_class\"].values\n",
    "    test_x = np.concatenate([i.reshape(-1, 1) if len(i.shape) == 1 else i for i in test_x], axis=1)\n",
    "    test_x[: ,0] = (test_x[: ,0] - 0.5) * 10\n",
    "    test_x[: ,4] = (test_x[: ,4]) / 3\n",
    "\n",
    "    meta_learner = lm.LogisticRegression(multi_class=\"multinomial\", penalty='elasticnet', solver=\"saga\", l1_ratio=0.5, class_weight=None, random_state=42)\n",
    "    meta_learner.fit(full_x, full_y)\n",
    "    output_prob_valid[\"_\".join(line)] = meta_learner.predict_proba(full_x)\n",
    "    output_prob_test[\"_\".join(line)] = meta_learner.predict_proba(test_x)\n",
    "    \n",
    "df_meta[\"meta_learning\"] = [output_prob_valid, output_prob_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca699f",
   "metadata": {},
   "source": [
    "## Threshold Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9d000",
   "metadata": {},
   "source": [
    "### Create infernced value table for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e0b0a222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_output_container_train = []\n",
    "raw_output_container_test = []\n",
    "\n",
    "for line in line_split:\n",
    "    train_x = []\n",
    "    test_x = []\n",
    "    for k, v in df_meta.items():\n",
    "        train_x.append(v[0][\"_\".join(line)])\n",
    "        test_x.append(v[1][\"_\".join(line)])\n",
    "    train_x = np.concatenate([i.reshape(-1, 1) if len(i.shape) == 1 else i for i in train_x], axis=1)\n",
    "    train_y = df_full.loc[df_full[\"product_code\"].isin(line), \"y_class\"].values\n",
    "    test_x = np.concatenate([i.reshape(-1, 1) if len(i.shape) == 1 else i for i in test_x], axis=1)\n",
    "    \n",
    "    raw_output = pd.DataFrame(train_x, columns=[\"reg_qual\", \"cls_cls0\", \"cls_cls1\", \"cls_cls2\", \"reg_cls\", \"meta_learning_cls0\", \"meta_learning_cls1\", \"meta_learning_cls2\"])\n",
    "    raw_output[\"y_true\"] = train_y\n",
    "    raw_output[\"product_code\"] = df_full.loc[df_full[\"product_code\"].isin(line), \"product_code\"].values\n",
    "    raw_output_container_train.append(raw_output)\n",
    "\n",
    "    raw_output = pd.DataFrame(test_x, columns=[\"reg_qual\", \"cls_cls0\", \"cls_cls1\", \"cls_cls2\", \"reg_cls\", \"meta_learning_cls0\", \"meta_learning_cls1\", \"meta_learning_cls2\"])\n",
    "    raw_output[\"product_code\"] = df_test.loc[df_test[\"product_code\"].isin(line), \"product_code\"].values\n",
    "    raw_output[\"product_id\"] = df_test.loc[df_test[\"product_code\"].isin(line), \"product_id\"].values\n",
    "    raw_output_container_test.append(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8cc27f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_qual</th>\n",
       "      <th>cls_cls0</th>\n",
       "      <th>cls_cls1</th>\n",
       "      <th>cls_cls2</th>\n",
       "      <th>reg_cls</th>\n",
       "      <th>meta_learning_cls0</th>\n",
       "      <th>meta_learning_cls1</th>\n",
       "      <th>meta_learning_cls2</th>\n",
       "      <th>y_true</th>\n",
       "      <th>product_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519407</td>\n",
       "      <td>0.977511</td>\n",
       "      <td>0.014327</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.976175</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>0.011371</td>\n",
       "      <td>0</td>\n",
       "      <td>A_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.532045</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.965334</td>\n",
       "      <td>0.030497</td>\n",
       "      <td>1.026221</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.986816</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>1</td>\n",
       "      <td>A_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.537199</td>\n",
       "      <td>0.018024</td>\n",
       "      <td>0.029870</td>\n",
       "      <td>0.952105</td>\n",
       "      <td>1.983897</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.977518</td>\n",
       "      <td>2</td>\n",
       "      <td>A_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533947</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0.951198</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.986045</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>1</td>\n",
       "      <td>A_31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532109</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.977561</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>1.008253</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.987474</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>1</td>\n",
       "      <td>A_31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_qual  cls_cls0  cls_cls1  cls_cls2   reg_cls  meta_learning_cls0  \\\n",
       "0  0.519407  0.977511  0.014327  0.008162  0.004220            0.976175   \n",
       "1  0.532045  0.004169  0.965334  0.030497  1.026221            0.006327   \n",
       "2  0.537199  0.018024  0.029870  0.952105  1.983897            0.010572   \n",
       "3  0.533947  0.029058  0.951198  0.019743  0.986219            0.007024   \n",
       "4  0.532109  0.006753  0.977561  0.015687  1.008253            0.006155   \n",
       "\n",
       "   meta_learning_cls1  meta_learning_cls2  y_true product_code  \n",
       "0            0.012453            0.011371       0         A_31  \n",
       "1            0.986816            0.006857       1         A_31  \n",
       "2            0.011909            0.977518       2         A_31  \n",
       "3            0.986045            0.006931       1         A_31  \n",
       "4            0.987474            0.006371       1         A_31  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output_container_train = pd.concat(raw_output_container_train)\n",
    "raw_output_container_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "64767fc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(architecture_path + \"train_threshold_analysis.xlsx\") as writer:\n",
    "    raw_output_container_train.groupby(\"y_true\").describe().T.reset_index().to_excel(writer, sheet_name=\"all\")\n",
    "    for line in line_split:\n",
    "        df_tmp = raw_output_container_train[raw_output_container_train[\"product_code\"].isin(line)].groupby(\"y_true\").describe().T.reset_index()\n",
    "        df_tmp.to_excel(writer, sheet_name=\"_\".join(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "37c8bfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_qual</th>\n",
       "      <th>cls_cls0</th>\n",
       "      <th>cls_cls1</th>\n",
       "      <th>cls_cls2</th>\n",
       "      <th>reg_cls</th>\n",
       "      <th>meta_learning_cls0</th>\n",
       "      <th>meta_learning_cls1</th>\n",
       "      <th>meta_learning_cls2</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524071</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>0.864400</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>0.536509</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.979189</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531568</td>\n",
       "      <td>0.054616</td>\n",
       "      <td>0.837202</td>\n",
       "      <td>0.108182</td>\n",
       "      <td>1.107915</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.976790</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533111</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.835881</td>\n",
       "      <td>0.140231</td>\n",
       "      <td>1.223501</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.976171</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532295</td>\n",
       "      <td>0.073844</td>\n",
       "      <td>0.888689</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.835941</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>0.981736</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.877041</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>0.382443</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_qual  cls_cls0  cls_cls1  cls_cls2   reg_cls  meta_learning_cls0  \\\n",
       "0  0.524071  0.121408  0.864400  0.014192  0.536509            0.012408   \n",
       "1  0.531568  0.054616  0.837202  0.108182  1.107915            0.010555   \n",
       "2  0.533111  0.023887  0.835881  0.140231  1.223501            0.009728   \n",
       "3  0.532295  0.073844  0.888689  0.037468  0.835941            0.009695   \n",
       "4  0.526138  0.877041  0.082427  0.040532  0.382443            0.959212   \n",
       "\n",
       "   meta_learning_cls1  meta_learning_cls2 product_code product_id  \n",
       "0            0.979189            0.008404         A_31   TEST_003  \n",
       "1            0.976790            0.012656         A_31   TEST_004  \n",
       "2            0.976171            0.014101         A_31   TEST_005  \n",
       "3            0.981736            0.008570         A_31   TEST_006  \n",
       "4            0.022046            0.018742         A_31   TEST_007  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output_container_test = pd.concat(raw_output_container_test)\n",
    "raw_output_container_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "55fe5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_test[[\"product_id\", \"product_code\"]]\n",
    "for line in line_split:\n",
    "    df_tmp.loc[df_tmp[\"product_code\"].isin(line).values, raw_output_container_test.columns[:-1]] = raw_output_container_test[raw_output_container_test[\"product_code\"].isin(line).values].iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013bad6",
   "metadata": {},
   "source": [
    "## Inference with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a857db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 주혁님 threshold 계산 algorithm\n",
    "# submit = pd.read_csv('/content/모델4개2.csv', encoding = 'cp949')\n",
    "# submit['0.748 결과'][(submit['0.748 결과'] != 0) & (submit['class0'] > 0.45) & (submit['Class를 회귀로(모델3개)'] <= 0.75) & (submit['Class를 회귀로(모델1개)'] <= 0.75)] = 0\n",
    "# s = pd.read_csv('/content/drive/MyDrive/LG_Aimers2/open (7)/sample_submission.csv')\n",
    "# s['Y_Class'] = submit['0.748 결과']\n",
    "# s.to_csv('SotaToCha_0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "651c4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold_params(x, norm_params={\"reg_qual\": 0.05, \"reg_cls\": 0.5, \"cls_cls\": 0.05, \"meta_learning\": 0.05}):\n",
    "    '''\n",
    "        reg_qual : percentage of reduction on upper and lower bound for class 1\n",
    "        cls_reg : multiplier of standard deviation on upper and lower bound for class 1 (mean + std * alpha, mean - std * alpha)\n",
    "        cls_cls : minimum probability for class 1\n",
    "        meta_learning : minimum probability for class 1 (same as cls_cls)\n",
    "    '''\n",
    "\n",
    "    threshold_dic = {\"reg_qual\": {}, \"reg_cls\": {}, \"cls_cls\": {}, \"meta_learning\": {}}\n",
    "\n",
    "    df_tmp = x.copy()\n",
    "    df_tmp[\"tmp\"] = df_tmp[\"product_code\"].apply(lambda x: \"A_31\" if x == \"A_31\" else \"T_31_O_31\")\n",
    "\n",
    "    # reg_qual\n",
    "    df_stats = df_tmp.groupby([\"tmp\", \"y_class\"])[\"y_quality\"].describe().T\n",
    "    for k in [\"A_31\", \"T_31_O_31\"]:\n",
    "        tmp_range = (df_stats[k].loc[\"max\", 1] - df_stats[k].loc[\"min\", 1])\n",
    "        threshold_dic[\"reg_qual\"][k] = [df_stats[k].loc[\"min\", 1] + tmp_range * norm_params[\"reg_qual\"], df_stats[k].loc[\"max\", 1] - tmp_range * norm_params[\"reg_qual\"]]\n",
    "\n",
    "    # reg_cls\n",
    "    df_stats = df_tmp.groupby(\"tmp\")[\"y_class\"].describe().T\n",
    "    for k in [\"A_31\", \"T_31_O_31\"]:\n",
    "        threshold_dic[\"reg_cls\"][k] = [df_stats.loc[\"mean\", k] - df_stats.loc[\"std\", k] * norm_params[\"reg_cls\"], df_stats.loc[\"mean\", k] + df_stats.loc[\"std\", k] * norm_params[\"reg_cls\"]]\n",
    "\n",
    "    # cls_cls\n",
    "    df_stats = df_tmp.groupby(\"tmp\")[\"y_class\"].value_counts(normalize=True)\n",
    "    for k in [\"A_31\", \"T_31_O_31\"]:\n",
    "        threshold_dic[\"cls_cls\"][k] = [df_stats[(k, 1)] * (1 + norm_params[\"cls_cls\"]), 1]\n",
    "\n",
    "    # meta_learning\n",
    "    df_stats = df_tmp.groupby(\"tmp\")[\"y_class\"].value_counts(normalize=True)\n",
    "    for k in [\"A_31\", \"T_31_O_31\"]:\n",
    "        threshold_dic[\"meta_learning\"][k] = [df_stats[(k, 1)] * (1 + norm_params[\"meta_learning\"]), 1]\n",
    "\n",
    "    for k, v in threshold_dic.items():\n",
    "        print(k)\n",
    "        print(v)\n",
    "\n",
    "    return threshold_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "dd2c8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_label(x, class_spliter):\n",
    "    df_tmp = x.copy()\n",
    "    df_tmp[\"tmp\"] = df_tmp[\"product_code\"].apply(lambda x: \"A_31\" if x == \"A_31\" else \"T_31_O_31\")\n",
    "\n",
    "    # reg_qual\n",
    "    df_tmp[\"label_reg_qual\"] = 1\n",
    "    for k, v in class_spliter[\"reg_qual\"].items():\n",
    "        tmp_labeld = []\n",
    "        for i in df_tmp.loc[df_tmp[\"tmp\"] == k, \"reg_qual\"].values:\n",
    "            if i < v[0]:\n",
    "                tmp_labeld.append(0)\n",
    "            elif i > v[1]:\n",
    "                tmp_labeld.append(2)\n",
    "            else:\n",
    "                tmp_labeld.append(1)\n",
    "        df_tmp.loc[df_tmp[\"tmp\"] == k, \"label_reg_qual\"] = tmp_labeld\n",
    "\n",
    "    # reg_cls\n",
    "    df_tmp[\"label_reg_cls\"] = 1\n",
    "    for k, v in class_spliter[\"reg_cls\"].items():\n",
    "        tmp_labeld = []\n",
    "        for i in df_tmp.loc[df_tmp[\"tmp\"] == k, \"reg_cls\"].values:\n",
    "            if i < v[0]:\n",
    "                tmp_labeld.append(0)\n",
    "            elif i > v[1]:\n",
    "                tmp_labeld.append(2)\n",
    "            else:\n",
    "                tmp_labeld.append(1)\n",
    "        df_tmp.loc[df_tmp[\"tmp\"] == k, \"label_reg_cls\"] = tmp_labeld\n",
    "\n",
    "    # cls_cls\n",
    "    df_tmp[\"label_cls_cls\"] = 1\n",
    "    for k, v in class_spliter[\"cls_cls\"].items():\n",
    "        tmp_labeld = []\n",
    "        for i in df_tmp.loc[df_tmp[\"tmp\"] == k, [\"cls_cls0\", \"cls_cls1\", \"cls_cls2\"]].values:\n",
    "            if (i[1] >= v[0]) & (i[1] <= v[1]):\n",
    "                tmp_labeld.append(1)\n",
    "            else:\n",
    "                tmp_labeld.append(0 if np.argmax([i[0], i[2]]) == 0 else 2)\n",
    "        df_tmp.loc[df_tmp[\"tmp\"] == k, \"label_cls_cls\"] = tmp_labeld\n",
    "\n",
    "    # meta_learning\n",
    "    df_tmp[\"label_meta_learning\"] = 1\n",
    "    for k, v in class_spliter[\"meta_learning\"].items():\n",
    "        tmp_labeld = []\n",
    "        for i in df_tmp.loc[df_tmp[\"tmp\"] == k, [\"meta_learning_cls0\", \"meta_learning_cls1\", \"meta_learning_cls2\"]].values:\n",
    "            if (i[1] >= v[0]) & (i[1] <= v[1]):\n",
    "                tmp_labeld.append(1)\n",
    "            else:\n",
    "                tmp_labeld.append(0 if np.argmax([i[0], i[2]]) == 0 else 2)\n",
    "        df_tmp.loc[df_tmp[\"tmp\"] == k, \"label_meta_learning\"] = tmp_labeld\n",
    "    \n",
    "    # ensemble prediction\n",
    "    df_tmp[\"counter\"] = df_tmp.filter(regex=\"label_*\").apply(lambda x: Counter(x).most_common(3), axis=1)\n",
    "    df_tmp[\"majority_vote\"] = df_tmp[\"counter\"].apply(lambda x: x[0][0])\n",
    "    casting_voter = \"label_meta_learning\"\n",
    "    print((df_tmp[\"counter\"].apply(len) > 1).sum())\n",
    "    df_tmp.loc[(df_tmp[\"counter\"].apply(len) > 1), \"majority_vote\"] = df_tmp.loc[(df_tmp[\"counter\"].apply(len) > 1), casting_voter].values\n",
    "    df_tmp = df_tmp.drop(\"counter\", axis=1)\n",
    "    \n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d10c8902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_qual\n",
      "{'A_31': [0.52459785685, 0.53533071415], 'T_31_O_31': [0.5247315075, 0.5353176984999999]}\n",
      "reg_cls\n",
      "{'A_31': [0.6814556170952801, 1.4068977965593386], 'T_31_O_31': [0.8039269511291918, 1.21899568497396]}\n",
      "cls_cls\n",
      "{'A_31': [0.4502008032128514, 1], 'T_31_O_31': [0.7866762177650429, 1]}\n",
      "meta_learning\n",
      "{'A_31': [0.5568273092369478, 1], 'T_31_O_31': [0.9729942693409742, 1]}\n"
     ]
    }
   ],
   "source": [
    "params = {\"reg_qual\": -0.05, \"reg_cls\": 0.5, \"cls_cls\": -0.05, \"meta_learning\": 0.175}\n",
    "class_spliter = get_threshold_params(df_full, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0dbba6e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "=== label_reg_qual ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    433\n",
       "2     93\n",
       "0     72\n",
       "Name: label_reg_qual, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.724080\n",
       "2    0.155518\n",
       "0    0.120401\n",
       "Name: label_reg_qual, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_reg_qual\n",
       "A_31          1                 0.518072\n",
       "              2                 0.277108\n",
       "              0                 0.204819\n",
       "O_31          1                 1.000000\n",
       "T_31          1                 0.868805\n",
       "              2                 0.069971\n",
       "              0                 0.061224\n",
       "Name: label_reg_qual, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_reg_cls ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: label_reg_cls, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.680602\n",
       "2    0.172241\n",
       "0    0.147157\n",
       "Name: label_reg_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_reg_cls\n",
       "A_31          1                0.473896\n",
       "              2                0.285141\n",
       "              0                0.240964\n",
       "O_31          1                0.666667\n",
       "              2                0.333333\n",
       "T_31          1                0.830904\n",
       "              2                0.087464\n",
       "              0                0.081633\n",
       "Name: label_reg_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_cls_cls ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: label_cls_cls, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.680602\n",
       "2    0.172241\n",
       "0    0.147157\n",
       "Name: label_cls_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_cls_cls\n",
       "A_31          1                0.473896\n",
       "              2                0.285141\n",
       "              0                0.240964\n",
       "O_31          1                0.666667\n",
       "              2                0.333333\n",
       "T_31          1                0.830904\n",
       "              2                0.087464\n",
       "              0                0.081633\n",
       "Name: label_cls_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_meta_learning ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: label_meta_learning, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.680602\n",
       "2    0.172241\n",
       "0    0.147157\n",
       "Name: label_meta_learning, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_meta_learning\n",
       "A_31          1                      0.473896\n",
       "              2                      0.285141\n",
       "              0                      0.240964\n",
       "O_31          1                      0.666667\n",
       "              2                      0.333333\n",
       "T_31          1                      0.830904\n",
       "              2                      0.087464\n",
       "              0                      0.081633\n",
       "Name: label_meta_learning, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== majority_vote ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    407\n",
       "2    103\n",
       "0     88\n",
       "Name: majority_vote, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.680602\n",
       "2    0.172241\n",
       "0    0.147157\n",
       "Name: majority_vote, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  majority_vote\n",
       "A_31          1                0.473896\n",
       "              2                0.285141\n",
       "              0                0.240964\n",
       "O_31          1                0.666667\n",
       "              2                0.333333\n",
       "T_31          1                0.830904\n",
       "              2                0.087464\n",
       "              0                0.081633\n",
       "Name: majority_vote, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_inference = get_inference_label(raw_output_container_train, class_spliter)\n",
    "for i in [\"label_reg_qual\", \"label_reg_cls\", \"label_cls_cls\", \"label_meta_learning\", \"majority_vote\"]:\n",
    "    print(f\"=== {i} ===\")\n",
    "    print(\"value counts\")\n",
    "    display(train_inference[i].value_counts())\n",
    "    display(train_inference[i].value_counts(normalize=True))\n",
    "    display(train_inference.groupby(\"product_code\")[i].value_counts(normalize=True))\n",
    "    print(\"\\n\")\n",
    "#     print(\"acc:\", accuracy_score(train_inference[\"y_true\"], test_inference[i]))\n",
    "#     print(\"f1:\", f1_score(train_inference[\"y_true\"], train_inference[i], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4e4047aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== label_reg_qual ===\n",
      "acc: 0.9565217391304348\n",
      "f1: 0.9393424036281179\n",
      "=== label_reg_cls ===\n",
      "acc: 1.0\n",
      "f1: 1.0\n",
      "=== label_cls_cls ===\n",
      "acc: 1.0\n",
      "f1: 1.0\n",
      "=== majority_vote ===\n",
      "acc: 1.0\n",
      "f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in [\"label_reg_qual\", \"label_reg_cls\", \"label_cls_cls\", \"majority_vote\"]:\n",
    "    print(f\"=== {i} ===\")\n",
    "    print(\"acc:\", accuracy_score(train_inference[\"y_true\"], train_inference[i]))\n",
    "    print(\"f1:\", f1_score(train_inference[\"y_true\"], train_inference[i], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d74b7cb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "=== label_reg_qual ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    271\n",
       "0     22\n",
       "2     17\n",
       "Name: label_reg_qual, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.874194\n",
       "0    0.070968\n",
       "2    0.054839\n",
       "Name: label_reg_qual, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_reg_qual\n",
       "A_31          1                 0.731343\n",
       "              0                 0.223881\n",
       "              2                 0.044776\n",
       "O_31          1                 1.000000\n",
       "T_31          1                 0.912134\n",
       "              2                 0.058577\n",
       "              0                 0.029289\n",
       "Name: label_reg_qual, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_reg_cls ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    259\n",
       "0     35\n",
       "2     16\n",
       "Name: label_reg_cls, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.835484\n",
       "0    0.112903\n",
       "2    0.051613\n",
       "Name: label_reg_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_reg_cls\n",
       "A_31          1                0.611940\n",
       "              0                0.388060\n",
       "O_31          1                1.000000\n",
       "T_31          1                0.895397\n",
       "              2                0.066946\n",
       "              0                0.037657\n",
       "Name: label_reg_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_cls_cls ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    252\n",
       "0     42\n",
       "2     16\n",
       "Name: label_cls_cls, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.812903\n",
       "0    0.135484\n",
       "2    0.051613\n",
       "Name: label_cls_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_cls_cls\n",
       "A_31          0                0.611940\n",
       "              1                0.328358\n",
       "              2                0.059701\n",
       "O_31          1                1.000000\n",
       "T_31          1                0.945607\n",
       "              2                0.050209\n",
       "              0                0.004184\n",
       "Name: label_cls_cls, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== label_meta_learning ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    264\n",
       "0     38\n",
       "2      8\n",
       "Name: label_meta_learning, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.851613\n",
       "0    0.122581\n",
       "2    0.025806\n",
       "Name: label_meta_learning, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  label_meta_learning\n",
       "A_31          0                      0.567164\n",
       "              1                      0.358209\n",
       "              2                      0.074627\n",
       "O_31          1                      1.000000\n",
       "T_31          1                      0.987448\n",
       "              2                      0.012552\n",
       "Name: label_meta_learning, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== majority_vote ===\n",
      "value counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    264\n",
       "0     38\n",
       "2      8\n",
       "Name: majority_vote, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.851613\n",
       "0    0.122581\n",
       "2    0.025806\n",
       "Name: majority_vote, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "product_code  majority_vote\n",
       "A_31          0                0.567164\n",
       "              1                0.358209\n",
       "              2                0.074627\n",
       "O_31          1                1.000000\n",
       "T_31          1                0.987448\n",
       "              2                0.012552\n",
       "Name: majority_vote, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_inference = get_inference_label(raw_output_container_test, class_spliter)\n",
    "for i in [\"label_reg_qual\", \"label_reg_cls\", \"label_cls_cls\", \"label_meta_learning\", \"majority_vote\"]:\n",
    "    print(f\"=== {i} ===\")\n",
    "    print(\"value counts\")\n",
    "    display(test_inference[i].value_counts())\n",
    "    display(test_inference[i].value_counts(normalize=True))\n",
    "    display(test_inference.groupby(\"product_code\")[i].value_counts(normalize=True))\n",
    "    print(\"\\n\")\n",
    "#     print(\"acc:\", accuracy_score(train_inference[\"y_true\"], test_inference[i]))\n",
    "#     print(\"f1:\", f1_score(train_inference[\"y_true\"], train_inference[i], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "098b4845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_qual</th>\n",
       "      <th>cls_cls0</th>\n",
       "      <th>cls_cls1</th>\n",
       "      <th>cls_cls2</th>\n",
       "      <th>reg_cls</th>\n",
       "      <th>meta_learning_cls0</th>\n",
       "      <th>meta_learning_cls1</th>\n",
       "      <th>meta_learning_cls2</th>\n",
       "      <th>product_code</th>\n",
       "      <th>product_id</th>\n",
       "      <th>tmp</th>\n",
       "      <th>label_reg_qual</th>\n",
       "      <th>label_reg_cls</th>\n",
       "      <th>label_cls_cls</th>\n",
       "      <th>label_meta_learning</th>\n",
       "      <th>majority_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.524071</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>0.864400</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>0.536509</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.979189</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_003</td>\n",
       "      <td>A_31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531568</td>\n",
       "      <td>0.054616</td>\n",
       "      <td>0.837202</td>\n",
       "      <td>0.108182</td>\n",
       "      <td>1.107915</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.976790</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_004</td>\n",
       "      <td>A_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533111</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.835881</td>\n",
       "      <td>0.140231</td>\n",
       "      <td>1.223501</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.976171</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_005</td>\n",
       "      <td>A_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.532295</td>\n",
       "      <td>0.073844</td>\n",
       "      <td>0.888689</td>\n",
       "      <td>0.037468</td>\n",
       "      <td>0.835941</td>\n",
       "      <td>0.009695</td>\n",
       "      <td>0.981736</td>\n",
       "      <td>0.008570</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_006</td>\n",
       "      <td>A_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.526138</td>\n",
       "      <td>0.877041</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>0.040532</td>\n",
       "      <td>0.382443</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>A_31</td>\n",
       "      <td>TEST_007</td>\n",
       "      <td>A_31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.527853</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.953319</td>\n",
       "      <td>0.022709</td>\n",
       "      <td>0.936865</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.993919</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>T_31</td>\n",
       "      <td>TEST_305</td>\n",
       "      <td>T_31_O_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.527677</td>\n",
       "      <td>0.060022</td>\n",
       "      <td>0.902709</td>\n",
       "      <td>0.037269</td>\n",
       "      <td>0.902171</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.992464</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>T_31</td>\n",
       "      <td>TEST_306</td>\n",
       "      <td>T_31_O_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.528133</td>\n",
       "      <td>0.024509</td>\n",
       "      <td>0.954418</td>\n",
       "      <td>0.021073</td>\n",
       "      <td>1.026776</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.993947</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>T_31</td>\n",
       "      <td>TEST_307</td>\n",
       "      <td>T_31_O_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.528046</td>\n",
       "      <td>0.046015</td>\n",
       "      <td>0.897660</td>\n",
       "      <td>0.056326</td>\n",
       "      <td>1.017740</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.992301</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>T_31</td>\n",
       "      <td>TEST_308</td>\n",
       "      <td>T_31_O_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.528873</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.949132</td>\n",
       "      <td>0.030837</td>\n",
       "      <td>1.035926</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.993810</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>T_31</td>\n",
       "      <td>TEST_309</td>\n",
       "      <td>T_31_O_31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reg_qual  cls_cls0  cls_cls1  cls_cls2   reg_cls  meta_learning_cls0  \\\n",
       "0    0.524071  0.121408  0.864400  0.014192  0.536509            0.012408   \n",
       "1    0.531568  0.054616  0.837202  0.108182  1.107915            0.010555   \n",
       "2    0.533111  0.023887  0.835881  0.140231  1.223501            0.009728   \n",
       "3    0.532295  0.073844  0.888689  0.037468  0.835941            0.009695   \n",
       "4    0.526138  0.877041  0.082427  0.040532  0.382443            0.959212   \n",
       "..        ...       ...       ...       ...       ...                 ...   \n",
       "238  0.527853  0.023972  0.953319  0.022709  0.936865            0.003062   \n",
       "239  0.527677  0.060022  0.902709  0.037269  0.902171            0.003894   \n",
       "240  0.528133  0.024509  0.954418  0.021073  1.026776            0.003020   \n",
       "241  0.528046  0.046015  0.897660  0.056326  1.017740            0.003790   \n",
       "242  0.528873  0.020031  0.949132  0.030837  1.035926            0.003040   \n",
       "\n",
       "     meta_learning_cls1  meta_learning_cls2 product_code product_id  \\\n",
       "0              0.979189            0.008404         A_31   TEST_003   \n",
       "1              0.976790            0.012656         A_31   TEST_004   \n",
       "2              0.976171            0.014101         A_31   TEST_005   \n",
       "3              0.981736            0.008570         A_31   TEST_006   \n",
       "4              0.022046            0.018742         A_31   TEST_007   \n",
       "..                  ...                 ...          ...        ...   \n",
       "238            0.993919            0.003018         T_31   TEST_305   \n",
       "239            0.992464            0.003642         T_31   TEST_306   \n",
       "240            0.993947            0.003033         T_31   TEST_307   \n",
       "241            0.992301            0.003909         T_31   TEST_308   \n",
       "242            0.993810            0.003150         T_31   TEST_309   \n",
       "\n",
       "           tmp  label_reg_qual  label_reg_cls  label_cls_cls  \\\n",
       "0         A_31               0              0              1   \n",
       "1         A_31               1              1              1   \n",
       "2         A_31               1              1              1   \n",
       "3         A_31               1              1              1   \n",
       "4         A_31               1              0              0   \n",
       "..         ...             ...            ...            ...   \n",
       "238  T_31_O_31               1              1              1   \n",
       "239  T_31_O_31               1              1              1   \n",
       "240  T_31_O_31               1              1              1   \n",
       "241  T_31_O_31               1              1              1   \n",
       "242  T_31_O_31               1              1              1   \n",
       "\n",
       "     label_meta_learning  majority_vote  \n",
       "0                      1              1  \n",
       "1                      1              1  \n",
       "2                      1              1  \n",
       "3                      1              1  \n",
       "4                      0              0  \n",
       "..                   ...            ...  \n",
       "238                    1              1  \n",
       "239                    1              1  \n",
       "240                    1              1  \n",
       "241                    1              1  \n",
       "242                    1              1  \n",
       "\n",
       "[310 rows x 16 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ee46581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inference.sort_values(\"product_id\").to_csv(architecture_path + \"test_rawoutput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63b79e",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d724e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_col = \"majority_vote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "730ac382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tmp = df_test[[\"product_id\", \"line\"]]\n",
    "df_test_tmp[\"target_class\"] = 1\n",
    "\n",
    "for line in line_split:\n",
    "    df_test_tmp.loc[df_tmp[\"product_code\"].isin(line), \"target_class\"] = test_inference.loc[test_inference[\"product_code\"].isin(line), inference_col].values\n",
    "\n",
    "df_test_tmp[\"target_class\"] = df_test_tmp[\"target_class\"].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "06c1677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>line</th>\n",
       "      <th>target_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>T100306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>T100304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>T100304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>T010305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>T010306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>TEST_305</td>\n",
       "      <td>T100306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>TEST_306</td>\n",
       "      <td>T100304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>TEST_307</td>\n",
       "      <td>T100306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>TEST_308</td>\n",
       "      <td>T100306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TEST_309</td>\n",
       "      <td>T100306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id     line  target_class\n",
       "0     TEST_000  T100306             1\n",
       "1     TEST_001  T100304             1\n",
       "2     TEST_002  T100304             1\n",
       "3     TEST_003  T010305             1\n",
       "4     TEST_004  T010306             1\n",
       "..         ...      ...           ...\n",
       "305   TEST_305  T100306             1\n",
       "306   TEST_306  T100304             1\n",
       "307   TEST_307  T100306             1\n",
       "308   TEST_308  T100306             1\n",
       "309   TEST_309  T100306             1\n",
       "\n",
       "[310 rows x 3 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "afa1f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../datasets/sample_submission.csv\")\n",
    "submission[\"Y_Class\"] = df_test_tmp[\"target_class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e979b7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>Y_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>TEST_305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>TEST_306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>TEST_307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>TEST_308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TEST_309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRODUCT_ID  Y_Class\n",
       "0     TEST_000        1\n",
       "1     TEST_001        1\n",
       "2     TEST_002        1\n",
       "3     TEST_003        1\n",
       "4     TEST_004        1\n",
       "..         ...      ...\n",
       "305   TEST_305        1\n",
       "306   TEST_306        1\n",
       "307   TEST_307        1\n",
       "308   TEST_308        1\n",
       "309   TEST_309        1\n",
       "\n",
       "[310 rows x 2 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a885cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(architecture_path + \"submission_\" + architecture_name + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c018dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
