{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXuRjd5Y_Xu6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from optuna import Trial\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(37) # Seed 고정\n",
        "train = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./test.csv')\n",
        "'''\n",
        "train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
        "train_y = train_df['Y_Class']\n",
        "\n",
        "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])\n",
        "train_x = train_x.fillna(0) # NaN 0으로 채우기\n",
        "test_x = test_x.fillna(0)\n",
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "    # test_x 데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가한다 (중요!!!)\n",
        "    for label in np.unique(test_x[i]):\n",
        "        if label not in le.classes_: # unseen label 데이터인 경우( )\n",
        "            le.classes_ = np.append(le.classes_,label) # 미처리 시 ValueError발생\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "'''\n",
        "col_list = train.columns\n",
        "nan_list = []\n",
        "nan_cnt = []\n",
        "nan_col = []\n",
        "full_list = []\n",
        "for col in col_list:\n",
        "    if train[col].isnull().sum() == 0 :\n",
        "        full_list.append(col)\n",
        "        continue\n",
        "    nan_list.append([col, train[col].isnull().sum()])\n",
        "    nan_cnt.append(train[col].isnull().sum())\n",
        "    nan_col.append(col)\n",
        "    \n",
        "'''모든값이 결측값이면 제거'''\n",
        "del_col = []\n",
        "for col in nan_list :\n",
        "    if col[1] == 598 :\n",
        "        del_col.append(col[0])\n",
        "train = train.drop(columns=del_col)\n",
        "test = test.drop(columns=del_col)\n",
        "train.head(3)\n",
        "\n",
        "\n",
        "\n",
        "trainA_31 = train[train['PRODUCT_CODE']=='A_31']\n",
        "train_T_31 = train[train['PRODUCT_CODE']=='T_31']\n",
        "train_O_31 = train[train['PRODUCT_CODE']=='O_31']\n",
        "\n",
        "testA_31 = test[test['PRODUCT_CODE']=='A_31']\n",
        "test_T_31 = test[test['PRODUCT_CODE']=='T_31']\n",
        "test_O_31 = test[test['PRODUCT_CODE']=='O_31']\n",
        "\n",
        "\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listA_31 = []\n",
        "nan_cntA_31 = []\n",
        "nan_colA_31 = []\n",
        "full_listA_31 = []\n",
        "for col in col_list:\n",
        "    if trainA_31[col].isnull().sum() == 0 :\n",
        "        full_listA_31.append(col)\n",
        "        continue\n",
        "    nan_listA_31.append([col, trainA_31[col].isnull().sum()])\n",
        "    nan_cntA_31.append(trainA_31[col].isnull().sum())\n",
        "    nan_colA_31.append(col)\n",
        "    \n",
        "\n",
        "del_col = []\n",
        "for col in nan_listA_31 :\n",
        "    if col[1] == len(trainA_31) :\n",
        "        del_col.append(col[0])\n",
        "trainA_31 = trainA_31.drop(columns=del_col)\n",
        "testA_31 = testA_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "del_col = []\n",
        "col_list = trainA_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if trainA_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "trainA_31 = trainA_31.drop(columns=del_col)\n",
        "testA_31 = testA_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listO = []\n",
        "nan_cntO = []\n",
        "nan_colO = []\n",
        "full_listO = []\n",
        "for col in col_list:\n",
        "    if train_O_31[col].isnull().sum() == 0 :\n",
        "        full_listO.append(col)\n",
        "        continue\n",
        "    nan_listO.append([col, train_O_31[col].isnull().sum()])\n",
        "    nan_cntO.append(train_O_31[col].isnull().sum())\n",
        "    nan_colO.append(col)\n",
        "    \n",
        "\n",
        "del_col = []\n",
        "for col in nan_listO :\n",
        "    if col[1] == len(train_O_31) :\n",
        "        del_col.append(col[0])\n",
        "train_O_31 = train_O_31.drop(columns=del_col)\n",
        "test_O_31 = test_O_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "del_col = []\n",
        "col_list = train_O_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if train_O_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "train_O_31 = train_O_31.drop(columns=del_col)\n",
        "test_O_31 = test_O_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "col_list = train.columns\n",
        "nan_listT = []\n",
        "nan_cntT = []\n",
        "nan_colT = []\n",
        "full_listT = []\n",
        "for col in col_list:\n",
        "    if train_T_31[col].isnull().sum() == 0 :\n",
        "        full_listT.append(col)\n",
        "        continue\n",
        "    nan_listT.append([col, train_T_31[col].isnull().sum()])\n",
        "    nan_cntT.append(train_T_31[col].isnull().sum())\n",
        "    nan_colT.append(col)\n",
        "    \n",
        "\n",
        "del_col = []\n",
        "for col in nan_listT :\n",
        "    if col[1] == len(train_T_31) :\n",
        "        del_col.append(col[0])\n",
        "train_T_31 = train_T_31.drop(columns=del_col)\n",
        "test_T_31 = test_T_31.drop(columns=del_col)\n",
        "\n",
        "\n",
        "del_col = []\n",
        "col_list = train_T_31.columns\n",
        "for col in col_list[6:] :\n",
        "    if train_T_31[col].nunique()==1 :\n",
        "        del_col.append(col)\n",
        "train_T_31 = train_T_31.drop(columns=del_col)\n",
        "test_T_31 = test_T_31.drop(columns=del_col)\n",
        "\n",
        "'''\n",
        "trainA_31_x = trainA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
        "testA_31_x = testA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_T_31_x = train_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','Y_Class','Y_Quality','PRODUCT_CODE'])\n",
        "test_T_31_x = test_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_O_31_x = train_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Class','Y_Quality'])\n",
        "test_O_31_x = test_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "\n",
        "'''\n",
        "#클래스 살리기\n",
        "trainA_31_x = trainA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Quality'])\n",
        "testA_31_x = testA_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_T_31_x = train_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','Y_Quality','PRODUCT_CODE'])\n",
        "test_T_31_x = test_T_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "train_O_31_x = train_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE','Y_Quality'])\n",
        "test_O_31_x = test_O_31.drop(columns=['PRODUCT_ID','TIMESTAMP','PRODUCT_CODE'])\n",
        "\n",
        "\n",
        "# classification\n",
        "trainA_31_y_c = trainA_31['Y_Class']\n",
        "train_T_31_y_c = train_T_31['Y_Class']\n",
        "train_O_31_y_c = train_O_31['Y_Class']\n",
        "\n",
        "# regression\n",
        "trainA_31_y_r = trainA_31['Y_Quality']\n",
        "train_T_31_y_r = train_T_31['Y_Quality']\n",
        "train_O_31_y_r = train_O_31['Y_Quality']\n",
        "\n",
        "train_T_31_y_r = pd.DataFrame(train_T_31_y_r,columns = ['Y_Quality'])\n",
        "train_T_31_y_r = train_T_31_y_r.reset_index(drop = True)\n",
        "test_T = train_T_31_y_r\n",
        "\n",
        "trainA_31_x=trainA_31_x.fillna(-1)\n",
        "testA_31_x=testA_31_x.fillna(-1)\n",
        "train_T_31_x=train_T_31_x.fillna(-1)\n",
        "test_T_31_x=test_T_31_x.fillna(-1)\n",
        "train_O_31_x=train_O_31_x.fillna(-1)\n",
        "test_O_31_x=test_O_31_x.fillna(-1)\n",
        "\n",
        "train_T_31_x['level0'] = 0\n",
        "train_T_31_x['level1'] = 0\n",
        "train_T_31_x['level0'][train_T_31_x['LINE'] == 'T100304'] = 1\n",
        "train_T_31_x['level1'][train_T_31_x['LINE'] == 'T100306'] = 1\n",
        "\n",
        "test_T_31_x['level0'] = 0\n",
        "test_T_31_x['level1'] = 0\n",
        "test_T_31_x['level0'][test_T_31_x['LINE'] == 'T100304'] = 1\n",
        "test_T_31_x['level1'][test_T_31_x['LINE'] == 'T100306'] = 1\n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(trainA_31_x[i])\n",
        "    trainA_31_x[i] = le.transform(trainA_31_x[i])\n",
        "    \n",
        "    for label in np.unique(testA_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    testA_31_x[i] = le.transform(testA_31_x[i]) \n",
        "print('Done.')\n",
        "\n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_T_31_x[i])\n",
        "    train_T_31_x[i] = le.transform(train_T_31_x[i])\n",
        "    \n",
        "    for label in np.unique(test_T_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_T_31_x[i] = le.transform(test_T_31_x[i]) \n",
        "print('Done.')\n",
        "\n",
        "\n",
        "# qualitative to quantitative\n",
        "qual_col = ['LINE']\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_O_31_x[i])\n",
        "    train_O_31_x[i] = le.transform(train_O_31_x[i])\n",
        "    \n",
        "    for label in np.unique(test_O_31_x[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_O_31_x[i] = le.transform(test_O_31_x[i]) \n",
        "print('Done.')\n",
        "\n",
        "\n",
        "\n",
        "from catboost import *\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "            'iterations':trial.suggest_int(\"iterations\", 300, 1000),\n",
        "            'learning_rate' : trial.suggest_uniform('learning_rate',0.1, 1),\n",
        "            'depth': trial.suggest_int('depth',5, 16),\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n",
        "            'reg_lambda': trial.suggest_uniform('reg_lambda',30,100),\n",
        "            'subsample': trial.suggest_uniform('subsample',0.3,1),\n",
        "            'random_strength': trial.suggest_uniform('random_strength',10,100),\n",
        "            'od_wait':trial.suggest_int('od_wait', 10, 150),\n",
        "            'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,20),\n",
        "            'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 1, 100),\n",
        "            \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0., 1.0),\n",
        "            'random_state' : 9555,\n",
        "            'verbose' : 0,\n",
        "        }\n",
        "    #'task_type' : 'GPU',\n",
        "    #\"eval_metric\":'RMSE',\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(train_T_31_x, train_T_31_y_r, test_size=0.3, stratify=train_T_31_x['Y_Class'])\n",
        "\n",
        "    valid_class = x_valid['Y_Class']\n",
        "    valid_class = pd.DataFrame(valid_class,columns = ['Y_Class'])\n",
        "    valid_class = valid_class.reset_index(drop = True)\n",
        "    \n",
        "    x_train.drop(['Y_Class'],axis=1,inplace=True)\n",
        "    x_valid.drop(['Y_Class'],axis=1,inplace=True)\n",
        "    cat = CatBoostRegressor(**params)\n",
        "    cat.fit(x_train, y_train, eval_set=[(x_train,y_train),(x_valid,y_valid)],\n",
        "              verbose=False)\n",
        "    cat_pred = cat.predict(x_valid)\n",
        "    \n",
        "    y_valid = cat_pred\n",
        "    y_valid = pd.DataFrame(y_valid,columns = ['Y_Quality'])\n",
        "    y_valid = y_valid.reset_index(drop = True)\n",
        "    y_valid['Y_Class2'] = 1\n",
        "    y_valid.loc[(y_valid['Y_Quality']<0.52507), 'Y_Class2'] = 0\n",
        "    y_valid.loc[(y_valid['Y_Quality']>0.5349), 'Y_Class2'] = 2\n",
        "    print(y_valid)\n",
        "    print(valid_class)\n",
        "    score = f1_score(valid_class, y_valid['Y_Class2'], average = 'macro')\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=550, show_progress_bar=True)\n",
        "\n",
        "#study.optimize(lambda trial: objective_xgb(trial, train_x, train_y), n_trials=100)\n",
        "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
        "\n",
        "\n",
        "param = study.best_trial.params\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "xgbc = XGBClassifier(**param, tree_method='gpu_hist', gpu_id=0,random_state=37)\n",
        "xgbc.fit(train_x, train_y)\n",
        "\n",
        "pred = xgbc.predict(test_x)\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['Y_Class'] = pred\n",
        "submit.to_csv('./submit.csv', index=False)\n",
        "'''\n"
      ]
    }
  ]
}